[
["index.html", "Theoretical Community Ecology Preliminaries Approach and target audience Topics Notation Grading and code of conduct A note about biographies Sources Acknowledgements", " Theoretical Community Ecology Stefano Allesina 2021-02-06 Preliminaries Approach and target audience The material was prepared for the graduate class Theoretical Community Ecology taught at the University of Chicago — AY 2020/2021. Following the material requires some familiarity with calculus (multivariable integration, derivatives, chain rule) and linear algebra (vector spaces, eigenvalues, eigenvectors). Also, a good working knowledge of R (writing functions, working with the packages deSolve and tidyverse) is needed to follow the code (all figures are generated at runtime, and therefore the source code for these lectures contains all the code/data needed to replicate the figures). The approach taken throughout the course is to alternate between code/simulations and mathematical derivations. While several theorems are (informally) stated, proofs are included only when elementary and/or informative of the underlying biological processes. The class builds upon material typically presented in classes on population, community and theoretical ecology. The main goal of the class is to build a toolbox for solving problems in theoretical community ecology, bridging the gap between what typically presented in introductory classes and the primary literature. Topics The choice of themes is very opinionated, and heavily biased toward my own research interests. Because of this, the focus is squarely on continuous time, time-invariant models—in most cases without any consideration of space and stochasticity. Similarly, the material mostly deals with the case of multispecies dynamics, though low-dimensional models are considered when their analysis helps with the understanding of the multispecies case. Finally, much of the material is centered around the Generalized Lotka-Volterra model and its cousins (e.g., the replicator equation). This because a) the Generalized Lotka-Volterra model for multiple interacting species is in a way the simplest nonlinear model for population dynamics; and b) it is a “canonical” model—in the sense that many other models can be re-cast in GLV form. Notation Unless specified or for obvious exceptions, Greek letters stand for scalars (i.e., real or complex numbers), lower case roman letters for vectors, and capital roman letters for matrices (as such \\(a_i\\) or \\(A_{ij}\\) are scalars). We typically work in \\(\\mathbb{R}^n\\) (the \\(n\\)-dimensional Euclidean space), \\(\\mathbb{R}^n_+\\) (i.e., the positive orthant of \\(\\mathbb{R}^n\\)), or \\(\\mathbb{R}^n_{0+}\\) (non-negative orthant). \\(D(x)\\) is a diagonal matrix with \\(x\\) on the diagonal. The matrix \\(A^T\\) is the transpose of \\(A\\). Whenever it is clear what I mean, I will drop the dependency on time of certain variables. The Generalized Lotka-Volterra model: \\[ \\dfrac{d x_i(t)}{d t} = x_i(t) \\left(a_i + \\sum_{j} B_{ij} x_j(t) \\right) \\] can be written in compact form as: \\[ \\dfrac{d x}{d t} = D(x) (a + B x) \\] Grading and code of conduct Students should follow the rules and regulations set out by University policy. I am expecting all students to a) participate in all classes (please contact me if you are going to be absent); b) actively contribute to discussions and lectures; c) be punctual (both for class and when submitting the homework); d) be professional and honest (no copying/cheating/plagiarizing). Homework (80%) Each lecture contains exercises that should be completed as graded homework. The homework should be submitted through Canvas as one or more pdf files obtained by compiling Rmd files. The homework should contain the derivations (you can use LaTex to typeset mathematics within Rmd, see here for commonly used commands), and code. The code must run and be correct to get a passing grade. Review (20%) The remaining 20% of the grade is based on a graded review. Each student should choose an interesting (important, provocative, etc.) published paper or preprint in theoretical community ecology, and produce a review (of the kind one would submit to a journal if solicited for comments). The review must contain two sections: a) Comments to the Authors, and b) Recommendation for the Editor. Good advice on writing reviews can be found here. Accommodation for students with disabilities University of Chicago is committed to ensuring equitable access to our academic programs and services. Students with disabilities who have been approved for the use of academic accommodations by Student Disability Services (SDS) and need a reasonable accommodation(s) to participate fully in this course should follow the procedures established by SDS for using accommodations. Timely notifications are required in order to ensure that your accommodations can be implemented. Please meet with me to discuss your access needs in this course after you have completed the SDS procedures for requesting accommodations. A note about biographies The lecture notes are interdispersed with short biographies of scientists who greatly contributed to the problems being studied. The attentive reader will notice that most of the photographs are depicting old white men. Their age is easy to explain: I have only included biographies of deceased scientists (so that they cannot contradict me!), and most of them enjoyed a long life (with some exceptions; for example Robert MacArthur tragically died at age 45). The impossibly skewed gender ratio, and the lack of ethnic diversity has to be explained with the tremendous homogeneity of the field—which was broken only recently. It is my hope that these lectures will engage young ecologists from different backgrounds and histories with the theory of community ecology, such that whoever will teach this type of material in a couple of decades will be able to include a more interesting and diverse gallery of portraits. Sources Many excellent books are available on these topics. Here are the main references I’ve used while preparing these lectures: Strogatz (2018) — a clear, concise introduction to dynamical systems. Ellner and Guckenheimer (2011) — an introduction to dynamical models focusing on biology. Hofbauer and Sigmund (1998) — a great resource for models of population dynamics and evolutionary game theory. Szederkenyi, Magyar, and Hangos (2018) — an introduction to quasi-polynomial systems and reaction networks. Hadeler, Mackey, and Stevens (2017) — a more mathematically-focused reading. Hirsch, Smale, and Devaney (2012) — an extensive, clearly written and rigorous introduction to dynamical systems. Acknowledgements These lectures grew out of a set of four lectures I have presented at the ICTP-SAIFR/IFT-UNESP “School on Community Ecology: from patterns to principles”, held on January 20-25, 2020 in São Paulo, Brazil. Thanks to the organizers (Marcus Aguiar, Jacopo Grilli, Roberto Kraenkel, Ricardo Martinez-Garcia and Paulo Inácio Prado) for the invitation and for prompting me to start working on the material. The lecture on assembly was test-driven at the ICTP “Winter School on Quantitative Systems Biology: Quantitative Approaches in Ecosystem Ecology”, organized by Simon Levin, Matteo Marsili, Jacopo Grilli, and Antonio Celani. I am grateful to the students in both schools for useful feedback. The development of this material was supported by the National Science Foundation (DEB #2022742). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect the views of the National Science Foundation. References "],
["models-for-a-single-population.html", "Lecture 1 Models for a single population 1.1 Types of dynamical systems 1.2 Initial-value problems 1.3 Solvable model: Exponential growth 1.4 Solvable model: Logistic growth 1.5 Qualitative analysis of models for a single population 1.6 Bifurcations 1.7 Long term behavior of 1-D systems 1.8 Lyapunov functions", " Lecture 1 Models for a single population Lesson plan: We start by discussing what it means to solve an initial-value problem: the solution is an expression that allows us to calculate \\(x(t)\\) for any \\(t\\). A few ecologically-relevant models can be solved explicitly, for example the exponential and logistic growth models. Because solving differential equations is a laborious process, and in many cases writing the solution is impossible or does not give us any insight on the dynamics, we introduce a graphical model that allows us to effortlessly sketch the dynamics of any ODE (i.e., models with a single equation). This allows us to introduce essential concepts such as the notion of an equilibrium and its stability. We show that determining stability using this graphical method is equivalent to performing stability analysis via linearization around an equilibrium, a method that will be extended to systems of multiple ODEs in the next chapter. We briefly discuss the idea of bifurcation points — i.e., particular choices of parameters for which the dynamics of the system change qualitatively. We conclude by introducing the idea of Lyapunov functions, allowing us to determine global stability of an equilibrium without the need to explicitly solve the model. We will see a lot of these functions when we study larger systems. 1.1 Types of dynamical systems Dynamical systems describe the change of certain variables, typically in time, space or a combination of the two. They have found applications in all scientific disciplines, and were introduced in ecology and evolutionary biology at the beginning of the twentieth century. Broadly, dynamical systems can be divided into continuous (described by differential equations), or discrete (described by maps, or difference equations) models. Many models for population dynamics can be written as (systems of) first-order ordinary differential equations, i.e. equations containing functions of one (or more) independent variables and their derivatives (typically, with respect to time). Ordinary means we’re not dealing with partial differential equations (used in ecology for example for reaction-diffusion equations, or spatial models). First-order, mean that they contain only the first derivative with respect to time. Here we will concentrate on autonomous systems, meaning that they are time-invariant (e.g., coefficients do not change in time). We can write these systems as: \\[ \\dfrac{d x(t)}{d t} = f(x(t)) \\] In general, we will examine cases in which \\(f(x(t))\\) is a nonlinear function of \\(x(t)\\). We typically deal with deterministic systems, in which randomness plays no role in determining future states. Stochastic differential equations, on the other hand, include random components. 1.2 Initial-value problems Typically, we would like to track the evolution of the system in time, starting from known initial conditions. For example, \\[ \\dfrac{d x(t)}{d t} = f(x(t)), \\;\\; x(0) = x_0 \\] where the independent variable \\(t\\) denotes time and is considered non-negative. \\(x(t)\\) is the state of the system (e.g., the density of the species) at time \\(t\\), \\(x(t) \\in \\mathbb{R}^n\\), and the function \\(f\\) models the evolution of the system, mapping \\(\\mathbb{R}^n \\to \\mathbb{R}^n\\). The vector \\(x_0 = x(0) \\in \\mathbb{R}^n\\) marks the initial condition of the system. The simplest and most common case in ecology is that in which \\(f\\) is (infinitely) many times continuously differentiable, a.k.a. smooth. If this is the case, then the solution \\(x(t)\\) exists and is unique. In ecological models, dynamics are invariant with respect to the non-negative orthant \\(\\mathbb{R}^n_{0+}\\), i.e., the vector \\(x(t)\\) remains non-negative whenever initialized at non-negative initial conditions \\(x_0 \\in \\mathbb{R}^n_{0+}\\). The function \\(f\\) is essentially non-negative if whenever \\(x_i = 0\\), then \\(f_i(x) \\geq 0\\) for all \\(x \\in \\mathbb{R}^n_{0+}\\). A dynamical system is non-negative only if \\(f\\) is essentially non-negative. We can solve the (system of) ODE(s) if we can write an explicit equation for \\(x(t)\\) given the parameters and the initial conditions. In practice, we rarely can solve the equations we’re interested in. We can however prove that, if \\(f(x(t))\\) is sufficiently well-behaved (technically, if \\(f(x)\\) is Lipschitz continuous, for example, if it has bounded derivatives), then the initial-value problem above has a solution, the solution is unique, and depends continuously on the intial conditions and the parameters. This means that if we start the system at any point \\(x(t)= x_t\\), we cannot have multiple trajectories intersecting. 1.3 Solvable model: Exponential growth History: Pierre-François Verhulst (1804-1849) Pierre-François Verhulst was born in 1804 in Brussels, Belgium. In 1835, he became professor of mathematics at the newly-instituded Free University of Brussels. In 1838, inspired by the work of Malthus and Quetelet, he wrote a Note on the law of population growth, where he argued that the geometric progression imagined by Malthus would be unfeasible to sustain. He therefore introduced an unknown function that would slow down growth for large populations: “The simplest hypothesis one can make on the form of this function is to suppose that” the unknown function would be quadratic in the size of the population. He went on to solve what is now known as the “logistic growth” model and contrasted it with data for the growth of populations in various countries. A model of ecological interest that has an explicit solution is that for the exponential growth: \\[ \\dfrac{d x(t)}{dt} = \\rho \\, x(t), \\;\\; x(0) = x_0 \\] This is a separable differential equation, meaning that we can formally write: \\[ \\dfrac{1}{x(t)} dx(t) = \\rho\\, dt \\] Integrate both sides (the left hand side in \\(d x(t)\\), the r.h.s. in \\(dt\\)): \\[ \\begin{aligned} \\int \\dfrac{1}{x(t)} d x(t) = \\rho \\int dt \\end{aligned} \\] Obtaining (\\(C_i\\) are constants of integration): \\[ \\begin{aligned} \\log x(t) + C_1= \\rho\\, t + C_2\\\\ \\log x(t) = \\rho\\, t + C_3\\\\ x(t) = e^{\\rho\\,t + C_3}\\\\ x(t) = C_4 e^{\\rho\\, t} \\end{aligned} \\] Substituting the initial condition \\(x(0) = x_0\\) we find that \\(C_4 = x_0\\): \\[ x(t) = x_0 e^{\\rho\\, t} \\] which is our solution. If we know the value of \\(\\rho\\) and the initial density \\(x_0\\), we can directly write the population density \\(x(t)\\) for any \\(t\\). 1.4 Solvable model: Logistic growth Another model that can be solved explicitly is that of the logistic growth: \\[ \\dfrac{d x(t)}{dt} = \\rho\\, x(t) (1 - \\alpha\\, x(t)), \\;\\; x(0) = 0 \\] again, we can separate the equation: \\[ \\dfrac{1}{x(t) (1 - \\alpha\\, x(t))} d x(t) = \\rho\\, dt \\] the r.h.s. is trivial to integrate, but the l.h.s. is trickier. We can transform it into a simpler expression by using partial fractions. We want to write: \\[ \\dfrac{1}{x(t) (1 - \\alpha\\, x(t))} = \\dfrac{A}{x(t)} + \\dfrac{B}{1 - \\alpha\\, x(t)} \\] where \\(A\\) and \\(B\\) are appropriate constants. Multiplying both sides by \\(x(t) (1 - \\alpha\\, x(t))\\), we obtain: \\[ 1 = A (1 - \\alpha\\, x(t)) + B \\, x(t) = A + x(t)\\, (B - A\\, \\alpha) \\] The l.h.s. does not contain \\(x(t)\\), and therefore we want to set \\(x(t)\\, (B - A\\, \\alpha) = 0\\), choosing \\(B = A\\, \\alpha\\), and therefore \\(A = 1\\). We can integrate the simpler form: \\[ \\int \\dfrac{1}{x(t)} \\,d x(t) + \\int \\dfrac{\\alpha}{(1 - \\alpha\\, x(t))}\\, d x(t) = \\rho\\, dt \\] obtaining: \\[ \\begin{aligned} \\log x(t) - \\log (1 - \\alpha\\, x(t)) = \\rho\\, t + C_1\\\\ \\log \\dfrac{x(t)}{1 - \\alpha\\, x(t)} = \\rho\\, t + C_1\\\\ \\dfrac{x(t)}{1 - \\alpha\\, x(t)} = e^{\\rho\\, t + C_1}\\\\ x(t) = \\dfrac{e^{\\rho\\, t + C_1}}{1 + \\alpha\\, e^{\\rho\\, t + C_1}}\\\\ x(t) = \\dfrac{1}{\\alpha + e^{-(\\rho\\, t + C_1)}} \\end{aligned} \\] To find the value of \\(C_1\\), substitute the initial condition \\(x(0) = x_0\\), and solve for \\(C_1\\): \\[ \\begin{aligned} x_0 = \\dfrac{1}{\\alpha + e^{-C_1}}\\\\ C_1 = \\log \\dfrac{x_0}{1 - \\alpha \\, x_0} \\end{aligned} \\] Finally, substituting, we find: \\[ x(t) = \\dfrac{x_0 \\, e^{\\rho\\, t}}{1 + \\alpha\\, x_0 \\, (e^{\\rho\\, t} - 1)} \\] which provides an explicit solution for this (very simple) model. Homework 1a Find the solution for the logistic growth with harvesting: \\[ \\dfrac{d x(t)}{dt} = \\rho\\, x(t) (1 - \\alpha\\, x(t)) - \\eta\\, x(t) \\] where \\(1 &gt; \\eta &gt; 0\\) is the proportion of individuals being harvested. 1.5 Qualitative analysis of models for a single population Because in general we cannot write an explicit solution for our models of interest, we attempt a qualitative analysis by: a) finding fixed points (equilibria); b) providing a qualitative description of the dynamics; c) probing the stability of fixed points; d) gaining an understanding of the system (nature of attractors, changes of behavior for different parameters) without deriving an explicit solution. When we are dealing with a single population, we can use a graphical method. Simply, plot \\(dx(t) /dt\\) against \\(x(t)\\). We think of \\(x(t)\\) as moving along the \\(x\\) axis, at a velocity determined by the \\(y\\) coordinate. For the exponential growth function: \\[ \\dfrac{d x(t)}{dt} = \\rho \\, x(t) \\] the graph becomes: The only point where the curve intercepts the \\(x\\) axis is \\(x^\\star = 0\\). A point \\(x^\\star\\) for which \\(\\left . \\dfrac{d x(t)}{dt} \\right|_{x^\\star} = 0\\) is an equilibrium (or fixed-point) for the system, meaning that if we initialize the system at \\(x^\\star\\), it will remain there unless perturbed. Whenever we apply a (small) perturbation to a stable equilibrium, the system returns to it; when we perturb an unstable equilibrium, on the other hand, the system moves away from it. Now think of a perturbation: if we were to perturb \\(x^\\star = 0\\) by introducing a few individuals, we would find that the population starts growing (i.e., \\(dx(t) / dt &gt; 0\\)), meaning that the point is unstable. Thus, using the graphical method introduced above, we can easily identify equilibria (i.e., where the curve intercepts the x-axis), and their stability (i.e., by determining whether the curve around the equilibrium is above or below \\(d x(t)/dt = 0\\)). Next, let’s consider the logistic growth equation: \\[ \\dfrac{d x(t)}{dt} = \\rho\\, x(t) (1 - \\alpha\\, x(t)) \\] We can draw the graph (note the quadratic term—we’re describing a parabola): Now we have two equilibria, at \\(x^\\star = 0\\) and \\(x^\\star = 1 / \\alpha\\). If we perturb \\(x^\\star = 0\\), the system moves away from it (unstable), while if we perturb \\(x^\\star = 1 / \\alpha\\) the system goes back to it (stable). History: Warder Clyde Allee (1885-1955) Born in Indiana, Allee received his PhD in 1912 from the University of Chicago, where he returned in 1921. He was the Dean in the College of Arts, Literature, and Science (1924-1926) and Secretary of the Department of Zoology (1927-1934). In 1935, a spinal tumor left him paralyzed from the waist down. This did not slow down his hectic schedule of teaching, researching and writing. He stayed at U. Chicago until his retirement (1950). Allee is also remembered as a pacifist (he was raised a Quaker) and an activist. He performed a series of studies on animal aggregation, finding that goldfish growing in a tank laced with colloidal silver would grow faster when more individuals were present. Today, the Allee effect applies to any population that grows faster when a certain threshold population is surpassed. Now a more complex model, in which the population experiences an Allee effect: \\[ \\dfrac{d x(t)}{dt} = \\rho\\, x(t) (x(t) - \\gamma) (1 - \\alpha\\, x(t)) \\] where \\(0&lt;\\gamma&lt;1 / \\alpha\\). Plotting, In this model, there are two stable equilibria (\\(x^\\star = 0\\) and \\(x^\\star = 1 / \\alpha\\)), separated by an unstable equilibrium (\\(x^\\star= \\gamma\\)). Depending on the initial condition, we might end up with either—we call this situation bistability. Note that bistability makes it clear that we can only apply small perturbations to the equilibrium to probe its stability—for example, imagine being at \\(x^\\star = 1 / \\alpha\\) and perturbing the population by bringing it below \\(\\gamma\\); then we would find that the population goes extinct, suggesting that \\(x^\\star = 1 / \\alpha\\) is “somewhat unstable”. 1.5.1 Stability using derivatives You might have noticed in the previous graphs that whenever the curve \\(dx(t) /dt\\) is negative on the left of a point and positive on its right we find that the point is unstable, while conversely a point for which \\(dx(t) /dt\\) is positive on the left and negative on the right is stable. We can formalize this by taking the derivative of \\(dx(t) /d t\\) with respect to \\(x(t)\\), and evaluating this function at different equilibria. For example, for the exponential growth model, we have: \\[ \\dfrac{\\partial}{\\partial x} \\dfrac{dx}{dt} = \\dfrac{\\partial f(x)}{\\partial x} = \\dfrac{\\partial (r x)}{\\partial x} = \\rho \\] This is always posive when \\(\\rho &gt; 0\\), and as such the only equilibrium (\\(x^\\star = 0\\)) is unstable. For the logistic growth, we find: \\[ \\dfrac{\\partial f(x)}{\\partial x} = \\dfrac{\\partial (\\rho\\, x - \\rho\\, \\alpha\\, x^2)}{\\partial x} = \\rho - 2 \\rho\\, \\alpha\\, x \\] When we evaluate this function at the equilibrium \\(x^\\star = 0\\), we obtain \\(\\rho &gt; 0\\), and as such the equilibrium is unstable. Conversely, when we evaluate the fuction at \\(x^\\star = 1 / \\alpha\\), we obtain \\(\\rho - 2 \\rho \\to -\\rho\\) and therefore the equilibrium is stable. Finally, for the model with Allee effect, we have: \\[ \\dfrac{\\partial (\\rho\\, x (x-\\gamma)(1-\\alpha\\, x))}{\\partial x} = - \\rho\\, \\gamma + 2 \\rho\\, x(1 + \\alpha) - 3 \\rho\\, \\alpha\\, x^2 \\] At \\(x^\\star = 0\\), we find \\(-\\rho\\, \\gamma\\) which is always negative, and as such \\(x^\\star = 0\\) is stable. At \\(x^\\star = \\gamma\\) we have \\(\\rho\\, \\gamma\\, (1- \\gamma\\, \\alpha)\\) which is positive (as \\(\\gamma\\, \\alpha &lt; 1\\)) and as such is an unstable equilibrium. Finally, for \\(x^\\star = 1/\\alpha\\) we have \\(\\rho (\\gamma - 1/\\alpha)\\) which is always negative. 1.5.2 What are we doing when probing stability using derivatives? More formally, we can think of describing the dynamics of a perturbation around the equilibrium. Call \\(\\Delta x(t) = x(t) - x^\\star\\), and approximate the dynamics around the equilibrium. We want to write the dynamics of \\(\\Delta x(t)\\). By chain rule, \\(\\frac{d \\Delta x(t)}{dt} = \\frac{d \\Delta x(t)}{d x(t)} \\frac{d x(t)}{dt}\\), and as such \\[ \\frac{d \\Delta x(t)}{dt} = f(\\Delta x(t) + x^\\star) \\] If we think of the perturbation as infinitesimally small, we can Taylor expand around \\(x^\\star\\): \\[ f(\\Delta x(t) + x^\\star) = f(x^\\star) + \\left . \\frac{df(x)}{dx} \\right |_{x^\\star} \\Delta x(t) + \\frac{1}{2}\\left . \\frac{d^2 f(x)}{dx^2} \\right |_{x^\\star} (\\Delta x(t))^2 + \\ldots \\] Taking only the linear term, and noticing that \\(f(x^\\star) = 0\\) by definition, we have: \\[ \\frac{d \\Delta x(t)}{dt} \\approx \\left . \\frac{d f(x)}{dx} \\right |_{x^\\star} \\Delta x(t) = \\rho\\, \\Delta x(t) \\] which is the equation for the exponential growth we have seen above. If \\(\\left . \\frac{d f(x)}{d x}\\right |_{x^\\star} &lt; 0\\) the perturbation \\(\\Delta x(t)\\) will die out, while if it is positive it will increase quickly. Note that the analysis is valid only in the immediate surroundings of \\(x^\\star\\)—i.e., only where the terms we have neglected are indeed negligible. 1.6 Bifurcations The shape of the graphs above might depend on the value of parameters. When a small change in one or several parameters causes a qualitative change in the behavior of the system, we say the system has crossed a bifurcation point (the term “bifurcation” was introduced by Henri Poincaré in 1885). At a bifurcation point, equilibria could disappear or be created, change their stability, the system could start cycling, etc. In low-dimensional system, there are a variety of different behaviors, each of which has its own name (e.g., saddle-node, pitchfork, transcritical, Hopf, period-doubling, …, bifurcation). The codimension of a bifurcation is the number of parameters we need to change the behavior of the system. Clearly, codimension-1 and -2 bifurcations are the simplest and most studied. Here we just show the main idea using a simple example. For a detailed and accessible introduction, see Strogatz (2018) and Seydel (2009). Consider the model: \\[ \\dfrac{d x}{dt} = \\rho + x^2 \\] The equilibria of the system, when they exist, are given by \\(x^\\star = \\pm \\sqrt{-\\rho}\\). It is clear that, when \\(\\rho &lt; 0\\) we will have two equilibria, when \\(\\rho = 0\\) a single equilibrium \\(x^\\star = 0\\), and that when \\(\\rho &gt; 0\\) no (real) equilibrium exists. As such, the shape of the diagrams we have sketched above depend on \\(\\rho\\). For example, when \\(\\rho = -4\\), we have: The equilibrium on the left is stable, while the one on the right is unstable. The graph is qualitatively the same for any \\(\\rho &lt; 0\\). When \\(\\rho = 0\\), however, the two equilibria “collide”, and merge into the single “half-stable” equilibrium: The equilibrium \\(x^\\star = 0\\) is stable if we approach it from the left, while unstable if we are reaching it from the right. When we cross the bifurcation \\(\\rho_c = 0\\), the equilibrium disappears altogether, leading to unbounded growth: We can summarize the behavior of the system for different values of \\(\\rho\\) in a bifurcation diagram: on the x-axis we have the parameter we are varying (in this case, \\(\\rho\\)), and on the y-axis we report \\(x(t)\\), marking the position of all the equilibria, with a solid line indicating stable equilibria and a dashed line the unstable ones: Note that the rate at which the system approaches (moves away from) the stable (unstable) equilibrium depends on \\(\\rho\\). When \\(\\rho \\ll 0\\) the system moves fast, while when \\(\\rho \\to \\rho_c = 0\\) the system moves more slowly. This phenomenon is called “critical slowing down” and has been proposed as a generic indicator that a system is approaching a bifurcation point. Homework 1b Draw the bifurcation diagram for logistic growth model with harvesting: \\[ \\dfrac{d x(t)}{dt} = \\rho\\, x(t) (1 - \\alpha\\, x(t)) - \\eta\\, x(t) \\] where \\(1 &gt; \\eta &gt; 0\\) is the proportion of individuals being harvested. Details take \\(\\rho = 1\\), \\(\\alpha = 1\\) and vary \\(\\eta\\) between 0 and 1. write code to solve the initial value problem from a random initial condition \\(x(0) \\sim \\mathcal U[0, 2]\\) (i.e., sampled independently from a uniform distribution between 0 and 2); document the possible outcomes. write code to plot the bifurcation diagram—for each value of \\(\\eta\\), mark stable and unstable equilibria. what is the critical \\(\\eta_c\\) where a bifurcation occurs? A few interesting references on detecting the approaching of a bifurcation in experimental systems: Key paper: Scheffer et al. (2009) Starting in the early 2000s, much work went into trying to anticipate dramatic changes in natural and man-made systems (e.g., lakes turning eutrophic, fisheries collapsing). In this review, Scheffer et al. summarize previous work and present an accessible introduction to the problem. Key paper: Dai et al. (2012) Dai et al. grew populations of Saccharomyces cerevisiae on sucrose. Because sucrose is split outside the cell, it creates an Allee effect: when the population density is high, it is energetically convenient to produce the enzyme to spit the sucrose, as the different cells pool their efforts; when population density is low, the gain is not sufficient to balance the cost. By tuning the mortality (dilution), they were able to experimentally recreate the bifurcation diagram of the exercise above. The data from the experiments are here. 1.7 Long term behavior of 1-D systems First-order (i.e., single-equation) ODEs can produce a very limited variety of long-terms behaviors: for \\(t \\to \\infty\\) we can only have \\(x(t) \\to \\pm \\infty\\) or \\(x(t) \\to x^\\star\\). For population models, this means that either growth is unbounded (e.g., exponential growth model), or the population will reach an equilibrium point (possibly, out of many). This is a direct consequence of the uniqueness of trajectories: because we are moving in a 1-dimensional space, the fact that trajectories cannot cross means that if we are at a certain point \\(x(t) = x_t\\), then either \\(dx(t)/dt &gt;0\\), \\(dx(t)/dt &lt;0\\), or \\(dx(t)/dt =0\\), but can take only one value, preventing more complex behaviors such as cycles or chaos. For smooth functions and autonomous systems, one needs at least two equations to produce cycles and three equations to produce chaos. This is in stark contrast with difference equations—a single, innocent-looking difference equation can give rise to all sorts of dynamics. Key paper: May (1976) May takes a possible model for the logistic growth in discrete time, and shows how this very simple model can give rise to equilibria, cycles and chaos. This is one of the papers that launched an all-out effort to explore chaotic dynamics that lasted for the best part of the 1980s. 1.8 Lyapunov functions While in many cases we cannot write an explicit solution for a (system of) differential equation(s), we might be able to determine the stability of equilibria and their basin of attraction (i.e., the set of initial conditions eventually leading to the equilibrium \\(x^\\star\\)) by considering functions that change monotonically through the dynamics. Suppose that \\(\\dfrac{d x(t)}{dt} =f(x(t))\\), and that \\(x^\\star\\) is an equilibrium. Let \\(V(x)\\) be a function defined in an open set \\(\\mathcal O\\) containing \\(x^\\star\\), such that a) \\(V(x^\\star) = 0\\) and \\(V(x) &gt; 0\\) for any \\(x \\neq x^\\star\\), and b) \\(d V /dt \\leq 0\\) for all \\(x \\in \\mathcal O - x^\\star\\). Then \\(V\\) is a Lyapunov function for the model, and \\(x^\\star\\) is stable. The Lyapunov function is called strict, and the equilibrium \\(x^\\star\\) asymptotically stable if \\(d V /dt &lt; 0\\). While Lyapunov functions are great, because we can prove stability without the need to solve the system, there is no general rule to construct such a function. Often, “candidate” Lyapunov functions are available, but the process of finding the right function typically requires a lot of ingenuity and trial and errors. Fortunately, for system with a single state a quadratic function is guaranteed to solve the problem. Take the model for logistic growth (with \\(\\rho &gt; 0\\) and \\(\\alpha &gt; 0\\), and the candidate Lyapunov function: \\[ V(x(t)) = (x(t) - x^\\star)^2 \\] with \\(x^\\star = 1 / \\alpha\\). The function is positive for any \\(x(t) \\neq x^\\star\\). Next, we derive with respect to \\(t\\): \\[ \\dfrac{d V(x(t))}{d t} = \\dfrac{d V(x(t))}{d x(t)}\\dfrac{d x(t)}{d t} = 2 \\left(x(t) - \\dfrac{1}{\\alpha}\\right)\\rho\\, x(t) (1 - \\alpha\\, x(t)) \\] The derivative is negative whenever \\(x(t) &gt; 0\\) and \\(x(t) \\neq x^\\star\\): \\[ \\dfrac{d V(x(t))}{d t} = 2 \\rho\\, x(t) \\left(x(t) - \\dfrac{1}{\\alpha}\\right) (1 - \\alpha\\, x(t))= -\\dfrac{\\rho\\, x(t)}{\\alpha}\\left(x(t) - \\dfrac{1}{\\alpha}\\right)^2 \\] and as such \\(x^\\star\\) is asymptotically stable. The basin of attraction (i.e., where the Lyapunov function has the desired properties) is \\(x \\in \\mathbb{R}_+\\). There can be several alternative Lyapunov functions. For example, consider: \\[ V(x(t)) = x(t) - x^\\star - x^\\star \\log \\dfrac{x(t)}{x^\\star} \\] which is positive for \\(x(t) &gt; 0\\) and \\(x(t) \\neq x^\\star\\), taking the derivative w.r.t. time, we find: \\[ \\dfrac{d V(x(t))}{d t} = \\left(1 - \\dfrac{x^\\star}{x(t)}\\right)\\rho\\, x(t) (1 - \\alpha\\, x(t)) = -\\rho\\, x^\\star (x(t) - x^\\star)^2 \\] which again is negative whenever \\(x^\\star &gt; 0\\), \\(\\rho &gt;0\\) and \\(x(t) \\neq x^\\star\\). References "],
["models-for-two-populations.html", "Lecture 2 Models for two populations 2.1 Qualitative analysis of models for two populations 2.2 Local stability analysis 2.3 Stability analysis of the Lotka-Volterra Predator-Prey model", " Lecture 2 Models for two populations Lesson plan: We discuss the concepts introduced in the previous chapter in the context of two-dimensional (“planar”) systems of differential equation. We summarize important concepts from linear algebra: eigenvalues and eigenvectors, the matrix exponential. We show how these concepts can be used to solve linear systems of differential equations. We introduce the “community matrix”, allowing us to determine the local asymptotic stability of equilibria. We analyze in detail the classic Lotka-Volterra predator-prey model, and a version of the model in which the prey grows logistically. 2.1 Qualitative analysis of models for two populations In this section, we extend the qualitative analysis we’ve performed for a single populations to models with two populations. Many of the methods introduced below extend to the case of multiple populations. 2.1.1 Isoclines of null growth Take a two-dimensional model. For each equation, we can write the solution of \\(dx/dt = 0\\) as a function of \\(y\\), thereby defining the curve in the \\((x, y)\\) plane (the “phase plane”) for which the growth of species \\(x\\) is zero. For a concrete example, take the classic predator-prey Lotka-Volterra system: \\[ \\begin{cases} \\dfrac{d x(t)}{dt} = \\rho\\, x(t) - \\alpha\\, x(t)\\, y(t)\\\\ \\dfrac{d y(t)}{dt} = -\\delta\\, y(t) + \\beta\\, x(t)\\, y(t) \\end{cases} \\] where \\(x(t)\\) is the density of the prey species at time \\(t\\) and \\(y(t)\\) that of the predator. We can interpret \\(\\rho\\) as the intrinsic growth rate of the prey (i.e., the growth when the predator is absent), \\(\\delta\\) as the death rate of the predator, and \\(\\alpha\\) and \\(\\beta\\) as the loss of (gain in) growth due to predation. History: Alfred J. Lotka (1880-1949) Alfred Lotka was born to French-speaking American parents in Lemberg (then part of the Habsburg empire, now Lviv, Ukraine). He studied in France, Germany and England, receiving a BSc in 1901 and a DSc in 1912 from Birmingham university. He moved to the US in 1902, and worked at the US Patent office, as an editor of Scientific American, and as a statistician at the Metropolitan Life Insturance Company in NYC. He wrote more than a hundred papers and five books, spanning a large range of topics. He’s best known for the book Elements of Physical Biology, his contributions to demography, and one of the first studies dealing with bibliometrics (Lotka 1926). Starting in 1910 (reprinted as Lotka (2002)) he investigated coupled differential equations relating to chemical as well as ecological dynamics. In Lotka (1920) he studied a system of two ODEs that gave rise to perpetual oscillations: “It was, therefore, with considerable surprise that the writer, on applying his method to certain special cases, found these to lead to undamped, and hence indefinitely continued, oscillations.” He went on to describe “1. A species of organism \\(S_1\\), a plant species, say, deriving its nourishment from a source presented in such large excess that the mass of the source may be considered constant during the period of time with which we are concerned. 2. A species \\(S_2\\), for example a herbivorous animal species, feeding on \\(S_1\\).” The equations he had derived (and then studied later in more detail) are now termed Lotka-Volterra equations. Let’s look at a possible trajectory for the system, to gain an intuition of what can happen: You can see that the population densities, when drawn in the “phase plane” cycle counterclockwise. Let’s try to understand why. The equation for the prey is zero either when \\(x(t) = 0\\) or when \\(\\rho - \\alpha\\,y(t) = 0\\), yielding \\(y(t) = \\rho / \\alpha\\). Whenever the density of the predator \\(y(t) &lt; \\rho / \\alpha\\), prey will grow; conversely, whenever \\(y(t) &gt; \\rho / \\alpha\\), prey will decline. Graphically: Similarly, the equation for the predator is zero either when \\(y(t) = 0\\) or when \\(-\\delta + \\beta\\, x(t) = 0\\), yielding \\(x(t) = \\delta / \\beta\\). Whenever the density of the prey \\(x(t) &lt; \\delta / \\beta\\), predators will decline; conversely, whenever \\(x(t) &gt; x(t) = \\delta / \\beta\\), predators will grow. Graphically: Now let’s put the two graphs together: Clearly, a possible equilibrium of the system is \\((x^\\star, y^\\star)^T = (0, 0)^T\\) (often called the “trivial” equilibrium). You can see that there is another equilibrium where the two isoclines meet \\((x^\\star, y^\\star)^T = (\\delta / \\beta, \\rho / \\alpha)^T\\), and that the dynamics will tend to cycle around the equilibrium. But how do we know whether dynamics will cycle toward the equilibrium, spiral away from it, or describe closed orbits? To answer this question, we can try to extend our linear analysis by Taylor-expanding the dynamics around the equilibrium. 2.2 Local stability analysis Suppose that a feasible (i.e., positive) equilibrium \\(x^\\star\\) exists for a given model. Then we can ask whether it is attractive, i.e. if trajectories started at initial condition \\(x(0)\\) will eventually reach \\(x^\\star\\). This problem is in general difficult to solve (but see below); as an alternative, we can test for local asymptotic stability, i.e., ask whether the system will return to the equilibrium if perturbed infinitesimally away from it. In general, whenever we describe an ecological community as a system of nonlinear, autonomous ODEs: \\[ \\frac{d x_i (t)}{d t} = f_i (x(t)) \\;, \\] we define an equilibrium \\(x^\\star\\) as a vector of densities such that: \\[ \\left. \\frac{d x_i}{d t} \\right|_{{x}^\\star} = f_i ({x}^\\star) = 0 \\quad \\forall i \\] A given system might have a multitude of equilibria. When the system is resting at an equilibrium point, it will remain there unless it is perturbed away from it. Local stability analysis is a method to probe whether a system that is perturbed infinitesimally away from an equilibrium will eventually return to it, or rather move away from it. Taylor series Single-variable: suppose function \\(f\\) infinitely differentiable around a point \\(x = a\\). Then \\[ f(x) = \\sum_{k = 0}^\\infty \\dfrac{D^{k} f(a)}{k!} (x-a)^k = f(a) + \\left. \\dfrac{d f}{d x} \\right|_{a} (x-a)+ \\dfrac{1}{2}\\left. \\dfrac{d^2 f}{d x^2} \\right|_{a} (x-a)^2 + \\cdots \\] where \\(D^{k} f(a)\\) is the \\(k\\)-th derivative of \\(f(x)\\) w.r.t. \\(x\\), evaluated at \\(a\\). Vector-valued functions: now \\(f(x)\\) is a vector-valued function, and \\(x\\) a vector. To expand around the point \\(a\\), we need to define the Jacobian matrix \\[ J = Df(x) \\] with elements: \\[ J_{ij} = \\dfrac{\\partial f_i({x})}{\\partial x_j} \\] Next, we define the Hessian tensor (in this case, a three-dimensional tensor): \\[ H_{ijk} = \\dfrac{\\partial^2 f_i(x)}{\\partial x_j\\, \\partial x_k} \\] It is convenient to write the Taylor expansion in component form: \\[ f_i(x) \\approx f_i(a) + \\sum_j \\left . J_{ij} \\right|_{a} (x_j - a_j) +\\dfrac{1}{2} \\sum_j \\sum_k \\left. H_{ijk} \\right|_a (x_j-a_j)(x_k-a_k) \\] Example Consider the vector-valued function: \\[ f(x) = \\begin{pmatrix} x_1^3 + 2 x_2^2\\\\ x_1 - x_2^3 \\end{pmatrix} \\] Approximate the function around a generic point \\(a = (a_1,a_2)^T\\). The Jacobian is: \\[ J = \\begin{pmatrix} 3 x_1^2 &amp; 4 x_2\\\\ 1 &amp; -3 x_2^2 \\end{pmatrix} \\] and the two slices of the Hessian tensor are: \\[ H_1 = \\begin{pmatrix} 6 x_1 &amp; 0 \\\\ 0 &amp; 4 \\end{pmatrix} \\] and \\[ H_2 = \\begin{pmatrix} 0 &amp; 0 \\\\ 0 &amp; -6 x_2 \\end{pmatrix} \\] as such: \\[ f(x) \\approx \\begin{pmatrix} a_1^3 + 2a_2^2 + 3 a_1^2 (x_1 - a_1)+ 4 a_2 (x_2-a_2) + 3 a_1 (x1-a_1)^2 + 2 (x_2 - a2)^2\\\\ a_1 - a_2^3+x_1-a_1-3 a_2^2 (x_2-a_2)-3 a_2 (x_2 - a_2)^2 \\end{pmatrix} \\] For example, expanding around \\(a = (0, 0)^T\\), we obtain: \\[ f(x) \\approx \\begin{pmatrix} 2 x_2^2\\\\ x_1 \\end{pmatrix} \\] while around \\(a = (2, 1)^T\\), we find: \\[ f(x) \\approx \\begin{pmatrix} 2 (x_2^2 + 3 x_1 (x_1-2) + 4)\\\\ x_1 + 3 x_2(x_2 - 3) + 5 \\end{pmatrix} \\] Note that considering the first two terms of the Taylor expansion results in second-degree polynomials; adding a cubic terms would in general yield a better approximation, etc. Suppose that a system is resting at an equilibrium \\(x^\\star\\), and that it is slightly perturbed away from it. \\(\\Delta x(0) = x(0)-x^\\star\\) is the state of the system immediately after the perturbation. Taylor-expanding around \\(x^\\star\\) and taking only the linear term, we have: \\[ f(\\Delta x(0)) = f(x^\\star)+ \\left. J \\right|_{x^\\star} \\Delta x(0) = \\left. J \\right|_{x^\\star} \\Delta x(0) \\] Where \\(J\\) is the Jacobian matrix of the system, whose elements are defined as: \\[ J_{ij} = \\frac{\\partial f_i({x})}{\\partial x_j} \\] Each element of this matrix is therefore a function, whose value depends on \\(x\\). When we evaluate the Jacobian matrix at an equilibrium point \\(x^\\star\\), we obtain the so-called “community matrix” \\(M\\): \\[ M = \\left. {J} \\right|_{ {x}^\\star} \\] Note that, although each system has a unique Jacobian matrix, there are as many community matrices as there are equilibria. The community matrix details the effect of increasing the density of one species on any other species around the equilibrium point. We can therefore write the differential equation: \\[ \\frac{d \\Delta x(t)}{dt} \\approx M \\Delta x(t) \\] which is a system of linear differential equations—i.e., the simplest system of ODEs, which can be solved in full generality. To solve the system, we need to recap a few important concepts from linear algebra. Eigenvalues and eigenvectors For a matrix \\(M\\), we have that if \\(M v = \\lambda v\\) with \\(v\\) different from the zero vector, then \\(\\lambda\\) is an eigenvalue and \\(v\\) the corresponding eigenvector. Practically, you can think of a matrix as an operator that turns a vector into another vector. If the resulting vector is a rescaled version of the initial vector, then you’ve found an eigenvector of the matrix, and the rescaling factor is the associated eigenvalue. For example, show that \\((1, 1)^t\\) is an eigenvector of the matrix: \\[ A = \\begin{pmatrix} 1 + a &amp; 1-a\\\\ 2a + 2 &amp; -2a \\end{pmatrix} \\] We have: \\[ Av = \\begin{pmatrix} (1 + a) v_1 + (1-a) v_2\\\\ (2a + 2) v_1 - 2a v_2 \\end{pmatrix} \\] if \\(v = (1, 1)^t\\), we have: \\[ Av = \\begin{pmatrix} 2\\\\ 2 \\end{pmatrix} = 2\\, v \\] and as such \\(v\\) is an eigenvector of \\(M\\), with associated eigenvalue \\(\\lambda = 2\\). Finding eigenvalues The eigenvalues of a matrix \\(M\\) are the roots (zeros) of the chacteristic polynomial: \\[ p(\\lambda) = \\det(\\lambda I - M) = 0 \\] Where does this equation come from? We write: \\[ \\begin{aligned} A v = \\lambda v\\\\ \\lambda v - Av = 0\\\\ (\\lambda I - A)v = 0 \\end{aligned} \\] if \\(v\\) is nonzero, then the matrix \\(\\lambda I - A\\) must be singular (i.e., have at least one eigenvalue equal to zero). Because the determinant is the product of the eigenvalues, then the determinant must also be zero. For a \\(2 \\times 2\\) matrix, we have: \\[ \\begin{aligned} \\det \\begin{pmatrix} \\lambda - a_{11} &amp; -a_{12}\\\\ -a_{21} &amp; \\lambda -a_{22} \\end{pmatrix} &amp;= (\\lambda - a_{11}) (\\lambda - a_{22}) - a_{12} a_{21}\\\\ &amp;= \\lambda^2 - \\lambda (a_{11} + a_{22}) + a_{11} a_{22} - a_{12} a_{21} \\end{aligned} \\] More compactly, \\[ p(\\lambda) = \\lambda^2 - \\lambda\\, \\text{tr}(A) + \\det(A) \\] where \\(\\text{tr}(M) = \\sum_i M_{ii} = \\sum_i \\lambda_i\\), and \\(\\det(M) = \\prod_i \\lambda_i\\). We therefore find: \\[ \\lambda = \\frac{\\text{tr}(M) \\pm \\sqrt{(\\text{tr}(M))^2 - 4 \\det(M)}}{2} \\] Find the eigenvalues for the matrix \\(A\\) above: \\[ \\begin{aligned} \\lambda &amp;= \\frac{1-a \\pm \\sqrt{(1-a)^2+8(1+a)}}{2}\\\\ &amp;= \\frac{1-a \\pm \\sqrt{(1+a^2 -2 a + 8 a + 8)}}{2} \\\\ &amp;= \\frac{1-a \\pm (a+ 3)}{2} \\end{aligned} \\] The eigenvalues are therefore \\(\\lambda_1 = 2\\) and \\(\\lambda_2 = -(1+a)\\). Facts about eigenvalues and eigenvectors Given a matrix \\(A\\), of size \\(n \\times n\\), a complex number \\(\\lambda\\) is an eigenvalue of \\(A\\) if there is a nonzero (complex) vector \\(v\\) such that \\(A v = \\lambda v\\). The vector \\(v\\) is called the eigenvector of \\(A\\) associated with \\(\\lambda\\). Note that eigenvectors are defined up to multiplication: if \\(v\\) is an eigenvector, then \\(\\alpha\\, v\\), with \\(\\alpha\\) real is also an eigenvector. Often, we choose \\(v\\) such that its norm \\(\\sqrt{\\sum_i v_i^2} = 1\\) (called “unit” eigenvector). A matrix of size \\(n\\) has at most \\(n\\) distinct eigenvalues. If all eigenvalues are distinct then the eigenvectors are linearly independent. This means that if we build the matrix \\(V = (v_1, v_2, \\ldots, v_n)\\), then \\(V\\) is invertible. Because of the fact above, and diagonalizable matrix (e.g., a sufficient condition is to have all eigenvalues distinct), then we can write: \\[ A = V \\Lambda V^{-1} \\] where \\(V\\) is the matrix of eigenvectors, and \\(\\Lambda\\) a diagonal matrix with the eigenvalues of \\(A\\) on the diagonal. As such, \\(V^{-1} A V = \\Lambda\\). This is a “similarity transformation”, meaning that the eigenvalues of \\(A\\) and \\(\\Lambda\\) are (obviously) the same. If the matrix \\(A\\) contains only real numbers (as always the case in population models), then the eigenvalues of \\(A\\) are either real, or form pairs of complex conjugate eigenvalues of form \\(\\alpha \\pm i\\, \\beta\\). This means for example that all odd-sized real matrices have at least one real eigenvalue. If \\(A\\) is real and symmetric, all eigenvalues are real, and all eigenvectors are orthogonal, and if it is diagonalizable we can write \\(A = V \\Lambda V^{T}\\). A diagonal matrix \\(A\\) has eigenvalues \\(\\lambda_i = A_{ii}\\) If \\(A\\) has eigenvalues \\(\\lambda\\), \\(B = \\beta\\, A\\) has eigenvalues \\(\\beta\\, \\lambda\\), and \\(C = A + \\gamma\\, I\\) has eigenvalues \\(\\lambda + \\gamma\\). The eigenvalues of \\(A^2 = A \\times A\\) are \\(\\lambda^2\\), and the eigenvalues of \\(A^{-1}\\) are \\(\\lambda^{-1}\\). The eigenvalues of \\(A^T\\) are the same as those of \\(A\\) (but the eigenvectors are not the same in general). \\(A + A^T\\) (this matrix is symmetric) has only real eigenvalues, and \\(A - A^T\\) (this matrix is skew-symmetric) has purely imaginary eigenvalues. A matrix is positive definite if all its eigenvalues are real and positive. It is positive semi-definite if eigenvalues can be zero. The matrices \\(AA^T\\) and \\(A^T A\\) are positive semi-definite, and have the same eigenvalues up to some zeros (used in SVD and PCA). Correlation and covariance matrices have these form. Provided that some mild conditions are satisfied, a matrix with non-negative entries has a unique largest real eigenvalue with a corresponding eigenvector that can be chosen to have strictly positive components (Perron-Frobenius theorem). A matrix with constant row sums \\(\\theta\\) has \\(\\theta\\) as the largest eigenvalue, and \\(v = 1\\) as the corresponding eigenvector (e.g., Markov Chains). Homework 2a Show that a matrix \\(A\\) with sign-pattern: \\[ S(A) = \\begin{pmatrix} - &amp; +\\\\ - &amp; 0 \\end{pmatrix} \\] has eigenvalues with negative real part. When a matrix is stable due to its sign-pattern (rather than specific values of the coefficients), it is called qualitatively stable. Key paper: May (1973) The idea of “sign-stability” was first introduced in economics. May borrowed the idea to analyze simple food webs. Analysis of ecological models based on sign (rather than magnitude) of coefficients was further developed by Richard Levins and collaborators. A good modern summary, along with a few new results, are provided by Dambacher et al. (2003). We can now analyze systems of linear ODEs. Solution of linear systems of ODEs Matrix exponential In analogy with the power series \\[ e^x = \\sum_{n=0}^{\\infty} \\dfrac{x^n}{n!} = 1 + x + \\dfrac{x^2}{2} + \\dfrac{x^3}{6} + \\dfrac{x^4}{24} + \\ldots \\] we define the matrix exponential \\[ e^X = \\sum_{n=0}^{\\infty} \\dfrac{1}{n!}X^n = I + X + \\dfrac{1}{2}X^2 + \\dfrac{1}{6}X^3 + \\dfrac{1}{24}X^4 + \\ldots \\] where \\(X^2 = X \\times X\\) and so on. Solution of systems of linear ODEs This allows us to solve the system of linear differential equations \\[ \\dfrac{d x(t)}{dt} = A x(t) \\] with \\(x(0) = x_0\\). When the determinant of \\(A\\), \\(\\det A \\neq 0\\), the only equilibrium of the system is \\(x^\\star = 0\\). If \\(\\det A = 0\\) (and \\(A \\neq 0\\)), on the other hand, there are infinitely many equilibria, all belonging to the same line (in 2-d). By writing the solution we can determine whether trajectories will approach or move away from an equilibrium. We write the solution as: \\[ x(t) = e^{A t} x_0 \\] Importantly, we have that, if \\(A\\) is diagonalizable, \\[ e^{A t} = V e^{\\Lambda t}V^{-1} \\] where \\(\\Lambda\\) is the diagonal matrix containing the eigenvalues of \\(A\\). Because \\(\\Lambda\\) is diagonal, we can solve the exponential explicitly: \\[ e^{\\Lambda t} = \\begin{pmatrix}e^{\\lambda_{1}t} &amp; 0 &amp; \\ldots &amp; 0\\\\0&amp; e^{\\lambda_{2}t} &amp; \\ldots &amp; 0\\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\0&amp; 0&amp; \\ldots &amp; e^{\\lambda_{n}t} \\end{pmatrix} \\] Now we want to study the dynamics of the system. To keep the complexity to a minimum, we define \\(y(t) = V^{-1} x(t)\\), meaning that we are choosing the most appropriate coordinates to study our trajectories. Our equation becomes: \\[ \\begin{aligned} x(t) &amp;= V e^{\\Lambda t} V^{-1} x_0\\\\ V^{-1}x(t) &amp;= V^{-1}V e^{\\Lambda t} V^{-1} x_0\\\\ y(t) = e^{\\Lambda t} y_0 \\end{aligned} \\] And therefore \\(y_j(t) = e^{(\\lambda_j)t} y_j(0)\\). Clealry, if all \\(\\lambda_j\\) are real and negative, the trajectories will die out, and the origin \\(y^\\star = 0\\) is stable. Similarly, if any eigenvalue is real and positive, then the perturbation will amplify in at least one direction. Next, we consider \\(\\lambda_j\\) to be complex. In this case, \\(\\lambda_j = \\alpha + i\\, \\beta\\). Using Euler’s formula, we have \\[ y_j(t) = y_j(0)\\, e^{(\\alpha + i\\, \\beta) t} = y_j(0)\\, e^{\\alpha\\, t} (\\cos(\\beta\\, t) + i \\sin(\\beta\\, t)) \\] As such, the solution will oscillate, with damped oscillations whenever \\(a &lt; 0\\) and increasing oscillations when \\(a &gt; 0\\). For example, a case of damped oscillations: and of increasing oscillations: In fact, all the possible trajectories in planar systems can be classified using only the determinant (product of eigenvalues) and the trace (sum of the eigenvalues) of the matrix \\(A\\): Now we can solve the system of ODEs: \\[ \\frac{d \\Delta x(t)}{dt} \\approx M \\Delta x(t) \\] obtaining: \\[ \\Delta x(t) = \\Delta x(0) e^{Mt} = \\Delta x(0) Q e^{\\Lambda t} Q^{-1} \\] Where \\(Q\\) is the matrix containing the (unit) eigenvectors of \\(M\\), and \\(\\Lambda\\) is a diagonal matrix containing the eigenvalues of \\(M\\). As such, the eigenvalues of \\(M\\) determine the stability of the equilibrium \\({x}^\\star\\): if all the eigenvalues have negative real part, then the system will eventually return to the equilibrium after sufficiently small perturbations; conversely, if any of the eigenvalues have positive real part, the system will move away from the equilibrium whenever perturbed. Therefore, depending on the sign of the “rightmost” eigenvalue of \\({M}\\), \\(\\lambda_1\\), we can determine the stability of \\({x}^\\star\\): \\[ \\text{Re}(\\lambda_1) \\begin{cases} &lt; 0 \\to {x}^\\star \\quad \\text{is stable}\\\\ &gt; 0 \\to {x}^\\star \\quad \\text{is unstable} \\end{cases} \\] 2.3 Stability analysis of the Lotka-Volterra Predator-Prey model We still haven’t figured out whether the coexistence equilibrium for the model \\[ \\begin{cases} \\dfrac{d x(t)}{dt} = \\rho\\, x(t) - \\alpha\\, x(t)\\, y(t)\\\\ \\dfrac{d y(t)}{dt} = -\\delta\\, y(t) + \\beta\\, x(t)\\, y(t) \\end{cases} \\] is stable or not. The Jacobian becomes: \\[ J = \\begin{pmatrix} \\rho - \\alpha\\, y &amp; -\\alpha\\, x\\\\ \\beta\\, y &amp; -\\delta + \\beta\\, x \\end{pmatrix} \\] The community matrix for the equilibrium \\((x^\\star, y^\\star)^T = (0, 0)^T\\) is: \\[ M_0 = \\left . J \\right|_{(0, 0)^T} = \\begin{pmatrix} \\rho &amp; 0\\\\ 0 &amp; -\\delta \\end{pmatrix} \\] which has eigenvalues \\(\\rho &gt; 0\\) amd \\(-\\delta &lt; 0\\) — the equilibrium is unstable. The coexistence equilibrium \\((x^\\star, y^\\star)^T = (\\delta / \\beta, \\rho / \\alpha)^T\\) yields the community matrix: \\[ M_c = \\left . J \\right|_{(\\delta / \\beta, \\rho / \\alpha)^T} = \\begin{pmatrix} 0 &amp; \\dfrac{\\alpha\\, \\delta}{\\beta} \\\\ -\\dfrac{\\beta\\, \\rho}{\\alpha} &amp; 0 \\end{pmatrix} \\] which has purely imaginary eigenvalues \\(\\lambda = \\pm i \\sqrt{\\rho \\, \\delta}\\). As such the equilibrium is not attractive nor unstable. In fact, Lotka and Volterra were (independently) able to prove that the system cycles neutrally around the equilibrium. Vito Volterra (1860-1940) Vito Volterra was born in Ancona (then part of the Papal State) in a poor jewish family. The financial situation precipitated with the death of his father, when Vito was two. Vito and his mother went to live with relatives in Turin and then Florence. Volterra showed amazing mathematical talent at a very young age. Antonio Roiti, professor of physics in Florence, noticed the budding mathematician and hired him as his assistant, so that he could continue his studies. He went on to enroll at the Scuola Normale in Pisa, receiving a degree in Physics in 1882. At age 23 he was made full professor of Rational Mechanics in Pisa, and then in 1900 of Mathematical Physics in Rome. For thirty years, he contributed important studies in mathematics, and enriched academic life in Italy (for example, he was the first director of the National Center for Research). In 1931 he refused to take an oath of loyalty to the fascist regime (only 12 professors out of 1250 refused), and was therefore forced to resign (his take on the fascist enterprise: “Empires die, but Euclid’s theorems keep their youth forever”). His interest in mathematical ecology is due to Umberto D’Ancona (his son-in-law), who had studied the trends in fisheries in the Adriatic sea before and immediately after WWI. In 1914-1918 fisheries in the Adriatic had stopped completely because of the conflict. D’Ancona had noticed that, while herbivorous fish had remained about constant, the piscivorous fish had increased dramatically in numbers. The problem piqued Volterra who immediately published a sophisticated study, proposing the same equations studied by Lotka. In a short letter to Nature (Volterra 1926a), he stated the so-called “Volterra’s Effect” (which he termed “Law III”): “a complete closure of the fishery was a form of ‘protection’ under which the voracious fishes were much the better and prospered accordingly, but the ordinary food-fishes, on which these are accustomed to prey, were worse off than before.” This brief paper was a summary of a much more extensive article (Volterra 1926b). Lotka-Volterra interactions In 1927, Lotka wrote to Nature to raise the issue that the equations studied by Volterra and the figures presented in Volterra’s brief article were identical to those found in Elements of Physical Biology (published in 1925). He concluded: “It would be gratifying if Prof. Volterra’s publication should direct attention to a field and method of inquiry which apparently has hitherto passed almost unnoticed.” Volterra graciously conceded “I recognize his priority, and am sorry not to have known his work, and therefore not have been able to mention it.” He however listed a few points in which the two authors had pursued different directions, and concluded “Working independently the one from the other, we have found some common results, and this confirms the exactitude and the interest in the position of the problem. I agree with him in his conclusions that these studies and these methods of research deserve to receive greated attention from scholars, and should give rise to important applications.” 2.3.1 Constant of motion for Lotka-Volterra Predator-Prey Volterra wrote: \\[ \\dfrac{d x(t)}{d y(t)} = \\dfrac{\\rho\\, x(t) - \\alpha\\, x(t)\\, y(t)}{-\\delta\\, y(t) + \\beta\\, x(t)\\, y(t)} \\] As such: \\[ (-\\delta\\, y + \\beta\\, x\\, y)\\, d x = (\\rho\\, x - \\alpha\\, x\\, y)\\, d y \\] dividing both sides by \\(x\\, y\\), we obtain: \\[ \\left(-\\dfrac{\\delta}{x} + \\beta \\right)\\, d x = \\left(\\dfrac{\\rho}{y} - \\alpha \\right)\\, d y \\] Integrating both sides: \\[ \\beta\\, x - \\delta\\, \\log x = - \\alpha\\, y + \\rho\\, \\log y + C \\] where \\(C\\) is a constant of integration. Rearranging, and substituting \\(x^\\star = \\delta / \\beta\\) and \\(y^\\star = \\rho / \\alpha\\), we obtain: \\[ \\beta (x - x^\\star \\log x) + \\alpha (y - y^\\star \\log y) = C \\] This means that the system has a constant of motion (a.k.a. “first integral”): the value of \\(C\\) depends on the initial conditions, and then the system will cycle around the equilibrium in closed orbits. Note that a) \\(C&gt;0\\) if the initial conditions are different from the equilibrium; b) \\(C = C_m &gt; 0\\) if we are at equilibrium; and therefore c) \\(C \\geq C_m\\) for all (positive) initial conditions. We can use \\(C\\) as a Lyapunov function: \\[ V(x,y) = \\beta (x - x^\\star \\log x) + \\alpha (y - y^\\star \\log y) \\] \\[ \\dfrac{d V(x,y)}{dt} = \\left(\\beta - \\dfrac{\\delta}{x} \\right) \\dfrac{dx}{dt}+\\left(\\alpha - \\dfrac{\\rho}{y} \\right) \\dfrac{dy}{dt} = 0 \\] As such, the dynamics are such that \\(V(x,y)\\) remains constant. 2.3.2 Analysis of Predator-Prey model with logistic growth for the prey In the classic Lotka-Volterra model, the local stability analysis of the coexistence equilibrium is inconclusive. When however the prey grows logistically it is easy to show that the equilibrium is now stable. For example, consider the system \\[ \\begin{cases} \\dfrac{dx}{dt} = x (1 - x/2 -y)\\\\ \\dfrac{dy}{dt} = y (x - 1) \\end{cases} \\] First, we find the equilibria. From the first equation, we have \\(x^\\star = 0\\), or \\(y^\\star = 1 - x^\\star /2\\); from the second equation, we have \\(y^\\star = 0\\) or \\(x^\\star = 1\\). Combining them, we find that either \\((x^\\star, y^\\star) = (0, 0)\\) (trival), \\((x^\\star, y^\\star) = (2, 0)\\) (boundary), or \\((x^\\star, y^\\star) = (1, 1/2)\\) (coexistence). The isoclines of zero growth are \\(y = 1 - x/2\\) for the prey, and \\(x = 1\\) for the predator. The Jacobian for the system is \\[ J = \\begin{pmatrix} 1 - x - y &amp; -x\\\\ y &amp; x -1 \\end{pmatrix} \\] At the equilibrium \\((x^\\star, y^\\star) = (1, 1/2)\\), we have: \\[ M = \\begin{pmatrix} - \\frac{1}{2} &amp; -1\\\\ \\frac{1}{2} &amp; 0 \\end{pmatrix} \\] The trace is \\(-1/2\\) and the determinant \\(1/2\\), as such the equilibrium is stable. The eigenvalues are given by: \\[ p(\\lambda) = \\lambda^2 + \\frac{1}{2} \\lambda + \\frac{1}{2} \\] Obtaining: \\[ \\lambda = \\dfrac{-\\frac{1}{2} \\pm \\sqrt{\\frac{1}{4} - 2}}{2} = \\dfrac{-1 \\pm i \\sqrt{7}}{4} \\] And as such small perturbations will oscillate back to equilibrium. Numerically: 2.3.2.1 Global stability We can write a Lyapunov function for the system above. Take: \\[ V(x,y) = \\left(x - x^\\star - x^\\star \\log \\dfrac{x}{x^\\star} \\right) + \\left(y - y^\\star - y^\\star \\log \\dfrac{y}{y^\\star} \\right) = (x - 1 - \\log x) + \\left(y - \\dfrac{1}{2} - \\dfrac{1}{2} \\log 2y \\right) \\] Derive with respect to time to obtain: \\[ \\dfrac{d V(x,y)}{dt} = -\\dfrac{1}{2}(1-x)^2 &lt; 0 \\] As such, the equilibrium \\((x^\\star, y^\\star) = (1, 1/2)\\) is globally stable. Homework 2b Take the competitive Lotka-Volterra model: \\[ \\dfrac{dx}{dt} = D(x) (r - Ax) \\] with the coefficients of \\(r = (r_1, r_2)^T\\) and \\(A\\) all positive. Discuss the existence of a coexistence equilibrium and its stability. Write a Lyapunov function for the case in which \\(A_{11} = A_{22} &gt; A_{12} = A_{21}\\). References "],
["generalized-lotka-volterra-model.html", "Lecture 3 Generalized Lotka-Volterra model 3.1 Formulation 3.2 A single population 3.3 Multi-species dynamics 3.4 MacArthur’s consumer-resource model 3.5 Further readings", " Lecture 3 Generalized Lotka-Volterra model Lesson plan: We start by discussing the Generalized Lotka-Volterra model, which we are going to see over and over again in the remainder of the lectures. We discuss the existence of a “coexistence” equilibrium, as well as its local stability. We show that the GLV model can give rise to all sort of dynamics, including limit cycles and chaos. Despite this fact, the persistence of all species requires the existence of a feasible equilibrium, which is the time-average of the species’ densities for complex attractors. We introduce D-stability, allowing us to write a Lyapunov function to determine global stability in GLV models. We conclude by analyzing the MacArthur’s consumer-resource model, highlighting its deep connection to GLV. 3.1 Formulation We can write the Generalized Lotka-Volterra model in a compact form as: \\[ \\dfrac{dx(t)}{dt} = D(x(t))(r + A x(t)) \\] where \\(x(t)\\) is a (column) vector of length \\(n\\) containing the densities of all populations \\(1, \\ldots, n\\) at time \\(t\\), \\(r\\) is a vector of “intrinsic growth rates” (or death rates, when negative), measuring the growth (decline) of population \\(i\\) when grown alone at low density, and \\(A\\) is a \\(n \\times n\\) matrix of interaction coefficients. We use \\(D(x)\\) to denote the diagonal matrix with \\(x\\) on the diagonal. 3.2 A single population The simplest case to study is that of a single population, in which case the equation becomes that of the logistic growth: \\[ \\dfrac{dx(t)}{dt} = x(t)(\\rho + \\alpha x(t)) \\] As we’ve seen before, this is a separable ODE, with solution: \\[ x(t) = \\frac{\\rho\\, {x_0}\\, e^{\\rho t}}{\\rho- \\alpha\\, {x_0} \\left(e^{\\rho t}-1\\right)} \\] 3.2.1 Metapopulation dynamics Consider a fragmented landscape in which habitable patches are connected by dispersal (for simplicity, suppose that all patches are reachable from any other). Call \\(p(t)\\) the proportion of patches occupied by the species of interest at time \\(t\\), and assume that a) an empty patch (the proportion of empty patches is \\(1 - p(t)\\)) is colonized by the species with rate \\(\\gamma\\, p(t)\\), where \\(\\gamma\\) is the “colonization rate”, and b) that occupied patches become empty at rate \\(\\epsilon\\, p(t)\\) (“extinction rate”). We want to model the proportion of patches occupied by the population at time \\(t\\) (Levins 1969): \\[ \\dfrac{d p(t)}{dt} = \\gamma\\, p(t)(1 - p(t)) - \\epsilon\\, p(t) = p(t) ((\\gamma - \\epsilon) - \\gamma\\, p(t)) \\] which is equivalent to the logistic equation above with \\(\\rho = \\gamma -\\epsilon\\) and \\(\\alpha = -\\gamma\\). As such, asymptotically the proportion of patches occupied by the population will be \\(-\\rho/\\alpha = (\\gamma -\\epsilon) / \\gamma\\). 3.2.2 S-I-S model Consider a population of individuals, each of which can be in one of two states: susceptible to a disease, or infective/infected. Call \\(S(t)\\) the proportion of susceptible individuals at time \\(t\\), and \\(I(t)\\) the proportion of infected individuals, with \\(S(t) + I(t) = 1\\). When individuals meet, an infected individual can transmit the disease to susceptibles with rate \\(\\beta\\); infected individuals recover from the disease with rate \\(\\gamma\\), and return susceptible. We can write the system of equations: \\[ \\begin{cases} \\dfrac{d S(t)}{dt} = -\\beta S(t) I(t) + \\gamma I(t)\\\\ \\dfrac{d I(t)}{dt} = \\beta S(t) I(t) - \\gamma I(t) \\end{cases} \\] take the second equation, and substitute \\(S(t) = 1 - I(t)\\); rearranging: \\[ \\dfrac{d I(t)}{dt} = \\beta (1-I(t)) I(t) - \\gamma I(t) = I(t)(\\beta - \\gamma -\\beta I(t)) \\] which is again the equation for the logistic growth with \\(\\rho = \\beta - \\gamma\\) and \\(\\alpha = -\\beta\\). As such, provided that \\(\\beta -\\gamma &gt; 0\\), asymptotically a fraction \\((\\beta - \\gamma) / \\beta\\) of individuals will be infected. The condition \\(\\beta -\\gamma &gt; 0 \\to \\beta &gt; \\gamma \\to \\beta/ \\gamma &gt; 1\\) is often written as \\(\\mathcal R_0 = \\beta/ \\gamma &gt; 1\\). 3.3 Multi-species dynamics 3.3.1 Existence of an equilibrium Returning to the multi-species system, and in analogy with the single species, we can look for stationary points (equilibria). If the matrix \\(A\\) is not singular, then we can look for a solution of \\(r + Ax = 0\\) that has positive components (called a feasible equilibrium). If such point exists, it is unique and is the solution of \\(Ax^\\star = -r\\), \\(x^\\star = -A^{-1}r\\). Suppose that the GLV has no feasible equilibrium. Then all trajectories (if bounded; some could grow to infinity) reach the boundary of \\(\\mathbb R^n_{0+}\\). Practically, this means that to ensure coexistence of all species, it is necessary to have an equilibrium in the interior \\(\\mathbb R^n_{+}\\). For a proof, see Theorem 5.2.1 in Hofbauer and Sigmund (1998). 3.3.2 Stability of the coexistence equilibrium Suppose that a feasible equilibrium \\(x^\\star\\) exists. For the GLV model, the Jacobian is easy to compute: \\[ J_{ij} = \\frac{\\partial f_i}{\\partial x_j} = A_{ij} x_i \\] and \\[ J_{ii} = \\frac{\\partial f_i}{\\partial x_i} = r_i + \\sum_j A_{ij} x_j + A_{ii} x_i \\] At equilibrium \\(r_i + \\sum_j A_{ij} x_j = 0\\), and therefore: \\[ M = \\left. {J} \\right|_{ {x}^\\star} = D(x^\\star)A \\] If the eigenvalues of \\(M\\) have all negative real part, then \\(x^\\star\\) is locally asymptotically stable. D-stability and Lyapunov-Diagonal Stability A matrix \\(A\\) is called stable if all its eigenvalues have negative real part. A matrix \\(A\\) is called D-stable if \\(D(x) A\\) is stable for every choice of \\(x\\) such \\(x_i &gt; 0\\; \\forall i\\). While conditions for D-stability are not known for matrices of size greater than 3, a sufficient condtion for D-stability is that there exists a diagonal matrix \\(D\\) with positive elements on the diagonal such that \\(DA + A^T D\\) is negative definite (i.e., has negative eigenvalues). Consequences for Lotka-Volterra dynamics If a matrix \\(A\\) is stable and symmetric, it is D-stable (just take \\(D = I\\)). Take a stable, non symmetric matrix \\(A\\) such that \\(A + A^T\\) is negative definite. Then any feasible equilibrium is stable: we have \\(M = D(x^\\star)A\\), but if \\(A\\) is D-stable then \\(M\\) is stable. 3.3.3 Types of dynamics As we’ve seen before, for a single population, there are only three types of dynamics that can be displayed by a GLV model: either the population grows to infinity, shrinks to zero, or asymptotically reaches a steady state. Smale (1976) and Hirsch (1982) showed that limit cylces are possible for three or more species, and that any dynamics can be found for competitive GLV systems with five or more species. A few examples taken from Barabás, J. Michalska-Smith, and Allesina (2016). First, a competitive system in which a feasible equilibrium does not exist, leading to the extinction of a species. For example, take \\[ r = \\begin{pmatrix} 1\\\\ 1\\\\ 1 \\end{pmatrix}\\;\\;A = -\\begin{pmatrix} 10 &amp; 9 &amp; 5 \\\\ 9 &amp; 10 &amp; 9\\\\ 5 &amp; 9 &amp; 10 \\end{pmatrix} \\] The coexistence equilibrium is not feasible: \\[ -A^{-1}r = \\begin{pmatrix} -\\dfrac{1}{12}\\\\ \\dfrac{1}{4}\\\\ -\\dfrac{1}{12}\\\\ \\end{pmatrix} \\] and as such dynamics will lead to a boundary equilibrium: Showing that species 2 goes extinct. Then, a case in which the equilibrium exists, and is attractive (stable). Take: \\[ r = \\begin{pmatrix} 10\\\\ 10\\\\ 10 \\end{pmatrix}\\;\\;A = -\\begin{pmatrix} 10 &amp; 7 &amp; 12 \\\\ 15 &amp; 10 &amp; 8\\\\ 7 &amp; 11 &amp; 10 \\end{pmatrix} \\] Now the coexistence equilibrium is feasible: \\[ -A^{-1}r = \\dfrac{1}{301}\\begin{pmatrix} 50\\\\ 110\\\\ 145\\\\ \\end{pmatrix} \\] and locally stable (the eigenvalues of \\(D(x^\\star) A)\\) have negative real part). Hence, there are initial conditions for which we will eventually converge to the equilibrium: With three competitors we can find stable limit cycles (this requires a feasible, unstable equilibrium): And with four or more species we can have chaos (also here we need a feasible, unstable coexistence equilibrium): 3.3.4 The equilibrium is the time-average Suppose that \\(x(t)\\) has a periodic orbit of period \\(T\\) (i.e., we assume \\(x(0) = x(T)\\)). Further, assume that the GLV has a feasible, interior equilibrium \\(x^\\star\\). We want to calculate the average density for each species: \\[ \\frac{1}{T} \\int_0^T x(t) dt \\] First, we assume that \\(x(t) &gt; 0\\) and write the dynamics of its logarithm: \\[ \\dfrac{d \\log(x_i(t))}{dt} = \\dfrac{1}{x_i(t)}\\dfrac{d x_i(t)}{dt} = r_i + \\sum_j A_{ij} x_j(t) \\] In vector form: \\[ \\dfrac{d \\log x(t)}{d t} = r + A x(t) \\] Compute the average on both sides: \\[ \\frac{1}{T}\\int_0^T \\frac{d \\log(x(t))}{dt} dt= \\frac{1}{T}\\int_0^T \\left(r + Ax \\right) dt \\] yielding: \\[ \\frac{1}{T}(\\log(x(T)) - \\log(x(0))) = 0 = r + A \\left( \\frac{1}{T} \\int_0^T x(t) dt \\right) \\] Note that the l.h.s. is zero because \\(x(0) = x(T)\\). Multiplying by the matrix inverse and rearranging: \\[ -A^{-1} r = x^\\star = \\frac{1}{T} \\int_0^T x(t) dt \\] showing that the average density is in fact the equilibrium. With a similar argument, one can prove that if the trajectory stays in a compact space (i.e., in case of chaotic attractors), then long-time average is still \\(x^\\star\\). 3.3.5 Lyapunov diagonal stability and global stability Suppose that there is a positive diagonal matrix \\(C\\) such that \\(C A + A^T C\\) is negative definite (i.e., has only negative eigenvalues; the eigenvalues are real because the matrix is symmetric). Then \\(A\\) is Lyapunov-diagonally stable. If this is the case, then \\(A\\) is stable, and any \\(D A\\) with \\(D\\) positive is also stable (called \\(D-\\)stability). Further, suppose that the GLV system with parameters \\(A\\) and \\(r\\) has a feasible equilibrium point \\(x^\\star\\). Then the function: \\[ V(x(t)) = 1^T C \\left( x(t) -x^\\star -x^\\star \\cdot \\log (x(t) / x^\\star)\\right) \\] is a Lyapunov function for the GLV system. It is clear that \\(V(x(t))\\) is positive everywhere in the positive orthant besides at equilibrium. Then, we need to show that the function decreases along the trajectories of the system. To prove this point, we start from \\(r = -Ax^\\star\\). Substituting, we can write the GLV system as \\(dx(t)/dt = D(x)A(x - x^\\star)\\); similarly, we can write \\(d \\log x(t)/dt = A(x - x^\\star)\\). Taking the derivative of \\(V\\) with respect to time: \\[ \\begin{aligned} \\frac{d V(x(t))}{dt} &amp;= 1^T C \\left(\\frac{d x(t)}{dt} - D(x^\\star) \\frac{d \\log x(t)}{dt} \\right)\\\\ &amp;= 1^T C \\left(D(x)(A (x - x^\\star) - D(x^\\star) A (x - x^\\star) \\right)\\\\ &amp;= 1^T C \\left(D(x - x^\\star) A (x - x^\\star) \\right)\\\\ &amp;= 1^T \\left(D(x - x^\\star) C A (x - x^\\star) \\right)\\\\ &amp;= (x - x^\\star)^T CA (x - x^\\star)\\\\ &amp;= \\frac{1}{2}(x - x^\\star)^T (CA + A^T C) (x - x^\\star)\\\\ \\end{aligned} \\] A matrix \\(B\\) is negative definite if \\(y^T B y &lt; 0\\) for all \\(y \\neq 0\\). As such, if \\(C A + A^T C\\), then \\(\\frac{d V(x(t))}{dt} \\leq 0\\), i.e., will decrease in time (starting from any \\(x(0)\\)) until the equilibrium \\(x^\\star\\) is reached. The results above show that if \\(A\\) is Lyapunov diagonally-stable and a feasible equilibrium \\(x^\\star\\) exists, then all trajectories starting at a positive density will converge to the equilibrium. This property is often used to prove global stability. 3.4 MacArthur’s consumer-resource model History: Robert H. MacArthur (1930-1972) Robert MacArthur was born in Toronto, and moved to Vermont when his father (a geneticist) became a professor at Marlboro College. He studied mathematics first at Marlboro College and then at Brown University. He enrolled as a PhD student in mathematics at Yale, but quickly switched to studying ecology with George Evelyn Hutchinson. He was a professor first at the University of Pennsylvania and then at Princeton University. In his brief career (he died at age 45) he revolutionized ecology, by making it into a rigorous, predictive science based on general principles. He is recognized for developing the Theory of Island Biogeography (with E. O. Wilson, MacArthur and Wilson (2001)), the investigation of limiting similarity (with R. Levins, MacArthur and Levins (1967)), the contributions to the complexity-stability debate (MacArthur (1955), see next lecture). The consumer-resource model he proposed in 1969 now bears his name (published also in MacArthur (1970) in a longer form—the first paper in the journal Theoretical Population Biology!). MacArtur considered a system with two classes of equations: those describing the dynamics of consumers \\((x_i)\\) and resources (\\(y_i\\)). Resources do not interact with each other, and consumers interact only through the sharing of resources. Several parameterizations are possible—here we choose a simple formulation that retains the main features of the model (see Case and Casten (1979) for a slightly more general model): \\[ \\begin{cases} \\dfrac{d y_i}{dt} = y_i \\left(r_i - b_i\\, y_i - \\sum_j P_{ij}\\, x_j \\right)\\\\ \\dfrac{d x_j}{dt} = x_j \\left(- m_j + \\sum_i v_j\\, P_{ij}\\, y_i \\right)\\\\ \\end{cases} \\] In the absence of consumers, each resource grows logistically. In the absence of resources, consumers go extinct. In the model, all parameters are taken to be positive: \\(r_i\\) is the growth rate for resource \\(i\\), \\(b_i\\) models its self-regulation; \\(m_j\\) is the death rate of consumer \\(j\\), and \\(v_j\\) models the efficiency of transformation of resources into consumers. The matrix \\(P\\) is in general rectangular (\\(n \\times k\\), where \\(n\\) is the number of resources and \\(k\\) that of consumers). Block matrices Any matrix can be rewritten as a series of smaller matrices stitched together. For square matrices, it is often convenient to partition a matrix into blocks such that diagonal blocks are square matrices and off-diagonal blocks are (in general) rectangular. For example: \\[ M = \\begin{pmatrix} 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\\\ 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10\\\\ 11 &amp; 12 &amp; 13 &amp; 14 &amp; 15\\\\ 16 &amp; 17 &amp; 18 &amp; 19 &amp; 20\\\\ 21 &amp; 22 &amp; 23 &amp; 24 &amp; 25\\\\ \\end{pmatrix} \\] Can be written as: \\[ M = \\begin{pmatrix} M_{11} &amp; M_{12}\\\\ M_{21} &amp; M_{22} \\end{pmatrix} \\] with: \\[ M_{11} = \\begin{pmatrix} 1 &amp; 2 \\\\ 6 &amp; 7 \\end{pmatrix} \\; M_{21} = \\begin{pmatrix} 3 &amp; 4 &amp; 5\\\\ 8 &amp; 9 &amp; 10\\\\ \\end{pmatrix} \\;\\ldots \\] Multiplication of block matrices The multiplication of two block matrices with square diagonal blocks is very easy: \\[ \\begin{pmatrix} A_{11} &amp; A_{12}\\\\ A_{21} &amp; A_{22} \\end{pmatrix} \\begin{pmatrix} B_{11} &amp; B_{12}\\\\ B_{21} &amp; B_{22} \\end{pmatrix} = \\begin{pmatrix} A_{11}B_{11} + A_{12} B_{21}&amp; A_{11}B_{12} + A_{12} B_{22}\\\\ A_{21}B_{11} + A_{22} B_{21} &amp;A_{21}B_{12} + A_{22} B_{22} \\end{pmatrix} \\] Determinant of block matrices Take \\[ A = \\begin{pmatrix} A_{11} &amp; A_{12}\\\\ A_{21} &amp; A_{22} \\end{pmatrix} \\] and assume that \\(A_{22}\\) is invertible. Then \\(\\det(A) = \\det(A_{22})\\det(A_{11} - A_{12}A_{22}^{-1} A_{21})\\) Inverse of block matrix Similarly, if \\(A_{22}\\) is invertible, and \\(\\det(A) \\neq 0\\) (and hence the Schur complement \\(A_{11} - A_{12}A_{22}^{-1} A_{21}\\) is nonsingular) then \\[ A^{-1} = \\begin{pmatrix} S &amp; -S A_{12}A_{22}^{-1}\\\\ -A_{22}^{-1} A_{21} S &amp; A_{22}^{-1} + A_{22}^{-1} A_{21}SA_{21}A_{22}^{-1} \\end{pmatrix} \\] where \\(S = (A_{11} - A_{12}A_{22}^{-1} A_{21})^{-1}\\) We can rewrite the system as a generalized Lotka-Volterra model (see Case and Casten (1979)). We define: \\[ z = (y,x)^T\\;\\;s = (r, -m)^T \\] And the block structured matrix \\(A\\): \\[ A = \\begin{pmatrix} A_{11} &amp; A_{12}\\\\ A_{21} &amp; A_{22} \\end{pmatrix}\\; \\text{with}\\; A_{11} = -D(b),\\; A_{12}=-P,\\; A_{21} = D(v)P^T, A_{22} = 0_{k,k} \\] where \\(0_{k,k}\\) is a \\(k \\times k\\) matrix of zeros. Now the system becomes: \\[ \\dfrac{d z}{d t} = D(z)(s + Az) \\] 3.4.1 Existence of an equilibrium For simplicity, we concentrate on the study of the feasibility and stability of the coexistence equilibrium. If an equilibrium \\(z^\\star \\neq 0\\) exists, it is the solution of \\(Az^\\star = -s\\), which requires matrix \\(A\\) to be non-singular. Matrix \\(A\\) is nonsingular only if \\(w = 0\\) is the only solution of \\(Aw = 0\\). We prove that \\(A\\) is nonsingular whenever \\(A_{12}\\) is of rank \\(k\\), and \\(A_{11}\\) is negative definite. We do so by contradiction. First, because the matrix \\(A\\) has a special structure, we can split \\(w\\) into \\((w_1, w_2)^T\\), and write: \\[ A \\begin{pmatrix} w_1\\\\ w_2 \\end{pmatrix} = \\begin{pmatrix} A_{11}w_1 + A_{12} w_2\\\\ A_{21}w_1 \\end{pmatrix} = \\begin{pmatrix} 0_n\\\\ 0_k \\end{pmatrix} \\] We therefore have \\(A_{21} w_1 = 0\\) and \\(A_{11}w_1 + A_{12} w_2 = 0\\). Suppose that \\(w_1 =0\\) and \\(w_2 \\neq 0\\); then we find \\(A_{12} w_2 = 0\\) with \\(w_2 \\neq 0\\), which is not possible when \\(A_{12}\\) has rank \\(k\\). Now suppose that \\(w_1 \\neq 0\\) and \\(w_2 = 0\\), but this implies \\(A_{11}w_1 = 0\\) with \\(w_1 \\neq 0\\), which is impossible given that \\(A_{11}\\) is clearly of full rank. We are left with the case in which both \\(w_1 \\neq 0\\) and \\(w_2 \\neq 0\\). We have \\(A_{21} w_1 = 0\\), but \\(A_{21} w_1= D(v)P^T w_1 = 0\\), which implies \\(P^T w_1 = 0\\) because all \\(v_i &gt; 0\\). Then, multiply the first set of equations by \\(w_1^T\\) and the second by \\(w_2^T\\). We obtain \\(w_1^T A_{11} w_1 - w_1^T P w_2 = 0\\) and \\(w_2^T D(v)P^T w_1 = 0 = w_2^T P^T w_1\\). But then \\(w_1^T P w_2 = 0\\), leaving us with \\(w_1^T A_{11} w_1 = 0\\) with \\(w_1 \\neq 0\\), which is again a contradiction because \\(A_{11}\\) is clearly negative definite (and as such \\(w_1^T A_{11} w_1 \\leq 0\\), with equality implying \\(w_1 = 0\\)). We have proven that \\(A\\) is nonsingular, and therefore a unique equilibrium point for the system exists (the equilibrium for the moment needs not to be feasible) whenever \\(A_{11} = -D(b)\\) is negative definite (which is always the case whenever resources are self-regulating) and, importantly, \\(A_{12}\\) has rank \\(k\\) (the number of consumers). This in turn implies that the number of resources must be larger (or equal) than the number of consumers. A similar argument is developed in the classic Levin (1970). Key paper: Levin (1970) Starting from fairly generic assumptions, the principle of competitive exclusion is generalized: No stable equilibrium can be attained in an ecological community in which some \\(r\\) components are limited by less than \\(r\\) limiting factors. In particular, no stable equilibrium is possible if some \\(r\\) species are limited by less than \\(r\\) factors. 3.4.2 Global stability Next, we prove that if a feasible equilibrium for the system exists, it is globally stable. First, we choose a diagonal matrix \\(G\\) \\[ G = \\begin{pmatrix} I_n &amp; 0_{n,k}\\\\ 0_{k,n} &amp; D(v)^{-1} \\end{pmatrix} \\] We have: \\[ B = GA = \\begin{pmatrix} -D(b) &amp; -P\\\\ P^T &amp; 0_{k,k} \\end{pmatrix} \\] \\(B\\) is therefore negative semi-definite: \\[ \\frac{1}{2}(B + B^T) = \\begin{pmatrix} -D(b) &amp; 0_{n,k}\\\\ 0_{k,n} &amp; 0_{k,k} \\end{pmatrix} \\] with eigenvalues \\(-b\\) and \\(0\\) (with multiplicity \\(k\\)). Therefore, \\[ \\begin{align} \\frac{d V(z(t))}{dt} &amp;= 1^T G \\left(\\frac{d z(t)}{dt} - D(z^\\star) \\frac{d \\log z(t)}{dt} \\right)\\\\ &amp;= \\frac{1}{2}(z - z^\\star)^T (GA + A^T G) (z - z^\\star)\\\\ &amp;= \\frac{1}{2}(z - z^\\star)^T (B + B^T) (z - z^\\star)\\\\ &amp;= (y - y^\\star)^T (-D(b)) (y - y^\\star) \\end{align} \\] which is zero only at equilibrium. This proves that any feasible equilibrium is stable. Homework 3a Prove the local stability of the feasible coexistence equilibrium. 3.4.3 Separation of time-scales In the original article, MacArthur (1970) takes an interesting shortcut, which can shed light on the behavior of the GLV when the matrix of interactions is symmetric (i.e., \\(A = A^T\\)). Consider the Consumer-Resource model above, and assume that resources equilibrate quickly compared to the dynamics of the consumers. In practice, this means that the system operates on two different time scales, such that the consumers perceive resources to be constantly at equilibrium. We solve the equations for the resources: \\[ \\begin{align} r - D(b)\\, y - P\\, x &amp;=0\\\\ y = D(b)^{-1} (r - P\\,x) \\end{align} \\] Substituting in the equations for the consumers, we obtain: \\[ \\begin{aligned} \\dfrac{d x}{dt} &amp;= D(x) \\left(- m + D(v) P^T\\, y \\right)\\\\ &amp;= D(x) \\left(- m + D(v) P^T\\, D(b)^{-1} (r - P\\,x) \\right)\\\\ &amp;= D(x) \\left([D(v) P^T\\, D(b)^{-1} r - m] - [D(v) P^T\\, D(b)^{-1} P]\\,x\\right)\\\\ &amp;= D(x) D(v)\\left([P^T\\, D(b)^{-1} r - D(v)^{-1}m] - [P^T\\, D(b)^{-1} P]\\,x\\right)\\\\ &amp;= D(x) D(v)\\left(s - B\\,x\\right) \\end{aligned} \\] Which is again GLV, with “growth rates” \\(s = P^T\\, D(b)^{-1} r - D(v)^{-1}m\\) and “interactions” \\(B = P^T D(b)^{-1} P\\), which, importantly, is symmetric (note also that if \\(P\\) is of rank \\(k\\) and \\(b &gt; 0\\), then \\(B\\) is of full rank). 3.4.4 Lyapunov function for symmetric Lotka-Volterra At equilibrium, we have \\(x^\\star = B^{-1} s\\). Consider the function: \\[ V(x(t)) = 2 \\sum_i s_i x_i - \\sum_{ij} B_{ij} x_i x_j \\] Note that \\(\\sum_i s_i x_i &gt; 0\\) and that whenever \\(B\\) is stable (and because it’s symmetric, negative definite), \\(- \\sum_{ij} B_{ij} x_i x_j &gt; 0\\). At equilibrium, we have: \\[ V(x^\\star) = 2 \\sum_i s_i x_i^\\star - \\sum_{ij} x_j^\\star B_{ij} B_{ij}^{-1} s_j = 2 \\sum_i s_i x_i^\\star - \\sum_j s_j x_j^\\star = \\sum_i s_i x_i^\\star \\] It is of particular interest the case in which \\(s_i = 1\\) for all \\(i\\) and \\(V(x^\\star)\\) is simply the total biomass of the system at equilibrium. Now, let’s take the derivative of \\(V(x(t))\\) with respect to \\(x_i\\): \\[ \\dfrac{\\partial V}{\\partial x_i} = 2 s_i - 2 \\sum_j B_{ij} x_j \\] But then: \\[ \\dfrac{d x_i}{d t} = x_i v_i \\left(s_i -\\sum_j B_{ij} x_j\\right) = x_i v_i \\frac{1}{2}\\dfrac{\\partial V}{\\partial x_i} \\] And therefore, by chain rule: \\[ \\dfrac{d V(x(t))} {d t} = \\sum_i \\dfrac{\\partial V}{\\partial x_i} \\dfrac{d x_i}{d t} = \\sum_i x_i v_i \\frac{1}{2}\\left(\\dfrac{\\partial V}{\\partial x_i} \\right)^2 \\] which is always nonnegative, and is zero at equilibrium. Therefore, \\(V(x(t))\\) is maximized through the dynamics. This holds even more generally, as we will see in the next lecture and in the following homework. In a way, competitive dynamics are “optimizing” \\(V\\), by following a gradient. This argument can be further expanded, showing that many ecological models can be interpreted as optimization processes (Marsland III, Cui, and Mehta (2019)). Homework 3b Consider a five-species system with symmetric, stable \\(B\\) (with all positive coefficients) and positive \\(s\\), yielding the feasible equilibrium \\(x^\\star\\). Find random parameters satisfying 1) \\(B_{ij} = B_{ji} &gt; 0\\; \\forall i,j\\); 2) \\(B\\) is stable; 3) \\(s_i &gt; 0 \\; \\forall i\\); 4) \\(B^{-1}s = x^\\star &gt; 0\\). These parameters define your pool of species. For each possible subset of species in the pool, (i.e., for all combinations ranging from a single species [5 cases], to two species [10 cases], \\(\\ldots\\), to all species together [1 case]), compute the corresponding equilibrium. Is it feasible? Is it stable? Take two subset of species such that a) both are feasible and stable; b) subset 1 contains subset 2 (i.e., all species in 2 are in 1, but not the converse); c) the value of \\(V(x^\\star)\\) for subset 1 is larger than that for subset 2. Try invading subset 2 with the species by introducing at the equilibrium of subset 2 the species that are in subset 1 but not in 2—starting all of them at low density. What happens? 3.5 Further readings On the theory of GLV: Hofbauer and Sigmund (1998) is a wonderful introduction to dynamical systems in ecology and population genetics, with a nice introduction to evolutionary game theory. Hadeler, Mackey, and Stevens (2017) contains a more mathematically-oriented treatment of the material covered in the first part of this lecture. Baigent (2016) is a mathematical introduction to Lotka-Volterra dynamics. References "],
["stability-of-large-ecological-communities.html", "Lecture 4 Stability of large ecological communities 4.1 Complexity and stability 4.2 The stability of random ecosystems 4.3 Accounting for interaction types 4.4 Symmetric matrices 4.5 Covariance matrices 4.6 Small-rank perturbations 4.7 Structured matrices 4.8 Further readings", " Lecture 4 Stability of large ecological communities Lesson plan: We introduce the so-called diversity-stability debate, by discussing the seminal contributions of MacArthur (1955) and May (1972). We show how the celebrated May’s stability criterion can be derived using elementary results from random matrix theory. We extend May’s results to the case in which interactions between the species are correlated. We discuss a few tools from random matrix theory that are useful for ecology. 4.1 Complexity and stability Key paper: MacArthur (1955) In 1955, MacArthur used an information-theoretic argument to suggest more speciose communities would be more “stable”: having a food web with many species would open several “channels” for energy to flow from resources to consumers, such that if a channel were to go dry, another channel could take its place. Key paper: May (1972) This idea was challenged by May, who showed that, all other things being equal, larger communities would be less likely to be dynamically stable. This paper started the so-called “diversity-stability” debate that populates the literature to this day. Key paper: McCann (2000) In this review, McCann summarizes the development of the diversity-stability debate over the span of three decades. As we have seen before, an equilibrium \\(x^\\star\\) is stable if the community matrix for the equilibrium has all eigenvalues with negative real part. For a Generalized Lotka-Volterra model, to determine the equilibrium and its stability, we would need to specify all the growth rates (\\(r\\), \\(n\\) values), as well as the matrix of interactions (\\(A\\), \\(n^2\\) values). This is impractical to do for large systems (though we will try this out later). But can something quite general be said about the limit in which many species are in the community? 4.2 The stability of random ecosystems History: Robert M. May (1936-2020) Born and educated in Sidney, May received a PhD in theoretical physics from the University of Sidney in 1959. Having started his career in the physics of super-conductivity, May became interested in ecology. When visiting Princeton during his stay at the Institute for Advanced Studies, he met MacArthur, and decided to change fields. He ended up changing the field of ecology, with an incredible number of contributions on population dynamics and chaos (see key papers in preceding lectures), the dynamics of infectious diseases (with Roy Anderson, Anderson and May (1992)), evolutionary game theory (Nowak and May (1992)), the estimation of the number of species on Earth (May (1988)), bibliometrics (May (1997)), and even banking (by modeling systemic risks, Haldane and May (2011)). He succeeded MacArthur at Princeton, and concluded his career in England (University of Oxford). He won a large number of prizes, and was created a life peer (Lord May, Baron of Oxford). He served as president of the Royal Society and as Chief Scientific Adviser to the government. May (1972) attempted to answer this question by considering a random community matrix. In a GLV system, the diagonal elements \\(M_{ii} = A_{ii} x_i^\\star\\) are influenced by self-regulation (i.e., as in a carrying capacity), while the off-diagonal elements \\(M_{ij} = A_{ij} x_i^\\star\\) model the effect of species \\(j\\) on the equilibrium of species \\(i\\). May considered the following algorithm to build a random community matrix. Take a large community, resting at an unspecified, feasible equilibrium; we build the community matrix by setting: \\(M_{ij} = 0\\) with probability \\((1-C)\\); with probability \\(C\\) we draw \\(M_{ij}\\) from a distribution with mean zero and variance \\(\\sigma^2\\). \\(C\\) is the proportion of realized connections, termed the “connectance” of the system. the diagonal elements are set to \\(-d\\), modeling self-regulation. May did not specify the distribution from which one would draw the nonzero interactions (more on this later). For the moment, let’s assume it’s a Normal distribution with mean zero and variance \\(\\sigma^2\\). Note that the average of the eigenvalues of a matrix \\(A\\) is given by the average of its diagonal elements \\(\\frac{1}{n}\\sum_i \\lambda_i = \\frac{1}{n} \\text{Tr}(A) = \\frac{1}{n} \\sum_i A_{ii}\\). As such, if \\(A = dI + B\\), the eigenvalues of \\(A\\) will be those of \\(B\\) shifted by \\(d\\). We want to determine whether the equilibrium will be stable, given \\(n\\), \\(C\\), \\(d\\) and \\(\\sigma^2\\). To do so, we need to find the location of the “rightmost” eigenvalue of \\(M\\). For example, let’s plot the eigenvalues of a large matrix (\\(500 \\times 500\\), the red-dashed line marks the location of zero on the x axis): The eigenvalues fall into an almost perfect circle! Turns out, that this is the behavior we should expect, as stated by the so-called “Circular Law”, one of the most beautiful results in random matrix theory. Circular law: Take a non-symmetric, \\(n \\times n\\) random matrix in which all coefficients \\(X_{ij}\\) are i.i.d. random variables with \\(\\mathbb E[X_{ij}] = 0\\) and \\(\\mathbb E[X_{ij}^2] = 1\\). Then, as \\(n \\to \\infty\\), the e.s.d. of \\({X} / \\sqrt{n}\\) converges to the circular law: \\[ \\mu(\\lambda) = \\begin{cases} \\frac{1}{\\pi} \\; \\; \\; \\text{if} \\; (\\text{Re}(\\lambda))^2 + (\\text{Im}(\\lambda))^2 \\leq 1\\\\ 0 \\; \\; \\;\\text{ otherwise}. \\end{cases} \\] This result can be used to calculate the radius of the eigenvalue distribution of the matrices studied by May: when the off-diagonal coefficients \\(M_{ij}\\) are 0 with probability \\(1-C\\) and are sampled independently from a distribution with mean \\(0\\) and variance \\(\\sigma^2\\) with probability \\(C\\), we have that \\(\\mathbb E[M_{ij}] = 0\\) and \\(\\mathbb E[M_{ij}^2] = C \\sigma^2\\). This means that if we were to divide the coefficients of \\({M}\\) by \\(\\sqrt{C \\sigma^2}\\) we would recover the unit variance, and the matrix would follow the circular law when \\(S\\) is large. Armed with this, we can calculate the radius: if the radius of \\({M} / \\sqrt{n C \\sigma^2}\\) converges to 1 when the matrix is large, then the radius of \\({M}\\) is approximately \\(\\sqrt{n C \\sigma^2}\\). For stability, we need a sufficiently negative diagonal (setting the center of the circle), yielding May’s stability criterion: \\[ \\sqrt{n C \\sigma^2} &lt; d \\] We can try this on our matrix (black dashed line): Showing that we accurately approximate the location of the rightmost eigenvalue. Note that, in the case of large \\(n\\), whenever the circle crosses zero, some eigenvalues will be positive, determining the instability of the equilibrium. Importantly, the distribution from which the coefficients are sampled does not matter—only that the mean is zero and that the variance is \\(\\sigma^2\\). For example, build the matrix using coefficients from a uniform distribution: This property is called universality in random matrix theory. Homework 4a The probability that a matrix is stable, given \\(C\\), \\(\\sigma\\) and \\(n\\) is close to 1 when the stability criterion is satisfied, and close to 0 when it is not. Matrices satisfying \\(\\sqrt{n C \\sigma^2} = d\\) are at the critical point. In theory, the results only hold in the limit \\(n \\to \\infty\\) (to be accurate, \\(nC \\to \\infty\\)), as eigenvalues can fall outside the circle with small probability. Write code to compute the real part for the “rightmost” eigenvalue of a random matrix (Note: computing eigenvalues is fairly expensive in terms of computing time. Use eigen(M, only.values = TRUE)$values to speed up calculations). Write code to build matrices like those studied by May (nonzero elements sampled from a normal distribution). Set \\(d = 10\\) and choose parameters \\(n\\), \\(C\\) and \\(\\sigma^2\\) such that you are close to the critical point (make sure \\(n\\) and \\(C\\) are large enough, for example \\(nC &gt; 10\\)). Draw 1000 random matrices and compute the probability drawing a stable matrix. Vary \\(n\\), \\(C\\) and \\(\\sigma^2\\) in turn, making them cross the critical point. Draw a graph where the probability of stability is on the y axis, the x axis measures \\(\\sqrt{nC\\sigma^2}\\). The graph should look like the one reported below: 4.3 Accounting for interaction types In ecological communities, the effect of species \\(i\\) on \\(j\\) and that of \\(j\\) on \\(i\\) are typically not independent (as assumed above): in the case of competition between species, we expect them both to be negative; for consumption, if one is positive, the other is negative, and so forth. A more refined model of a random matrix would therefore sample interactions in pairs from a bivariate distribution. The elliptic law can deal with this case: Elliptic law: Take a non-symmetric, \\(n \\times n\\) random matrix in which the pairs of coefficients \\((X_{ij}, X_{ji})\\) are sampled independently from a bivariate distribution defined by a vector of means \\(m = (0,0)^t\\) and a covariance matrix \\(\\Sigma = \\begin{pmatrix} 1 &amp; \\rho\\\\ \\rho &amp; 1 \\end{pmatrix}\\). Then, as \\(n \\to \\infty\\), the e.s.d. of \\({X} / \\sqrt{n}\\) converges to the elliptic law: \\[ \\mu(\\lambda) = \\begin{cases} \\frac{1}{\\pi (1 - \\rho^2) } \\quad \\text{if} \\; \\frac{(\\text{Re}(\\lambda))^2}{(1 + \\rho)^2} + \\frac{(\\text{Im}(\\lambda))^2}{(1 -\\rho)^2} \\leq 1\\\\ 0 \\quad \\quad \\quad \\text{ otherwise} \\end{cases} \\] Note that when \\(\\rho = 0\\), the elliptic law reduces to the circular law. Using the elliptic law, Allesina and Tang (2012) were able to extend May’s criterion to ecological networks with different mixtures of interaction types. Build a matrix \\(M\\) by sampling the entries in pairs: \\((M_{ij}, M_{ji})\\) are zero with probability \\((1-C)\\), and with probability \\(C\\) sampled independently from a bivariate distribution with mean \\(\\nu = (0, 0)^T\\), and covariance matrix \\(\\Sigma = \\sigma^2 \\begin{pmatrix} 1 &amp; \\rho\\\\ \\rho &amp; 1\\end{pmatrix}\\). Then \\(\\mathbb E[M_{ij}] = 0\\), \\(\\mathbb E[M_{ij}^2] = C \\sigma^2\\), and \\(E[M_{ij} M_{ji}] = C \\sigma^2 \\rho\\). By dividing the entries \\({M}\\) by \\(\\sqrt{C \\sigma^2}\\), we obtain a matrix following the elliptic law. As such, the stability criterion becomes: \\[ \\sqrt{n C \\sigma^2}(1 + \\rho) &lt; d \\] To see the elliptic law in action, we can build matrices in which we sample the coefficients in pairs from a bivariate normal distribution. If we sample the entries from a distribution with a positive correlation, we obtain a horizontally-stretched ellipse (and hence, more difficult to stabilize than the circle): Similarly, a negative correlation (e.g., as in predator-prey) would make the system easier to stabilize: Allesina and Tang therefore concluded that, all other things being equal, ecological communities in which predator-prey interactions are prevalent (and as such \\(E[M_{ij} M_{ji}] &lt; 0\\)) are easier to stabilize than those dominated by competition/mutualism (\\(E[M_{ij} M_{ji}] &gt; 0\\)). 4.4 Symmetric matrices Build a random symmetric matrix \\(X\\) by sampling the coefficients \\(X_{ij}\\) in the upper-triangular part (i.e., \\(i &lt; j\\)) independently from a distribution such that \\(\\mathbb E[X_{ij}] = 0\\) and \\(\\mathbb E[X_{ij}^2] = 1\\). Set \\(X_{ji} = X_{ij}\\), thereby building a symmetric matrix. The diagonal elements are sampled from a distribution with mean zero and finite variance. Then, as \\(n \\to \\infty\\), the empirical spectral distribution of \\(X / \\sqrt{n}\\) (i.e., of the matrix in which all the coefficients have been divided by the \\(\\sqrt{n}\\)) converges almost surely to the Wigner’s semicirle distribution: \\[\\begin{equation} \\mu(\\lambda) = \\begin{cases} \\frac{1}{2 \\pi} \\sqrt{4 - \\lambda^2}\\; \\; \\; \\text{if}\\; \\lambda \\in [-2, 2]\\\\ 0 \\; \\; \\;\\text{ otherwise}. \\end{cases} \\end{equation}\\] Importantly, we have not defined the distribution of the \\(X_{ij}\\): as long as the coefficients have mean zero, and unit variance, the result holds (universality). 4.5 Covariance matrices Take a \\(p \\times n\\) rectangular matrix \\(X\\), with \\(p &lt; n\\) and i.i.d. coefficients with \\(\\mathbb E[X_{ij}] = 0\\) and \\(\\mathbb E[X_{ij}^2] = 1\\). When \\(n \\to \\infty\\), the ratio \\(p/n \\to y\\) (i.e., the number of rows and columns grow proportionally). Then the eigenvalue distribution of the scaled covariance matrix \\(S = \\frac{1}{n} X X^T\\) converges to the Marchenko-Pastur distribution: \\[ \\begin{equation} \\mu(\\lambda) = \\begin{cases} \\frac{1}{2 \\pi \\lambda y} \\sqrt{\\left((1 + \\sqrt{y})^2 - \\lambda \\right) \\left(\\lambda - (1 - \\sqrt{y})^2 \\right)}\\; \\; \\; \\text{if} \\; (1 - \\sqrt{y})^2 \\leq \\lambda \\leq (1 + \\sqrt{y})^2\\\\ 0 \\; \\; \\;\\text{ otherwise}. \\end{cases} \\end{equation} \\] 4.6 Small-rank perturbations The basic results listed above consider matrices whose coefficients have mean zero. Clearly, this is rarely the case in ecological systems, and therefore for applications we need to incorporate the possibility of nonzero means. While in general one cannot compute the distribution of the eigenvalues of a sum of two matrices \\({M} = {A} + {B}\\) from the eigenvalues of the two matrices, this calculation is possible whenever \\({A}\\) has small-rank (i.e., few nonzero eigenvalues, or a finite amount in the limit of infinitely large sizes) and \\({B}\\) is a large random matrix. In this case, the distribution of the eigenvalues of \\({M}\\) will be composed by a bulk, defined by the spectrum of \\({B}\\), and (possibly) a few outlier eigenvalues, matching closely the nonzero eigenvalues of \\({A}\\) (a correction is needed when the coefficients of \\({B}\\) are correlated, O’Rourke and Renfrew (2014)). For example, let’s add a matrix with three nonzero eigenvalues to a large random matrix of the type studied by May: 4.7 Structured matrices Some special matrices with few nonzero eigenvalues are of the form: \\[ M = \\begin{pmatrix} \\alpha_{k,k} &amp; \\beta_{k,n-k}\\\\ \\gamma_{n-k,k} &amp; \\delta_{n-k, n-k} \\end{pmatrix} \\] where for example \\(\\alpha_{k,k}\\) is a \\(k \\times k\\) matrix with \\(\\alpha\\) in all entries. The eigenvalues of this matrix (or more complicated block-structured matrices with constants in every block) are easy to compute. Take: \\[ M&#39; = \\begin{pmatrix} \\frac{k}{n}\\alpha &amp; \\frac{k}{n}\\beta\\\\ \\frac{n-k}{n}\\gamma &amp; \\frac{n-k}{n}\\delta \\end{pmatrix} \\] and call \\(\\lambda&#39;\\) the eigenvalues of \\(M&#39;\\). Then the eigenvalues of \\(M\\) are \\(\\lambda = n \\lambda&#39; \\cup 0_{n-2}\\). Homework 4b Study the spectrum of the community matrix of a competitive community in which species are divided into two groups (e.g., benthic, pelagic), and interactions are as follow: \\(M_{ii} = -5 \\; \\forall i\\) \\(M_{ij} \\sim \\mathcal N(\\mu_{1}, \\sigma^2)\\) when \\(i\\) and \\(j\\) belong to the same group, and \\(M_{ij} \\sim \\mathcal N(\\mu_{2}, \\sigma^2)\\) when they belong to different groups. Use \\(\\mu_1 = -1, \\mu_2 = -1/2, \\sigma^2 = 1/4\\) and assume the two groups have equal sizes. 4.8 Further readings On random matrices and stability: Allesina and Tang (2015) is an opinionated review on applications of random matrices in ecology. The lectures follow Allesina and Grilli (2020) quite closely. The online version of the book is available through the library. References "],
["ecological-assembly.html", "Lecture 5 Ecological assembly 5.1 Assembly 5.2 Modeling invasions 5.3 Top-down assembly 5.4 Network spandrels 5.5 Bottom-up assembly", " Lecture 5 Ecological assembly Lesson plan: We have seen in the previous lecture that a large ecological community will almost invariably be unstable, possibly leading to extinctions. It is therefore natural to ask what happens when either a feasible equilibrium does not exist, or it is unstable. In particular, we want to know how many species can persist. We discuss the problem of assembly, and why is it so challenging to study analytically. We introduce a few assumptions that make the problem tractable and at the same time non trivial. We compute how many species will coexist in a GLV with random parameters, and see how we can study assembly by drawing an “assembly graph” 5.1 Assembly We call ecological assembly the process by which ecological communities are built by the interplay of invasions (increasing community “richness”) and extinctions (decreasing it). The typical setting for an assembly model is one in which a large (possibly infinite) pool of species are available (e.g., in a “mainland”), and every so often individuals from the species’ pool enter a local habitat (island, patch, etc.), at which point they might either grow (invasion, establishment, etc.), or go extinct. In either case, the local community might respond to the invader—for example, the invader could send some of the local populations extinct, or shift the community from one state to another. Historically, this type of island-mainland models (based on species) have been contrasted with “trait-environment” models, in which species’ traits, rather than identity are the focus of the dynamics. In such models, ideas such as “environmental filtering” (i.e., the pruning of species that cannot grow in the local environment) and “trait underdispersion” (i.e., the fact that the filtering imposed by the environment results in a convergence in traits) arise naturally. When thinking of communities of competitors (e.g., different species of plants), then we might think that species’ interactions will also play a role—because species need to be different enough to coexist, this would generate “trait overdispersion” (due to limiting similarity). For a very opinionated summary of 25 years of discussions on these themes (1975-2000), see Weiher and Keddy (2001) (but first read the review Gotelli (1999), stating that the language and tone of the introduction is “an embarrassment to the discipline”). The idea of assembly was first introduced in ecology by the pioneers of “succession”. For example, in 1899 Henry Chandler Cowles studied the vegetation development in the Indiana Dunes—sand dunes are first colonized by “pioneer” species of plants, which are then overgrown by different vegetation in older dunes. Because dunes are regularly disrupted by wind, one could make a “space-for-time” substitution and reconstruct the development of the vegetation as a “chronosequence”. Importantly, Cowles (and then Clements) held the view that succession would be a strongly ordered, “determinisitc” process by which communities tended to a certain “climax” state. In the 1920s, Henry Gleason challenged this view, advocating for a much greater role for chance. History: Henry Chandler Cowles (1869-1939) Born in Kensington, Connecticut, Cowles attended Oberlin College, and received a PhD from the University of Chicago in 1898. His thesis is centered on the vegetation succession of the Indiana Dunes. His main inspiration came from the work of Eugen Warming (Cowles studied Danish in order to read the original Plantesamfund). He was one of the pioneers of “ecology” in the US, a term that he helped popularizing, for example writing (along with Coulter and Barnes, all at U. Chicago) A textbook of botany for colleges and universities, with the second volume dedicated to the “Ecology” of plants. He was one of the founding members of the Ecological Society of America (in 1915). Another important piece of the puzzle was provided by the work of Jared Diamond who, while studying avian assemblages in New Guinea, proposed that certain species assemblages would be “forbidden” (due to competition)—by observing several instances of assembly (in the different islands), one could guess the rules of the assembly game (Diamond (1975)). Diamond’s work sparked decades of intense debate, bringing a focus on the role of null models in ecology (are the observed patterns due to chance or necessity?), with especially cogent critiques brought forward by Simberloff, Connor and Gotelli (see for example Gotelli and Graves (1996)). History: Evelyn Chrystalla “E.C.” Pielou (1924-2016) Born in England, and developing her career in Canada, she was one of the first women in mathematical ecology. She studied radio-physics at the University of London, receiving her certificate at 18 years old. She went on to work in the Navy during WWII—meeting, and subsequently marrying a biologist. This fact changed the course of her career—having completed a Bachelor’s degree in Botany, she kept publishing research while raising three children and eventually earning a PhD (also from U. London). After a few years in the Canadian Dept. of Forestry (and then Agriculture), she was hired as a full professor at Queens U. (Ontario), and subsequently Dalhousie and Lethbrdige. Her books “Introduction to Mathematical Ecology” and subsequent “Mathematical Ecology” (Pielou (1977))—which starts with: “The fact that ecology is essentially a mathematical subject is becoming even more widely accepted”—have formed generations of (theoretical) ecologists. As stated in her obituary “Never afraid to express an opinion, she did not suffer fools gladly”—as shown over and again in her work. She is well-known for her books, for the development of null models in biogeography, and her measure of “evenness” of a community. In the early 2000s, the focus changed decisively and became centered on the difference between “neutrality” (i.e., where species distribution are driven by stochastic fluctuations, Hubbell (2001)) and “niche” (i.e., driven by species interactions—or rather their avoidance). Finally, the budding field of “community phylogenetics” (Cadotte and Davies (2016)) is centered on relating these concepts to data stemming from phylogenetic trees. Here, we step back and reconsider basic models of ecological assembly in the style for example of Drake (1991), Law and Morton (1996), and Morton et al. (1996). 5.1.1 What makes the study of assembly difficult? There are three main complications that stand in the way of the development of simple theories for ecological assembly (taken from Serván and Allesina (2020)): Invasion rates. We have a timescale for the local dynamics, and a timescale for invasions, and the time at which the first species goes extinct after an invasion influences the effect of subsequent invasions. The simplest way to think of this is to have a “rock-paper-scissors” community. Suppose that our island contains only “rock”, and that “paper” enters the system—if we wait for long enough, it will displace rock; if before rock goes extinct, “scissors” invades, we can recover the full three-species community; if instead scissors arrives when rock is extinct, then it will displace paper. As such, if the speed at which the dynamics of the local community proceed are slow enough compared to the rate of invasion, we have that several species can invade before the community has reached its asymptotic configuration. At the extreme where local dynamics are fast compared to the rate of invasion, we have that each invader finds the local community at its asymptotic state; as the invasion rate increases, the system approaches a point where all the species enter the system before any extinction takes place. Increasing the invasion rate even further would result in an open system with constant immigration. Invasion size. Consider the two-species competitive Lotka-Volterra model with preemptive competition, and suppose that initially we have species \\(x_1\\) resting at its carrying capacity, i.e., the state of the system is \\(\\{x_1\\}\\). If \\(x_2\\) invades with sufficiently low density, we find \\(\\{x_1, x_2\\} \\to \\{x_1\\}\\); on the other hand, if \\(x_2\\) has sufficiently high density, we can cross the separatrix in the phase plane, leading to \\(\\{x_1, x_2\\} \\to \\{x_2\\}\\). This simple example shows that the density at which the invader enters the system can alter the outcome of the dynamics. Invasion timing. When the local community coexists at a non-fixed point attractor, the fate of the invader could be very different depending on when it is introduced. For example, a predator requiring its prey to be above a certain level would not be able to invade an oscillating system whenever prey are at low abundance, but would start growing if the invasion happened at a time when prey were abundant. 5.1.2 Ecological assembly without tears We make three main assumptions, which remove the difficulties above while leaving the model interesting to study: Invasion events are rare. We assume that the invasion rate is low enough such that, after an invasion, the local community has sufficient time to reach its asymptotic configuration before the next invader arrives. In other words, we consider cases in which local dynamics operates at a much faster rate than invasions. Note that this choice precludes certain dynamics; for example, under these stringent conditions the rock-paper-scissors community described above would never reach the three-species configuration. While this is a strong requirement, it corresponds to assumptions routinely made in the study of population genetics, and in invasion analysis. Invaders arrive at low abundance. We assume that the density of the invader is low enough so that intraspecific effects are negligible at the time of invasion (again, as routinely assumed in invasion analysis). Under this assumption, the assembly of the Lotka-Volterra preemptive competition model would have two possible final states, corresponding to each species in isolation. Note also that whenever the invader can enter the system only at low abundance, the local stability of an attractor (i.e. the community at the attractor is resistant to small perturbations caused by changes in abundance of any of the species in the pool) is sufficient to make it a possible outcome of the assembly process. Fixed-point dynamics. Finally, we consider models in which the asymptotic state of the local community is a feasible, stable equilibrium, thereby sidestepping the difficulty stemming from the timing of invasion. For example, the Generalized Lotka-Volterra model with a symmetric matrix of interaction \\(A\\) yields only fixed-point dynamics. 5.1.3 Top-down and bottom-up assembly We distinguish between two extreme cases of assembly. In top-down assembly, all species enter the system (at arbitrary densities) at the same time; assembly then is simply the pruning of some of the species through the dynamics. At the other extreme, we find bottom-up assembly, in which species enter the system one at a time. Our second lecture will focus on top-down assembly, and the third on bottom-up assembly. 5.2 Modeling invasions Imagine starting with a bare environment, and introducing the first species. If the species can grow in the new environment, it will establish, and if not, it will go extinct. Mathematically, we assume that new species are introduced at very low abundance, so that they do not experience self-limitation due to crowding, and that invasion are spaced in time so that the dynamics can play out before the next invasion happens. For example, consider the GLV model, and the case of the first species entering the system, and write the equation for the per-capita growth rate: \\[ \\dfrac{1}{x_i(t)}\\dfrac{dx_i(t)}{dt} = r_i + A_{ii} x_i(t) \\] If \\(x_i(0) \\ll 1\\), we can set \\(A_{ii} x_i(0) \\approx 0\\), obtaining \\[ \\dfrac{1}{x_i(t)}\\dfrac{dx_i(t)}{dt} \\approx r_i \\] That is, the species will establish if it has a positive growth rate in the new environment. Suppose that this is the case: then species \\(i\\) will grow to its equilibrium abundance \\(x_i^\\star = -r_i / A_{ii}\\). Now add a second species. Its initial per-capita growth rate is going to be: \\[ \\dfrac{1}{x_j(t)}\\dfrac{dx_j(t)}{dt} = r_j + \\sum_k A_{jk} x_k(t) \\approx r_j + A_{ji}x_i^\\star \\] Species \\(j\\) can therefore grow when rare if \\(r_j + A_{ji}x_i^\\star &gt; 0\\), i.e., \\(r_j &gt; -A_{ji}x_i^\\star\\). We call this type of inequality an “invasion criterion”. If the species \\(j\\) can grow when rare, in general, it could a) grow initially, but then go extinct; b) displace species \\(i\\), sending it to extinction; c) coexist with species \\(i\\). By reiterating invasions with different species, we can assemble a large ecological community. 5.2.1 Invasions in multispecies communities Now consider a pool of species (e.g., a metacommunity/mainland) and an environment (e.g., a local habitat/island) in which some of the species are present, and coexisting at an equilibrium. We have \\(n\\) species in the pool, and \\(k\\) species in the habitat/island. We want to write conditions for the invasibility of the equilibrium. To this end, we can re-arrange the rows and columns of \\(A\\), and the elements of \\(r\\) to obtain two blocks: one for the \\(k\\) species already in the community, and one for the \\(n-k\\) potential invaders. The fixed point \\(\\bar{x}\\) can be written as: \\[ \\bar{x} = \\left(\\begin{array}{l} x^{(k)} \\\\ 0^{(n-k)} \\end{array} \\right) \\] where \\(x^{(k)}\\) contains the density of the coexisting species. Similarly, the growth rates are \\[ r = \\left(\\begin{array}{l} r^{(k)} \\\\ r^{(n-k)} \\end{array} \\right) \\] and the interaction matrix \\[ A = \\begin{pmatrix} A^{(k,k)} &amp; A^{(k, n- k)}\\\\ A^{(n-k,k)} &amp; A^{(n-k, n- k)}\\\\ \\end{pmatrix} \\] where each block \\(A^{(a,b)}\\) contains the effects of the species in set \\(b\\) on the growth of the species in \\(a\\). For feasibility we need: \\[ x^{(k)} = -\\left(A^{(k,k)} \\right)^{-1}r^{(k)} &gt; 0 \\] Now we want to write the condition for the non-invasibility of the resident community by the other species in the metacommunity. For each species in \\((n-k)\\), we need to have a negative growth rate when invading: \\[ r^{(n-k)} + A^{(n-k,k)}x^{(k)} &lt; 0 \\] an equilibrium \\(\\bar{x}\\) for which a) the \\(x^{(k)}\\) is feasible and stable (when considering only the species in \\(k\\)) and b) no other species can invade when rare is called the feasible, stable, non-invasible solution or the saturated equilibrium. 5.2.2 Lyapunov stability and saturated equilibria We have seen in previous section that, whenever there exists a matrix \\(C\\) such that \\(CA + A^T C\\) is negative definite and we have a feasible equilibrium \\(x^\\star\\) then the equilibrium is globally stable. Now we consider the case in which a feasible equilibrium does not exist. However, we can prove that a saturated equilibrium exists and is unique: we have an equilibrium \\(\\bar{x}\\) in which some components are positive and some are zero such that \\(k\\) species coexist at a globally stable equilibrium, and the remaining \\((n-k)\\) species cannot invade it. Following Hofbauer and Sigmund (1998) (section 15.3), we write: \\[ V(x) = -\\sum_i c_i (\\bar{x}_i \\log x_i - x_i) \\] yielding: \\[ \\begin{aligned} \\dfrac{dV(x)}{dt} &amp;= -\\sum_i c_i \\left(\\bar{x}_i \\frac{d \\log x_i}{dt} - \\frac{d x_i}{dt} \\right) \\\\ &amp;= -\\sum_i c_i \\left( \\bar{x}_i - x_i \\right) \\left( r_i + \\sum_j A_{ij} x_j \\right) \\\\ &amp;= -\\sum_i c_i \\left( \\bar{x}_i - x_i \\right) \\left( r_i + \\sum_j A_{ij} (x_j - \\bar{x}_j) + \\sum_j A_{ij} \\bar{x}_j \\right) \\\\ &amp;= \\sum_{i,j} \\left( \\bar{x}_i - x_i \\right) c_i A_{ij} \\left( \\bar{x}_j - x_j \\right) + \\sum_i c_i \\left( \\bar{x}_i - x_i \\right) \\left(r_i + \\sum_j A_{ij} \\bar{x}_j \\right) \\end{aligned} \\] The first term is negative for all \\(x \\neq \\bar{x}\\), and is zero at the saturated equilibrium point. The second term is zero for all \\(\\bar{x}_i &gt; 0\\): \\(r_i + \\sum_j A_{ij} \\bar{x}_j = 0\\), given that \\(\\bar{x}\\) is an equilibrium for the species at positive density; for the remaining species (for which \\(\\bar{x}_i = 0\\)), this amounts to the invasion criterion above, and must therefore be negative. As such \\(V(x)\\) is a Lyapunov function for the system, assuming negative values everywhere but at \\(\\bar{x}\\). 5.3 Top-down assembly To begin our explorations of assembly, we consider the case in which all species are introduced in the habitat at the same time, and at arbitrary initial densities. Here we investigate the simplest case in which dynamics are given by the GLV model, \\(A\\) is symmetric and stable (and therefore Lyapunov Diagonally stable) matrix with random coefficients, and \\(r\\) is a vector of growth rates with random coefficients. For simplicity, we take the off-diagonal elements of \\(A\\) and the growth rates from a normal distribution centered at zero (the same would be found for any distribution symmetric about zero). This case was studied by Serván et al. (2018). First, we are going to consider a trivial case, then simulate a more complex one, and finally outline the proof in Serván et al. (2018). 5.3.1 A trivial case Suppose that the growth rates are drawn from a normal distribution centered at zero, and that the matrix \\(A\\) is diagonal and stable (i.e., species do not interact with each other; each species is self regulating). As such, a species will persist if and only if \\(r_i &gt; 0\\). If we draw the growth rates from any distribution centered at zero, then the probability of having a positive growth rate is \\(1/2\\). Therefore, the number of coexisting species will follow the binomial distribution with parameters \\(n\\) and \\(1/2\\). 5.3.2 Simulating final composition Now, let’s simulate cases in which species do interact with each other. First, we load the functions we’ve written before: # this file contains functions to integrate GLV dynamics # and plot the results source(&quot;dat/general_code_assembly.R&quot;) And then write functions to give us a (barely) stable, symmetric matrix \\(A\\), and random growth rates: # function to build symmetric, Lyapunov Diagonally-stable matrix build_LDstable &lt;- function(n){ A &lt;- matrix(0, n, n) A[upper.tri(A)] &lt;- rnorm(n * (n - 1) / 2) # make symmetric A &lt;- A + t(A) # now find the largest eigenvalue l1A &lt;- max(eigen(A, only.values = TRUE, symmetric = TRUE)$values) if (l1A &gt; 0){ # set the diagonal to make it stable diag(A) &lt;- diag(A) - l1A - 0.01 } return(A) } # function to get random growth rates build_randomr &lt;- function(n){ return(rnorm(n)) } Now, we build a random system with seven species, and integrate the dynamics: set.seed(5) # for reproducibility n &lt;- 7 A &lt;- build_LDstable(n) r &lt;- build_randomr(n) x0 &lt;- runif(n) out &lt;- GLV_dynamics(z0 = x0, A = A, r = r, maxtime = 25, bytime = 0.1) show(plot_dynamics(out)) knitr::kable( out$ts %&gt;% filter(out$ts$time == max(out$ts$time))# %&gt;% #select(-time) ) time species density 25 x1 0.4290121 25 x2 0.2761340 25 x3 0.0000000 25 x4 0.4021960 25 x5 0.0000000 25 x6 0.6452999 25 x7 0.5776737 As you can see, in this case, two species (3 and 5) go extinct, while the other ones reach a feasible equilibrium. Let’s try to start the system with species 3 and 5 at high abundance, to show that the equilibrium is indeed globally stable: x0[3] &lt;- 10 x0[5] &lt;- 10 out &lt;- GLV_dynamics(z0 = x0, A = A, r = r, maxtime = 25, bytime = 0.1) show(plot_dynamics(out)) knitr::kable( out$ts %&gt;% filter(out$ts$time == max(out$ts$time))#%&gt;% #select(-time) ) time species density 25 x1 0.4291312 25 x2 0.2759277 25 x3 0.0000000 25 x4 0.4020638 25 x5 0.0000000 25 x6 0.6454349 25 x7 0.5777422 As you can see, the system still goes to the same equilibrium, with 3 and 5 extinct. Turns out, for this type of system, one does not even need to integrate dynamics: the Lemke–Howson algorithm can be adapted to solve the problem efficiently (Serván et al. 2018). I have coded up the algorithm already, and you can load the function get_final_composition(A, r) by typing: source(&quot;dat/L-H.R&quot;) get_final_composition(A, r) # use LH instead of integrating dynamics [1] 0.4290300 0.2761030 0.0000000 0.4021761 0.0000000 0.6453202 0.5776840 5.3.3 A random zoo In the case above, 5 species persisted. We can ask how many species will coexist in general under this parametrization. A good metaphor is that of the random zoo: take a large zoo, open all the cages, and return after fifty years. How many species will you find? To simulate the random zoo, we take random matrices and random growth rates with \\(n\\) species, and tally the number of coexisting species over several simulations: set.seed(1) n &lt;- 5 nsim &lt;- 2000 results &lt;- tibble(simulation = 1:nsim, ncoexisting = rep(NA, nsim)) for (i in 1:nsim){ # build the matrix and vector A &lt;- build_LDstable(n) r &lt;- build_randomr(n) xstar &lt;- get_final_composition(A, r) results$ncoexisting[i] &lt;- sum(xstar &gt; 0) } pl &lt;- ggplot(data = results) + aes(x = ncoexisting) + geom_bar() + scale_x_continuous(&quot;number of species coexisting&quot;, breaks = 0:10) show(pl) # add binomial distribution tbinom &lt;- data.frame(ncoexisting = 0:n, expectation = nsim * dbinom(0:n, n, 0.5)) pl &lt;- pl + geom_point(data = tbinom, aes(x = ncoexisting, y = expectation)) show(pl) We find again that the number of coexisting species follows the binomial distribution with parameters \\(n\\) and \\(1/2\\) (i.e., exactly the same result found for non interacting species). To prove this fact, let’s begin with showing that the probability of having all species coexisting is \\(1 / 2^n\\). For this, we need \\(x^\\star = -A^{-1}r\\) to be feasible. For each possible \\(A\\) (invertible) and \\(r\\), we have that the vector \\(- A^{-1}r\\) will display a certain pattern of signs. Proving that the probability that all \\(n\\) species coexist is \\(1 / 2^n\\) amounts to proving that all sign patterns are equally probable. To this end, define the matrix \\(D_k = (-1)^{\\delta_{ik}} \\delta_{ij}\\). This is like the identity matrix, but with element \\(k\\) of the diagonal set to \\(-1\\) instead of \\(1\\). We have that: \\[ (D_k A D_k) D_k x^\\star = -D_k r \\] That is, by setting the \\(k^\\text{th}\\) element of \\(D_k\\) to -1, we flip the sign of the \\(k^\\text{th}\\) component of \\(x^\\star\\). For example: set.seed(2) A &lt;- build_LDstable(3) r &lt;- build_randomr(3) # the equilibrium is not feasible solve(A, -r) [1] -11.75292 26.47508 22.73981 # build matrix D_1 D_1 &lt;- diag(c(-1, 1, 1)) # the multiplication changes the sign of a component of the solution # making the equilibrium feasible as.numeric(solve(D_1 %*% A %*% D_1, -D_1 %*% r)) [1] 11.75292 26.47508 22.73981 Because of the symmetry assumption (i.e., we sampled all growth rates and off-diagonal elements from a distribution centered at zero), \\((D_k A D_k)\\) has the same distribution as \\(A\\), and \\(D_k r\\) the same distribution as \\(r\\). In fact, one can see that \\((D_k A D_k)\\) is also a similarity transformation, implying that the eigenvalues of \\(A\\) and \\((D_k A D_k)\\) are the same (i.e., the operation preserves stability): eigen(A)$values [1] -0.010000 -1.601076 -3.665781 eigen(D_1 %*% A %*% D_1)$values [1] -0.010000 -1.601076 -3.665781 We can repeat the operation several times, connecting each possible starting point to the feasible solution. Therefore, the probability of all species coexisting amounts to the probability of having chosen the “right” sequence of \\(D_k\\), which happens with probability \\(1 / 2^n\\). Notice that the same proof holds when the coefficients of \\(A\\) are sampled in pairs from a bivariate distribution (rather than having symmetric matrices), as long as the distribution is centered at zero, and the matrix is Lyapunov-Diagonally stable (Serván et al. (2018)). Using the same argument, one can prove that, under this parametrization, the probability of observing \\(k\\) species coexisting and \\(n -k\\) not being able to invade is exactly \\(\\binom{n}{k} \\frac{1}{2^n}\\) (Serván et al. (2018)). We can complicate the model substantially, but the results are qualitatively unchanged: the more species ones put in, the more species one finds after dynamics have elapsed. The proportion of species surviving depends on the choice of the distributions for the growth rates and interactions. 5.3.4 A random zoo in the wild One might object that the derivations above have no parallel in reality. However, I think that they can be seen as a simplified version of an experiment done routinely by ecologists. Take for example the work of Bittleston et al. (2020). They sampled bacterial communities from ten different pitcher plants, and cultured them in the laboratory on a synthetic medium. They tracked the change of richness in time. This is their Figure 2 (look at panel b): The more the species present at day 3 (i.e., once those with a negative growth rate had disappeared), the more one would find after two months—and the relationship is linear! 5.3.5 Assembly and saturated equilibrium Now let’s make it more complicated: we assemble an ecological community from the ground up. At each step, we introduce a species at low abundance, starting from an empty community. We then compute the new equilibrium, completing a step of the assembly: assembly_one_step &lt;- function(x, r, A){ n &lt;- nrow(A) invader &lt;- sample(1:n, 1) x[invader] &lt;- 0.001 # introduce the invader at low abundance present &lt;- x &gt; 0 # these are the species present now # compute new equilibrium y &lt;- get_final_composition(A[present, present, drop = FALSE], r[present]) x[present] &lt;- y return(x) } Now we can take a species pool along with their parameters, and try to assemble the system until we can no longer add any more species (i.e., until we reach a saturated equilibrium): set.seed(7) n &lt;- 10 A &lt;- build_LDstable(n) r &lt;- build_randomr(n) # start with no species x &lt;- rep(0, n) # assemble for 40 steps and keep track of richness and composition ninvasions &lt;- 40 results &lt;- tibble(invasion = 1:ninvasions, richness = rep(NA, ninvasions), composition = rep(NA, ninvasions)) for (i in 1:ninvasions){ x &lt;- assembly_one_step(x, r, A) results$richness[i] &lt;- sum(x &gt; 0) results$composition[i] &lt;- paste((1:n)[x&gt;0], collapse = &quot;-&quot;) } knitr::kable(head(results)) invasion richness composition 1 0 2 0 3 1 2 4 2 1-2 5 2 1-2 6 2 1-2 pl &lt;- ggplot(results) + aes(x = invasion, y = richness, label = composition) + geom_point() + geom_line() + geom_text(hjust = 0, nudge_y = 0.25, angle = 90)+ ylim(c(0, n * 1.25)) show(pl) Now let’s roll back history and assemble again: # start with no species x &lt;- rep(0, n) # assemble for 40 steps and keep track of richness ninvasions &lt;- 40 results &lt;- tibble(invasion = 1:ninvasions, richness = rep(NA, ninvasions), composition = rep(NA, ninvasions)) for (i in 1:ninvasions){ x &lt;- assembly_one_step(x, r, A) results$richness[i] &lt;- sum(x &gt; 0) results$composition[i] &lt;- paste((1:n)[x&gt;0], collapse = &quot;-&quot;) } knitr::kable(head(results)) invasion richness composition 1 1 4 2 1 4 3 1 4 4 1 4 5 2 4-10 6 2 4-10 pl &lt;- ggplot(results) + aes(x = invasion, y = richness, label = composition) + geom_point() + geom_line() + geom_text(hjust = 0, nudge_y = 0.25, angle = 90)+ ylim(c(0, n * 1.25)) show(pl) As you can see, despite taking a different assembly history, we reach the same final composition. In fact, this is exactly what we would expect if we were to throw all species in the environment at the same time: get_final_composition(A, r) [1] 1.7588344 2.5440743 0.0000000 0.7860178 1.8730535 2.5502055 0.6961259 [8] 1.6956878 0.0000000 0.0000000 x [1] 1.7588344 2.5440743 0.0000000 0.7860178 1.8730535 2.5502055 0.6961259 [8] 1.6956878 0.0000000 0.0000000 As such, given enough time, any assembly history for a symmetric, stable matrix \\(A\\) will eventually reach the final composition represented by the saturated equilibrium (Serván and Allesina (2020)). Interestingly, this is not the case when the matrix is not symmetric. Serván et al. (2018) conjectured however that the probability of finding a system whose final composition cannot be assembled one species at a time decreases rapidly with the size of the pool, as long as \\(A\\) is Lyapunov Diagonally stable. 5.4 Network spandrels What is the network structure of the assembled community vs. that of the initial pool? Can we detect a signature of the forces acting on the community such that some species can persist, while other go extinct? To answer these questions, we start by considering a larger pool of species: set.seed(1) # initial pool A &lt;- build_LDstable(200) r &lt;- build_randomr(200) # final composition xstar &lt;- get_final_composition(A, r) A_pruned &lt;- A[xstar &gt; 0, xstar &gt; 0] r_pruned &lt;- r[xstar &gt; 0] Are the properties of matrix \\(A\\) different from those of the pruned version \\(\\tilde{A}\\)? We probe this in two ways: first, we build a graph with the strongest interactions, and plot it. plot_graph_strong &lt;- function(B, quantile = 0.75){ Bstrong &lt;- abs(B) diag(Bstrong) &lt;- 0 Bstrong[Bstrong &lt; quantile(Bstrong, quantile)] &lt;- 0 gr &lt;- graph_from_adjacency_matrix((Bstrong &gt; 0) * 1, mode = &quot;undirected&quot;) plot(gr, vertex.size=10, vertex.label=NA, layout=layout_with_fr) } plot_graph_strong(A) plot_graph_strong(A_pruned) There seems to be no special structure. A more powerful way to show the same is to plot the eigenvalues of \\(A\\) and \\(\\tilde{A}\\). For a symmetric matrix with off-diagonal elements centered at zero, the eigenvalues should follow Wigner’s semicircle law: plot_eigen &lt;- function(B){ evals &lt;- data.frame(lambda = eigen(B, only.values = TRUE, symmetric = TRUE)$values) ggplot(data = evals) + aes(x = lambda) + geom_histogram(bins = as.integer(nrow(evals) / 10), colour = &quot;black&quot;) } plot_eigen(A) plot_eigen(A_pruned) As such, the matrix of interactions before/after dynamics seem to have the same properties. However, as shown in Serván et al. (2018), the distribution of the growth rates changes in a non-trivial way: toplot &lt;- data.frame(r = r, type = &quot;before&quot;) toplot &lt;- rbind(toplot, data.frame(r = r_pruned, type = &quot;after&quot;)) ggplot(toplot) + aes(x = r, fill = type) + geom_histogram(position = &quot;dodge&quot;) But what if species were to be related to each other? For example, suppose \\(r_i = 1\\) for all species, and build a matrix in which the interactions of species \\(i + 1\\) are obtained by mutating slightly those of species \\(i\\): n &lt;- 200 r &lt;- rep(1, 200) A &lt;- matrix(0, n, n) # set first species A[1, 1] &lt;- -1 # now each species is obtained by mutating the previous one for (i in 2:n){ ai &lt;- A[i -1,] * (1 - 0.05 * runif(n)) A[i, ] &lt;- A[i, ] + ai A[, i] &lt;- A[, i] + ai A[i, i] &lt;- -1 } # make LD-stable l1 &lt;- max(eigen(A, only.values = TRUE, symmetric = TRUE)$values) if (l1 &gt; 0) diag(A) &lt;- diag(A) - l1 * 1.01 Now each species is similar to the previous one: image(A[1:n, n:1]) Perform the pruning, and plot networks and eigenvalues: xstar &lt;- get_final_composition(A, r) A_pruned &lt;- A[xstar &gt; 0, xstar &gt; 0] r_pruned &lt;- r[xstar &gt; 0] plot_graph_strong(A) plot_graph_strong(A_pruned) plot_eigen(A) plot_eigen(A_pruned) Meaning that if our matrix \\(A\\) is structured, we will recover a structured matrix after pruning, while if \\(A\\) is unstructured, we will recover an unstructured matrix. Maynard, Serván, and Allesina (2018) showed that a well-defined network structure could be a “network spandrel” (cfr. Gould and Lewontin (1979) and Solé and Valverde (2006)) arising from the way new species are introduced, rather than a “signature of stability”. 5.5 Bottom-up assembly Mother Nature, of course, does not assemble her networks by throwing n species together in one go. It makes more sense to assume that she adds one species after another through successive invasions. Sigmund (1995) Having considered the case in which all species are thrown into the habitat at the same time (top-down assembly), we consider a process in which we start from the “bare ground” and build our community from the bottom-up. Note that in top-down assembly, any feasible equilibrium can be achieved by starting with the appropriate initial conditions; being slightly less generous, we can think of being able to assemble from the top-down any “persistent” (e.g., stable), feasible community we can form from the pool. It makes therefore sense to ask whether these same states can or cannot be accessed when assembling the community from the ground up. 5.5.1 An assembly graph In GLV, a given (sub-)community has at most one feasible equilibrium; that is, there is no true multi-stability in GLV: we can find the system at different stable states, but they have to differ in composition. Because of this fact, we can devise a scheme to label the possible states our community can be in. We call \\(0\\) the state in which no species are present, \\(1\\) the state in which only species 1 is present, \\(2\\) the state in which only species 2 is present, \\(3\\) the state in which species 1 and 2 are both present, and so on. Practically, we take the community composition to be the base-2 representation of the label. For example, label \\(11\\) in a community of 6 species corresponds to \\(001011\\) (i.e., a state in which species 1, 2, and 4 are present). As this notation makes obvious, for a given pool of \\(n\\) species, we can have up to \\(2^n - 1\\) feasible equilibria. As we saw in Lecture 1, the existence of a feasible equilibrium is a necessary (but not sufficient—we should require also some form of stability/permanence) condition for coexistence. Clearly, any feasible (and persistent/stable) sub-community can be observed by initializing the system at (or, in case of locally/globally stable configurations, close to) the desired densities. On the other hand, unstable configurations will eventually collapse to some other sub-community. As such, we take the labels/states representing stable/persistent communities to be the nodes in a directed graph. Then, we take the edges of this graph to represent invasions, moving the local community from one state to another. To keep the graph simple, we only consider “successful” invasions (i.e., those for which the initial and final state differ), thereby removing the need for “self-loops”. This assembly graph was considered several times in the literature (see for example Law and Morton (1993), Hang-Kwang and Pimm (1993), Schreiber and Rittenhouse (2004), Capitán, Cuesta, and Bascompte (2009)). Here, we follow the approach Serván and Allesina (2020), and note that the assembly graph fully describes the assembly process whenever the assumptions that we’ve made at the onset of our exploration (invasions are rare, invasions are small, dynamics converge to equilibria) are satisfied. When this is the case, we can study the assembly process in its full glory by studying a graph (which definitely sounds more fun!). 5.5.2 How many invasions? First, we might want to think of the problem of invasion. The bottom-up assembly can be seen as a single, massive invasion. At the other extreme, we have assembly proceeding with invasions of a single species at a time. Of course, we can imagine anything in between: species invade in small groups, there is a distribution describing the number of species invading at each step, etc. For example, let’s build the assembly graph for a given set of (random) parameters: we take \\(A\\) to be a symmetric, stable nonpositive matrix (e.g., representing competition between species), and \\(r\\) to be a vector of positive, random growth rates. Let’s build the assembly graph when we consider that species can enter the system only one at a time: source(&quot;dat/general_code_assembly.R&quot;) source(&quot;dat/L-H.R&quot;) # Lemke-Howson algorithm to get saturated equilibrium source(&quot;dat/build_assembly_graph.R&quot;) source(&quot;dat/build_assembly_graph_unstable.R&quot;) # code to build and draw assembly graphs for symmetric matrices set.seed(4) # for reproducibility A &lt;- build_competitive_stable(4) r &lt;- runif(4) assembly_invasion_1 &lt;- build_assembly_graph_unstable(r, A) plot_assembly_graph(assembly_invasion_1$graph, assembly_invasion_1$info) What if we allow for two invasions at a time? assembly_invasion_2 &lt;- build_assembly_graph_unstable(r, A, 2) plot_assembly_graph(assembly_invasion_2$graph, assembly_invasion_2$info) And allowing four invasions in one go (as in top-down assembly): assembly_invasion_4 &lt;- build_assembly_graph_unstable(r, A, 4) plot_assembly_graph(assembly_invasion_4$graph, assembly_invasion_4$info) For simplicity, let’s stick with the case in which only a single species enter in the local community at every invasion event. 5.5.3 Properties of the assembly graph Accessibility: which states can we reach starting from the bare ground, and performing invasions of (say) one species at a time? We call states that can be built in this way “accessible”. Translated into graph properties, we call a state accessible if there is a path leading from the state 0 to the community of interest (“an assembly path”). If all states are accessible, we call the graph itself accessible. States that are not accessible can be reached by top-down, but not bottom-up assembly. Cycles: directed cycles in the graph translate into sub-communities for which invasions drive the system in a cyclic composition (a generalization of rock-paper-scissors!). Assembly endpoints: if a node has no outgoing edges, assembly will stop once the corresponding state has been reached. We call this state an “assembly endpoint”. A more complex type of assembly endpoint is that in which there is a cycle connecting two or more communities, and the cycle as a whole has no outgoing edges. Possible assembly graphs 5.5.4 Assembly graphs for GLV For GLV with symmetric, competitive interactions (actually, for a slightly more general case), Serván and Allesina (2020) proved that: For a species pool of competitors (i.e., a given \\(r &gt; 0\\) and a symmetric matrix \\(A &lt; 0\\)), the bottom-up assembly endpoints are the same as the endpoints for top-down assembly. Moreover, the assembly graph is accessible—therefore we can build any feasible, stable sub-community from the ground up. In fact, for each sub-community we can find the “shortest” assembly path, which we can construct without any extinction. The assembly graph is acyclic, meaning that we will never observe communities with cyclic compositions. Every walk on the assembly graph eventually reaches a sink, and, when \\(A\\) is stable, the sink is unique. This means that for this type of species pool, historical contingencies (Fukami (2015)) are impossible—if we wait for long enough, the system will always reach the same state, thereby erasing any trace of the assembly history. set.seed(5) A &lt;- build_competitive_stable(6) r &lt;- runif(6) ag &lt;- build_assembly_graph_unstable(r, A) plot_assembly_graph(ag$graph, ag$info) Community “29” is composed of species 1, 3, 4, 5. We can assemble this state without extinctions starting from the bare ground: first invade with species 4, sending the community to state “8”; then, add species 3, moving the state to “12”; then add species 5, moving to “28”, and finally add species 1, reaching “29”. This fact has important consequences: for example, we can assemble the final state without the need for “transient invaders” (or “stepping stone species”, i.e., species that allow the assembly to proceed, but then disappear). Recently Amor, Ratzke, and Gore (2020) demonstrated experimentally the occurrence of transient invaders: they co-cultured Corynebacterium ammoniagenes (Ca) and Lactobacillus plantarum (Lp) and showed that one species displaces the other, with the identity of the winner depending on initial conditions (bistability). When the environment is dominated by Lp, Ca cannot invade. However, if first we introduce Pseudomonas chlororaphis (Pc), and then invade with Ca, Lp-dominated environments can be invaded by Ca—and Pc disappears without a trace. This is their Figure 1: 5.5.5 Relationship with Lyapunov functions If a graph has the properties above (acyclic, single source, single sink), then there is a way to order the nodes such that all edges point in the same direction (topological sorting). In this case, we can devise an “energy” associated with each community state such that assembly “maximizes” the quantity, connecting “low-energy” states to “high-energy ones” via invasion. In fact, we can even write down such a function—it is exactly the Lyapunov function devised by MacArthur (1970 Note: the first paper ever in Theoretical Population Biology!) for GLV with symmetric, competitive interactions: \\[ V(x) = 2 \\sum_i r_i x_i + \\sum_{i,j} A_{ij} x_i x_j \\] MacArthur proved that this quantity is maximized through the dynamics when the the equilibrium exists and \\(A\\) is stable. At equilibrium, we find \\(V(x^\\star) = \\sum_i r_i x_i^\\star\\). During assembly, community composition changes such that \\(V(\\bar{x})\\) is maximized through the assembly process. Note that when \\(r_i = 1\\) for all species, then \\(V(\\bar{x})\\) is simply the total biomass in the community. As such, through invasions the total biomass in the community is maximized. plot_assembly_graph(ag$graph, ag$info, TRUE) Now a case with equal growth rates: set.seed(10) A &lt;- build_competitive_stable(5) r &lt;- rep(1, 5) # same growth rates! ag2 &lt;- build_assembly_graph(r, A) plot_assembly_graph(ag2$graph, ag2$info, TRUE) The community “15” is composed of species 1, 2, 3, and 4, while community “30” of species 2, 3, 4, and 5. Let’s compute their biomasses: # community 15 biom_15 &lt;- sum(solve(A[1:4, 1:4], -r[1:4])) print(paste(&quot;Community 15:&quot;, biom_15)) [1] “Community 15: 0.974135821684639” # community 30 biom_30 &lt;- sum(solve(A[2:5, 2:5], -r[2:5])) print(paste(&quot;Community 30:&quot;, biom_30)) [1] “Community 30: 0.855081379845787” This result would have pleased Cowles, Gleason, Odum, and many of the pioneers of succession! For these (restrictive) conditions, assembly is indeed an orderly, predictable process, culminating in a “climax” with a clear ecological interpretation. (For a similar result in a completely different context, see Suweis et al. (2013)). 5.5.6 How many assembly endpoints? What happens when the matrix \\(A\\) is still nonpositive and symmetric, but not stable? In this case, it is Gleason who can laugh—for unstable matrices we can have several assembly endpoints, thereby reinstating the role of chance in determining the ultimate fate of the community. source(&quot;dat/general_code_assembly.R&quot;) source(&quot;dat/build_assembly_graph_unstable.R&quot;) set.seed(5) n &lt;- 10 A &lt;- build_competitive_unstable(n) r &lt;- runif(n) tmp &lt;- build_assembly_graph_unstable(r, A) plot_assembly_graph(tmp$graph, tmp$info, TRUE) Note that the Lyapunov function still holds (locally): when moving on the graph, the “energy” is always increased. The number of “assembly endpoints” (i.e., saturated equilibria) depends on the stability of the matrix—what if we reduce the stability even further? # these are the diagonal elements diag(A) [1] -1.1244467 -1.7740170 -0.9204892 -1.4486570 -0.1384223 -2.9264971 [7] -0.3754522 -2.0440457 -1.1836697 -0.2244013 # and these the eigenvalues eigen(A, symmetric = TRUE, only.values = TRUE)$values [1] 6.6159328 5.3603879 3.1108237 1.1950182 -0.1931400 -0.5697615 [7] -2.2641869 -3.2814435 -3.5994749 -18.5342540 Let’s add \\(0.13\\) to the diagonal (such that the fifth species has almost no self-regulation)—this shifts all of the eigenvalues to the right: A2 &lt;- A diag(A2) &lt;- diag(A2) + 0.13 eigen(A2, symmetric = TRUE, only.values = TRUE)$values [1] 6.74593280 5.49038786 3.24082373 1.32501822 -0.06313999 [6] -0.43976150 -2.13418688 -3.15144351 -3.46947493 -18.40425400 tmp &lt;- build_assembly_graph_unstable(r, A2) plot_assembly_graph(tmp$graph, tmp$info, TRUE) Similarly, by shifting the eigenvalues to the left, we can get access larger communities: A3 &lt;- A diag(A3) &lt;- diag(A3) - 2 tmp &lt;- build_assembly_graph_unstable(r, A3) plot_assembly_graph(tmp$graph, tmp$info, TRUE) Interestingly, how the number of assembly endpoints changes when we change the parameters of the model is an open problem—in fact we haven’t even characterized the worse-case scenario. See Biroli, Bunin, and Cammarota (2018) for a derivation showing that they should be growing exponentially with size. 5.5.7 Build your own assembly graph! Building the assembly graph is computationally very expensive, even with all these results at hand. Fortunately, we do not need to integrate the dynamics (a point that was greatly debated in the literature, see Morton et al. (1996) for one of the rare cases in which a debate ends up with consensus between opposing factions). Currently, the algorithm can be sketched as: for each of the \\(2^n\\) possible sub-communities (ranging from bare ground to all species present), determine whether the sub-community is feasible and stable (this is the most computationally expensive step); now go through all the feasible, stable communities; for each determine the “neighbor” communities that can be reached with (say, one) invasion(s). call \\(S\\) the feasible, stable community we are considering, and add species \\(j\\) (or multiple species), and check that \\(j\\) can invade when rare. If it cannot, move to the next neighbor; If it can, there are two cases: if the community \\(\\{S, j\\} = S&#39;\\) is feasible and stable, draw an edge \\(S \\to S&#39;\\) if the community \\(\\{S, j\\} = S&#39;\\) is not feasible and stable, the system will collapse to a smaller sub-community; to determine which sub-community it will collapse to, check all the possible sub-communities of \\(S&#39;\\), and take the one with the greatest \\(V(x^\\star)\\), \\(S&#39;&#39;\\). Draw an an edge \\(S \\to S&#39;&#39;\\) Can a better (faster, more efficient) algorithm be devised? Homework 5 Build the assembly graph for a GLV model in which the growth rates of all species are the same, and interactions are given by phylogenetic relatedness. In particular, consider an ultrametric phylogenetic tree \\(T\\), and the “variance-covariance” matrix induced by the tree, \\(\\Sigma\\). Because the tree is ultrametric, then \\(\\Sigma_{ii} = 1\\) for all \\(i\\). The off-diagonal elements \\(\\Sigma_{ij}\\) express the proportion of shared ancestry (and as such \\(1\\geq \\Sigma_{ij} \\geq 0\\)). Take the GLV model: \\[ \\dfrac{dx}{dt}=D(x)(1 - \\Sigma x) \\] Notice that \\(\\Sigma\\) is positive (semi-)definite by construction. Now build the assembly graph: does it have any interesting property? 5.5.8 Conclusions We have explored the problem of ecological assembly by working with the Generalized Lotka-Volterra model and three main assumptions: 1) invasions are rare, such that invaders always find the local community at the attractor; 2) invasion sizes are small; and 3) dynamics always lead to equilibria–thereby allowing us to determine the unique outcome of any invasion event. These three assumptions made the study of assembly tractable, and yet not trivial, allowing us to map the complex dynamics of the system into an assembly graph: the properties of this graph translate directly into ecological properties of the assembly process. For competitive Lotka-Volterra with symmetric interactions, when the interaction matrix is stable, all assembly paths will eventually lead to the same state (the “saturated equilibrium” we’ve seen in Lectures 1 and 2). In this case, the history that led to the community cannot be reconstructed from the final state. When the matrix of interactions is unstable, on the other hand, the system can end up in different places depending on the history of assembly. We have also found that for these cases, top-down (all in one go) and bottom-up (sequential) assembly can reach exactly the same states. Top-down assembly experiments (e.g., with bacterial communities) are much easier to perform than bottom-up ones, and I believe that this approach has been underexploited (both theoretically, and experimentally). Much more work remains to be done to reach a general theory of ecological assembly (even for GLV), but the results shown here provide a good springboard, and an expectation, for the study of more complex cases. References "],
["predicting-coexistence-in-ecological-communities.html", "Lecture 6 Predicting coexistence in ecological communities 6.1 Background: Diversity and Ecosystem Functioning 6.2 Synthetic communities using the GLV model 6.3 Total biomass 6.4 Hyperplanes 6.5 Fitting real data 6.6 Predicting real data out of fit", " Lecture 6 Predicting coexistence in ecological communities Lesson plan: 1. We consider the problem of co-culturing several species taken from a pool in all possible combinations. 1. This type of experiments has been conducted to test hypotheses on the relationship between diversity and ecosystem functioning. 1. The number of combinations grows quickly with the size of the pool, making experiments difficult. 1. The difficulty is compounded by the fact that not all combinations are expected to lead to coexistence. 1. We parameterize a simple statistical model, and draw a connection with GLV dynamics. 1. We test whether our model is able to predict the outcomes of experiments out-of-fit. 6.1 Background: Diversity and Ecosystem Functioning Ecologists have performed large experiments in which different assemblages of species are co-cultured. These experiments have been conducted with plants (for example, Biodiversity Ecosystem Functioning experiments e.g., Hector et al. (1999) Tilman et al. (2001), Cadotte (2013)) and in the laboratory using protozoan, algae or bacteria. Two commonly-encountered problems in this type of experiments have to to with the scaling of the number of experiments with the number of species, and with the probability of coexistence. Scale: How many communities can we form from a pool of \\(n\\) species? We can culture a single species in isolation (\\(n\\) possibilities), two species in pair (\\(n(n-1) / 2\\) possibilities), and so on. The total is therefore: \\[ \\sum_{j=1}^n \\binom{n}{j} = 2^n -1 \\] And this is only considering the presence/absence of each species! Moreover, we might want to vary the initial conditions (e.g., starting two species at low/high abundance, equal abundance, high/low abundace), etc. Clearly, this makes trying all possible combinations unfeasible when \\(n\\) is large enough. For example, for 10 species we can form 1023 assemblages, while with 20 more than a million! Coexistence: even if we could try all possible experiments, many assemblages would collapse to smaller communities because of extinctions. For example, pairs could become monocultures, triplets become pairs or monocultures, etc. As such, even if we were to try all possible combinations, we would end up observing a smaller set of “final communities”. To guide experimentation, we need a way to be able to predict the (probable) outcome of experiments without having to run them all. Here we attempt to do so by examining a handful of experimental results, and using these data to parametrize a statistical model. The model provides a way to navigate the enormous space of possibilities, thereby suggesting “good” experiments that yield a large probability of coexistence. 6.2 Synthetic communities using the GLV model To set the stage for deriving a statistical model that can deal with the problems above, we start by simulating the communities that can be formed from a pool of \\(n\\) species using the GLV model. First, we need a way to index our communities. As done before, we take a vector \\(p\\) reporting the presence/absence of a given species in a community. To this end, we associate a label \\(k \\in \\{1, \\ldots, 2^n -1\\}\\) with each possible community. If only taxon 1 is present (\\(p = [1,0,0,\\ldots,0]\\)), then \\(k = 1\\), if only taxon 2 is present (\\(p =[0,1,0,\\ldots,0]\\)) then \\(k = 2\\), if both taxa 1 and 2 are part of the community, \\(k = 3\\) (\\(p = [1,1,0,\\ldots,0]\\)); in general, \\(k = \\sum_{i = 1}^n p_i 2^{(i-1)}\\) where \\(p_i = 1\\) if taxon \\(i\\) is in the community, and \\(p_i = 0\\) otherwise. We can then cycle through each of the \\(2^n - 1\\) assemblages that can be formed, and determine whether the species will coexist or not in our experiment. For simplicity, we report as coexisting any set of species for which a) the GLV equilibrium is feasible, and b) it is locally stable. We collect all the communities that are coexisting along with the abundance of all species in the matrix \\(E\\). In R: set.seed(3) # take a random matrix of interactions: # -Aij &lt;- U[0,1]; -Aii &lt;- Sqrt(2) + U[0,1] # all interactions are competitive n &lt;- 5 A &lt;- -matrix(runif(n * n), n, n) diag(A) &lt;- diag(A) - sqrt(2) # choose positive growth rates r &lt;- runif(n) + 0.5 Now go through all possible combinations: E &lt;- matrix(0, 0, n) # matrix containing all communities x_template &lt;- rep(0, n) # template for row of E for (k in 1:(2^n - 1)){ p &lt;- as.integer(intToBits(k)[1:n]) # from index to presence/absence presence &lt;- p &gt; 0 A_k &lt;- A[presence, presence, drop = FALSE] r_k &lt;- r[presence] # check if equilibrium is feasible x_k_star &lt;- solve(A_k, -r_k) if (all(x_k_star &gt; 0)){ # check if equilibrium is locally stable # a) build community matrix M &lt;- x_k_star * A_k # b) compute eigenvalues eM &lt;- eigen(M, only.values = TRUE)$values # c) check stability if (all(Re(eM) &lt; 0)){ # we have a feasible, stable equilibrium # add to the set tmp &lt;- x_template tmp[presence] &lt;- x_k_star E &lt;- rbind(E, tmp) } } } rownames(E) &lt;- NULL knitr::kable( as.data.frame(E) ) V1 V2 V3 V4 V5 0.8160172 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.7146465 0.0000000 0.0000000 0.0000000 0.6791728 0.3582477 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.7238026 0.0000000 0.0000000 0.6215352 0.0000000 0.6009974 0.0000000 0.0000000 0.0000000 0.5020196 0.6478907 0.0000000 0.0000000 0.5350404 0.2430998 0.5813274 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.4587203 0.0000000 0.6216900 0.0000000 0.0000000 0.3705821 0.0000000 0.0000000 0.6939825 0.0000000 0.2853194 0.0000000 0.5053259 0.4292078 0.0000000 0.2798359 0.0000000 0.0000000 0.0000000 0.6113454 0.3113519 0.0000000 0.5088350 0.0000000 0.5297602 0.2588800 0.0000000 0.0000000 0.5113268 0.5771994 0.1918210 0.0000000 0.4278506 0.3044843 0.5224118 0.1960531 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.7605268 0.7455409 0.0000000 0.0000000 0.0000000 0.4886529 0.0000000 0.7097723 0.0000000 0.0000000 0.4892822 0.6109202 0.3901920 0.0000000 0.0000000 0.3886299 0.0000000 0.0000000 0.6977346 0.0000000 0.3937544 0.5908223 0.0000000 0.5915668 0.0000000 0.2341095 0.0000000 0.5049339 0.6318646 0.0000000 0.2354156 0.5062650 0.2591997 0.5729480 0.0000000 0.1756769 0.0000000 0.0000000 0.0000000 0.4309479 0.6875147 0.5556349 0.0000000 0.0000000 0.3598731 0.4969348 0.0000000 0.6907495 0.0000000 0.2679023 0.4511633 0.4476631 0.4567147 0.0000000 0.2658808 0.3776961 0.0000000 0.0000000 0.5887242 0.3006418 0.4001216 0.4749396 0.0000000 0.5198836 0.2551261 0.2708252 0.0000000 0.5139182 0.5636548 0.1848845 0.2365139 0.4000232 0.3200119 0.5151320 0.1902248 0.1893434 6.3 Total biomass Our simulated communties have much in common with BEF experiments. For example, plotting the species richness on the x-axis and the total biomass on the y-axis, we recover the typical pattern found in real experiments (Hector et al. (1999), Tilman et al. (2001), Cadotte (2013)): library(tidyverse) # plotting and wrangling total_biomass &lt;- rowSums(E) species_richness &lt;- rowSums(E &gt; 0) BEF &lt;- tibble(species_richness = species_richness, total_biomass = total_biomass) ggplot(data = BEF) + aes(x = species_richness, y = total_biomass) + geom_point() + geom_smooth() + my_theme ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; showing a modest increase in total biomass with increasing species richness. 6.4 Hyperplanes We can rewrite the GLV model as: \\[ \\begin{aligned} \\dfrac{dx(t)}{dt} &amp;= D(x(t))(r + A x(t))\\\\ &amp;= D(r) D(x(t))(1 + B x(t)) \\end{aligned} \\] where we have \\(b_{ij} = a_{ij} / r_i\\). The equilibrium for each subset of species \\(k\\) (if it exists) can be found as \\[x^{(k)\\star}= -(B^{(k)})^{-1} 1^{(k)}\\] where \\((B^{(k)})^{-1}\\) is the inverse of the \\(B^{(k)}\\) sub-matrix of \\(B\\) in which only the rows/columns belonging to \\(k\\) are retained, and \\(1^{(k)}\\) is a vector of ones with length equal to the number of species in \\(k\\). We now want to link the matrix \\(B\\) with the results of the experiments, stored in matrix \\(E\\). Call \\(x^{(k)}_i\\) the recorded density of taxon \\(i\\) in community \\(k\\) (i.e., stored in one of the rows of \\(E\\)). We know that, whenever a feasible equilibrium exist, \\[ (B^{(k)}) x^{(k)}= 1^{(k)} \\] which can be seen as a system of as many equations as there are species in \\(k\\). Then, we can build a matrix \\(P\\) where each row represents an equation of form: \\[ \\sum_{j \\in k} b_{ij} x_j^{(k)} = 1 \\] and we have a column for each coefficient in \\(B\\). For example, take three taxa, and suppose that we can culture each in isolation, and that the all assemblages coexist when co-cultured. We can write 12 equations: monocultures (\\(k \\in \\{1, 2, 4\\}\\)) give rise to a single equation; co-cultures of two taxa to two equations each (\\(k \\in \\{3, 5, 6 \\}\\)); and communities with three taxa to three independent equations (\\(k = 7\\)). Here are the 12 equations we can write: \\[ \\begin{aligned} b_{11} x_1^{(1)} &amp;= 1\\\\ b_{22} x_2^{(2)} &amp;= 1\\\\ b_{11} x_1^{(3)} + b_{12}x_2^{(3)} &amp;= 1\\\\ b_{21} x_1^{(3)} + b_{22}x_2^{(3)} &amp;= 1\\\\ b_{33} x_3^{(4)} &amp;= 1\\\\ b_{11} x_1^{(5)} + b_{13} x_3^{(5)} &amp;= 1\\\\ b_{31} x_1^{(5)} + b_{33} x_3^{(5)} &amp;= 1\\\\ b_{22} x_2^{(6)} + b_{23} x_3^{(6)} &amp;= 1\\\\ b_{32} x_2^{(6)} + b_{33} x_3^{(6)} &amp;= 1\\\\ b_{11} x_1^{(7)} + b_{12} x_2^{(7)} + b_{13} x_3^{(7)} &amp; = 1\\\\ b_{21} x_1^{(7)} + b_{22} x_2^{(7)} + b_{23} x_3^{(7)} &amp; = 1\\\\ b_{31} x_1^{(7)} + b_{32} x_2^{(7)} + b_{33} x_3^{(7)} &amp; = 1 \\end{aligned} \\] We can summarize the equations in a more compact form as \\(P v(B)=1\\): \\[ \\begin{pmatrix} x_1^{(1)} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; x_2^{(2)} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ x_1^{(3)} &amp; x_2^{(3)} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; x_1^{(3)} &amp; x_2^{(3)} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; x_3^{(4)} \\\\ x_1^{(5)} &amp; 0 &amp; x_3^{(5)} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; x_1^{(5)} &amp; 0 &amp; x_3^{(5)} \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; x_2^{(6)} &amp; x_3^{(6)} &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; x_2^{(6)} &amp; x_3^{(6)}\\\\ x_1^{(7)} &amp; x_2^{(7)} &amp; x_3^{(7)} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; x_1^{(7)} &amp; x_2^{(7)} &amp; x_3^{(7)} &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; x_1^{(7)} &amp; x_2^{(7)} &amp; x_3^{(7)} \\end{pmatrix} \\begin{pmatrix} b_{11}\\\\ b_{12}\\\\ b_{13}\\\\ b_{21}\\\\ b_{22}\\\\ b_{23}\\\\ b_{31}\\\\ b_{32}\\\\ b_{33} \\end{pmatrix} = \\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1 \\end{pmatrix} \\] where \\(v(B)\\) is a vectorized version of \\(B\\). Because we have \\(n 2^{n-1} = 12\\) equations, and \\(n^2 = 9\\) variables, in principle the system can be solved. Moore-Penrose pseudoinverses For a \\(n \\times n\\) matrix \\(A\\), the inverse is determined (when it exists), as a matrix \\(A^{-1}\\) such that \\(AA^{-1} = A^{-1}A = I\\). A square matrix is invertible if its determinant (remember, the product of its eigenvalues) is nonzero. A matrix with determinant zero is called singular or degenerate and has no inverse. Singular matrices are rare, in the sense that a random matrix is “almost never” singular (this can be stated in a precise mathematical way). An invertible matrix has full rank (i.e., the rows [columns] are all linearly independent). Can we find a matrix that “works like” an inverse when \\(A\\) is singular (or not square)? Turns out, we can find a matrix \\(A^+\\) that satisfies these four criteria: \\[ AA^+A = A \\] \\[ A^+AA^+ = A^+ \\] \\[AA^+ = (AA^+)^T\\] \\[A^+A = (A^+A)^T\\] Suppose that \\(A\\) has linearly independent columns (i.e., it is of full column rank), then \\(A^T A\\) has full rank and is therefore invertible. In this case, we can compute the left pseudoinverse as \\[A^+ = (A^T A)^{-1}A^T\\] This is called the left inverse because \\(A^+A= (A^T A)^{-1}A^TA=I\\). When \\(A\\) has independent rows, one can compute the right inverse. Note that a generalized inverse \\(A^+\\) exists even if \\(A\\) is not of full column nor row rank, but in this case it is not unique. Application: least squares The pseudo-inverse can be used to find the least-squares solution of a system of linear equations. For example, in linear regression, we want to model a set of \\(n\\) observations, \\(y\\), as a linear function of measured predictors \\(X\\) (for example, a matrix with \\(n\\) rows [one for each observation], and \\(k\\) columns [the number of measured predictors for each observation, typically with \\(k \\ll n\\)]) and some parameters \\(b\\). The linear system \\[ Xb = y \\] has no solution (for example, because \\(X\\) is rectangular). If \\(X\\) were to be invertible, finding the parameters would be easy: \\[ \\hat{b} = X^{-1}y \\] we can attempt the same approach using the pseudo-inverse: \\[ \\hat{b} = X^{+}y \\] in particular, it can be proven that the solution \\(\\hat{b}\\) minimizes the SSQ: call \\(\\hat{y} = X \\hat{b}\\), then the solution \\(\\hat{b}\\) is the parameter choice minimizing \\(SSQ = \\sum_i (y_i -\\hat{y}_i)^2\\). One can recognize the equation above as a linear regression, and choose \\(\\hat{v}(B) = P^{+}1\\) (where \\(P^{+}\\) is the Moore-Penrose pseudo-inverse of \\(P\\)). Before doing that, however, we can try to simplify the calculation by rearranging the rows of \\(P\\): \\[ \\begin{pmatrix} x_1^{(1)} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ x_1^{(3)} &amp; x_2^{(3)} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ x_1^{(5)} &amp; 0 &amp; x_3^{(5)} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ x_1^{(7)} &amp; x_2^{(7)} &amp; x_3^{(7)} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; x_2^{(2)} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; x_1^{(3)} &amp; x_2^{(3)} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; x_2^{(6)} &amp; x_3^{(6)} &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; x_1^{(7)} &amp; x_2^{(7)} &amp; x_3^{(7)} &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; x_3^{(4)} \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; x_1^{(5)} &amp; 0 &amp; x_3^{(5)} \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; x_2^{(6)} &amp; x_3^{(6)}\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; x_1^{(7)} &amp; x_2^{(7)} &amp; x_3^{(7)} \\end{pmatrix} \\begin{pmatrix} b_{11}\\\\ b_{12}\\\\ b_{13}\\\\ b_{21}\\\\ b_{22}\\\\ b_{23}\\\\ b_{31}\\\\ b_{32}\\\\ b_{33} \\end{pmatrix} = \\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1 \\end{pmatrix} \\] Showing that the matrix \\(P\\) is block-diagonal, with blocks \\(P_i = E_i\\), where \\(E_i\\) is the matrix \\(E\\) in which only the rows in which species \\(i\\) is present are retained. As such, we can solve for the matrix \\(B\\) one row at a time: \\[ \\begin{pmatrix} x_1^{(1)} &amp; 0 &amp; 0 \\\\ x_1^{(3)} &amp; x_2^{(3)} &amp; 0 \\\\ x_1^{(5)} &amp; 0 &amp; x_3^{(5)} \\\\ x_1^{(7)} &amp; x_2^{(7)} &amp; x_3^{(7)} \\end{pmatrix} \\begin{pmatrix} b_{11}\\\\ b_{12}\\\\ b_{13} \\end{pmatrix} = \\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 1 \\end{pmatrix} \\] For example: # rescaled matrix B &lt;- 1 / r * A # now try to recover B from matrix E fitted_B &lt;- matrix(0, n, n) for (i in 1:n){ # take the matrix Ei Ei &lt;- E[E[,i] &gt; 0, , drop = FALSE] # solve for the row (MASS::ginv computes the pseudoinverse) fitted_B[i,] &lt;- -rowSums(MASS::ginv(Ei)) } ggplot(data = tibble(real = as.vector(B), fitted = as.vector(fitted_B))) + aes(x = real, y = fitted) + geom_point() + geom_abline(slope = 1, intercept = 0) Notice that in general the system of equations is over-determined. As such, we can fit using a subset of the experiments, and then predict the rest of the experiments out-of-fit. For example, let’s fit again using the information on monocultures and pairs only, and then predict experiment 31, in which all species should coexist: E_partial &lt;- E[rowSums(E&gt; 0) &lt; 3, ] fitted_B &lt;- matrix(0, n, n) for (i in 1:n){ # take the matrix Ei Ei &lt;- E_partial[E_partial[,i] &gt; 0, , drop = FALSE] # solve for the row fitted_B[i,] &lt;- -rowSums(MASS::ginv(Ei)) } ggplot(data = tibble(real = as.vector(B), fitted = as.vector(fitted_B))) + aes(x = real, y = fitted) + geom_point() + geom_abline(slope = 1, intercept = 0) print(&quot;predicted&quot;) [1] “predicted” solve(fitted_B, - rep(1, n)) [1] 0.4000232 0.3200119 0.5151320 0.1902248 0.1893434 print(&quot;observed&quot;) [1] “observed” E[(2^n -1), ] [1] 0.4000232 0.3200119 0.5151320 0.1902248 0.1893434 The equation \\(E_i B_i = -1\\) shows that all the equilibria of species \\(i\\) in a GLV system are arranged on a hyperplane. Homework 6a As seen above, for GLV, the matrix \\(B = D(r)^{-1}A\\) encodes all the equilibria (feasible or unfeasible) for the model. Knowing \\(B\\) is therefore all we need to determine the existence of a feasible equilibrium for any community we can form from the pool. Does the matrix \\(B\\) informs us on invasibility? Take a sub-community \\(k\\) resting at its feasible equilibrium point. Can one determine whether a species \\(i \\notin k\\) can invade when rare by inspecting the matrix \\(B\\)? When does the matrix \\(B\\) can be used to determine the stability of the feasible equilibrium for a subset \\(k\\)? 6.5 Fitting real data Having played with synthetic data, we can start thinking about data stemming from real experiments. In particular, consider the linear, additive model: \\[ x_i^{(k)} = \\gamma_i - \\sum_{j\\neq i} \\theta_{ij} x_j^{(k)} \\] where \\(x_i^{(k)}\\) is the density of species \\(i\\) in community \\(k\\), \\(\\gamma_i\\) models the density of \\(i\\) when grown in isolation, and the parameters \\(\\theta_{ij}\\) model how the density of \\(i\\) is influenced by the other species in community \\(k\\). Dividing both sides by \\(\\gamma_i\\) and rearranging: \\[ \\sum_{j\\neq i} (\\theta_{ij} /\\gamma_i) x_j^{(k)} + (1/{\\gamma_i}) x_i^{(k)}= \\sum_j b_{ij} x_j^{(k)} = 1 \\] which is exactly the same system of equations found above. As such, fitting a linear, addittive model for the biomass of each species in each plot is equivalent to finding the equilibrium strcuture of a GLV model that approximates the data. One thing to consider when modeling real data, contrary to simulated data, is the structure of the errors. For example, empirical data often contain replicates that reach slightly different densities. Moreover, what is typically done in these types of experiments is to sort and measure biomass for a section of each plot, and then to multiply to extrapolate the biomass for the whole plot. As such, if the error is normally distributed for the sub-plot, then it’s going to be lognormally distributed for the whole plot. Furthermore, we need to link the rows of matrix \\(P\\) above, because when we make an error in measuring \\(x_j^{(k)}\\), the value is reported over several values. Following Maynard, Miller, and Allesina (2020), we do the following: Propose a matrix \\(B\\) Compute the predicted abundance for all species in all observed assemblages (call them \\(\\tilde{x}_j^{(k)}\\)) Compute the SSQ: \\(\\sum_{j, k} (\\log x_j^{(k)} - \\log \\tilde{x}_j^{(k)})^2\\) Search numerically for the matrix \\(B\\) minimizing the SSQ # constant to penalize solutions with negative # abundances penalization &lt;- 100000 # main fitting function # input: # - matrix E as above (the data) # - proposed matrix B # output: # - predicted matrix \\tilde{E} # - SSQ compute_SSQ &lt;- function(B, E){ tildeE &lt;- E ones &lt;- rep(1, ncol(B)) # vector of 1s for (i in 1:nrow(E)){ presence &lt;- E[i, ] &gt; 0 # use internal calls to speed up calculation predicted_x &lt;- .Internal(La_solve(B[presence, presence, drop = FALSE], ones[presence], 10^-6)) tildeE[i, presence] &lt;- predicted_x } # now compute SSQ observed &lt;- E[E &gt; 0] # penalize negatives predicted &lt;- tildeE[E &gt; 0] predicted[predicted &lt; 0] &lt;- penalization return(list(B = B, E = E, tildeE = tildeE, SSQ = sum((log(predicted) - log(observed))^2) )) } # for numerical minimization to_minimize &lt;- function(b, E){ n &lt;- ncol(E) return(compute_SSQ( matrix(b, n, n), E )$SSQ) } To test this method, we are going to use the data from Kuebbing et al. (2015), who co-cultured four species of plant in 14 out of 15 possible combinations. Let’s load the data url &lt;- &quot;https://github.com/dsmaynard/endpoints/raw/master/data/Kuebbing_plants/natives.csv&quot; E &lt;- as.matrix(read_csv(url)) ## ## ── Column specification ──────────────────────────────────────────────────────────── ## cols( ## as = col_double(), ## fa = col_double(), ## la = col_double(), ## po = col_double() ## ) head(E) as fa la po [1,] 1.4711 0 0 0 [2,] 1.7968 0 0 0 [3,] 1.8993 0 0 0 [4,] 2.0634 0 0 0 [5,] 2.2665 0 0 0 [6,] 2.3062 0 0 0 tail(E) as fa la po [135,] 1.1219 1.8011 0.2390 1.4065 [136,] 1.4751 1.3486 0.2474 1.5491 [137,] 0.6021 1.9389 0.1817 2.7487 [138,] 0.8973 1.6002 0.1156 3.2293 [139,] 3.0384 1.4442 0.4590 1.5490 [140,] 2.9240 2.3903 0.2379 4.3230 And let’s try to find a good numerical solution starting from the identity matrix: set.seed(2) B &lt;- matrix(0, 4, 4) diag(B) &lt;- 1 tmp &lt;- optim(par = as.vector(B), fn = to_minimize, E = E, method = &quot;BFGS&quot;) best_B &lt;- matrix(tmp$par, 4, 4) solution &lt;- compute_SSQ(best_B, E) Now let’s write code to show a nice plot of the predicted vs. observed values for all communities: plot_solution &lt;- function(solution, oof = NULL){ # add a column with community composition spnames &lt;- colnames(solution$E) community &lt;- apply(solution$E, 1, function(x) paste(spnames[x &gt; 0], collapse = &quot;_&quot;)) # work with observed data E &lt;- as_tibble(solution$E) %&gt;% add_column(community = community) %&gt;% mutate(experiment = row_number()) toplot &lt;- E %&gt;% gather(species, observed_biomass, -experiment, -community) %&gt;% filter(observed_biomass &gt; 0) # now the predicted data if (is.null(oof)){ tildeE &lt;- as_tibble(solution$tildeE) %&gt;% add_column(community = community) %&gt;% gather(species, predicted_biomass, -community) %&gt;% distinct() } else { tildeE &lt;- as_tibble(solution$tildeE) %&gt;% add_column(community = community, oof = oof) %&gt;% gather(species, predicted_biomass, -community, -oof) %&gt;% distinct() } # join the two data sets toplot &lt;- toplot %&gt;% inner_join(tildeE, by = c(&quot;community&quot;, &quot;species&quot;)) %&gt;% filter(observed_biomass &gt; 0) if (is.null(oof)){ pl &lt;- ggplot(data = toplot) + aes(x = species, fill = species) + geom_violin(aes(y = observed_biomass), draw_quantiles = 0.5, scale = &quot;width&quot;) + geom_point(aes(y = predicted_biomass)) + facet_wrap(~community, scales = &quot;free_y&quot;) + scale_y_log10(&quot;biomass&quot;) } else { pl &lt;- ggplot(data = toplot) + aes(x = species, fill = species) + geom_violin(aes(y = observed_biomass, alpha = I(1 - 0.9 * oof)), draw_quantiles = 0.5, scale = &quot;width&quot;) + geom_point(aes(y = predicted_biomass)) + facet_wrap(~community, scales = &quot;free_y&quot;) + scale_y_log10(&quot;biomass&quot;) } return(pl) } plot_solution(solution) 6.6 Predicting real data out of fit Exactly as done for the GLV simulated data, we can attempt fitting the matrix \\(B\\) using only part of the experimental data, and then predict the rest out-of-fit. This is a powerful test to make sure that a) we have chosen a good structure for the statistical model, and b) we are not overfitting. For example, let’s try to predict all triplets out of fit. First, we fit the model using only the information about monocultures, pairs, and the quadruplet (11 experiments); then, we use the fitted matrix to predict all of the data and plot: set.seed(1) B &lt;- matrix(0, 4, 4) diag(B) &lt;- 1 Enotriplets &lt;- E[rowSums(E &gt; 0) != 3, ] oof &lt;- rowSums(E &gt; 0) == 3 tmp &lt;- optim(par = as.vector(B), fn = to_minimize, E = Enotriplets, method = &quot;BFGS&quot;) best_B_oof &lt;- matrix(tmp$par, 4, 4) solution_oof &lt;- compute_SSQ(best_B_oof, E) plot_solution(solution_oof, oof) Repeat excluding all the pairs: set.seed(1) B &lt;- matrix(0, 4, 4) diag(B) &lt;- 1 Enopairs &lt;- E[rowSums(E &gt; 0) != 2, ] oof &lt;- rowSums(E &gt; 0) == 2 tmp &lt;- optim(par = as.vector(B), fn = to_minimize, E = Enopairs, method = &quot;BFGS&quot;) best_B_oof2 &lt;- matrix(tmp$par, 4, 4) solution_oof2 &lt;- compute_SSQ(best_B_oof2, E) plot_solution(solution_oof2, oof) Of course, we might push this too far. For example, a popular way to attempt parameterizing models is to consider only monocultures and pairs: set.seed(1) B &lt;- matrix(0, 4, 4) diag(B) &lt;- 1 Eonlymonopairs &lt;- E[rowSums(E &gt; 0) &lt; 3, ] oof &lt;- rowSums(E &gt; 0) &gt;= 3 tmp &lt;- optim(par = as.vector(B), fn = to_minimize, E = Eonlymonopairs, method = &quot;BFGS&quot;) best_B_oof3 &lt;- matrix(tmp$par, 4, 4) solution_oof3 &lt;- compute_SSQ(best_B_oof3, E) plot_solution(solution_oof3, oof) You can see that we predict a lack of coexistence for the system with all four species, while experimentally we have observed coexistence in all ten replicates. Maynard, Miller, and Allesina (2020) have demonstrated that experimental designs mixing high- and low-abundance experiments provide the best fit while minimizing the number of experiments. References "],
["game-theory-and-replicator-dynamics.html", "Lecture 7 Game theory and replicator dynamics 7.1 Game theory 7.2 Two-player matrix games 7.3 Mixed strategies 7.4 Nash Equilibria 7.5 Evolutionary stable strategies 7.6 Replicator dynamics", " Lecture 7 Game theory and replicator dynamics 7.1 Game theory We briefly introduce the study of mathematical models of games, and their relations to the GLV model. While the origin of game theory can be traced back to the 1700s, modern game theory started with von Neumann’s paper On the Theory of Games of Strategy, published in 1928, and with the subsequent 1944 book with Morgensten Theory of Games and Economic Behavior. John Nash’s paper (Nash 1950) introduced the notion of a Nash Equilibrium (NE). Originally, game theory was studied by economists and mathematicians, but with the 1973 book Evolution and the Theory of Games (Maynard Smith 1982), John Maynard Smith showed how the same tools could be used to study evolutionary dynamics, introducing the influential concept of an Evolutionary Stable Strategy (ESS). Evolutionary game theory was greatly advanced through the introduction of the Replicator Equation (RE), which, as we will see later, has strong connection with the GLV model. For a detailaed introduction to evolutionary game theory see Hofbauer and Sigmund (1998). History: John Maynard Smith (1920-2004) Born in London, when he was a student at Eaton he decided to study the work of JBS Haldane. He set out to Cambridge to study engineering, and subsequently worked as an engineer designing military aircrafts. In 1947, he had a change of hearth and decided to study Drosophila genetics at U.C.L. under Haldane. In 1973, based on his interaction with George Price, he formalized the concept of “Evolutionarily Stable Strategy”, which became central to evolutionary game theory. His book Evolution and the Theory of Games (1982) was an immediate success and contributed to the birth of the field. History: George R. Price (1922-1975) One of the most remarkable characters in the history of biology, he was born in New York. He studied chemistry at U. Chicago, receiving a Ph.D. in 1946 (for work connected to the Manhattan Project). He went on to take a variery of jobs: teaching chemistry at Harvard, consulting at Argonne, researching at Bell Lab, writing popular science, working on medical research at U. Minnesota, and consulting for IBM on computer graphics. In 1966, he was operated for a tumor, and the operation resulted in a partial paralysis. With the money from his medical insurance, he moved to the UK to start a new life. Without any training in population genetics or statistics, he devised the Price equation, based on his readings of Hamilton’s papers on kin selection. This feat landed him a job at Galton Lab at UCL, despite his lack of credentials. His collaborations with Hamilton and Maynard-Smith led to the development of evolutionary game theory. A strong atheist from an early age, in 1970 Price had a religious experience, converted to Christianity and started (inspired by his own equation) to perform acts of random kindness to complete strangers. Having given up all his possessions, and possibly due to his stopping of thyroid treatment, Price grew depressed and committed suicide in 1975. The book The Price of Altruism: George Price and the Search for the Origins of Kindness (Oren Harman, 2010) narrates the incredible story of his life. 7.2 Two-player matrix games We start by anayzing games in which two players face each other, each choosing one strategy out of a set. Importantly, we consider static games in which each player makes their decision without having knowledge of the decision of the other player. Player 1 chooses a “pure” strategy \\(s_1\\) from the set of pure strategies \\(S_1\\), while player 2 chooses \\(s_2 \\in S_2\\). We call \\(\\pi_k (s_1, s_2)\\) the payoff for player \\(k\\) when player 1 chooses \\(s_1\\) and player 2 \\(s_2\\). In a matrix game, we can arrange the payoffs for each player in a matrix. We call \\(A\\) the matrix of payoffs for player one and \\(B\\) that for player two. 7.2.1 Example: the prisoner’s dilemma Two prisoners alleggedly committed a crime, but the police do not have enough evidence to convict them. They therefore approach each prisoner separately, proposing a deal: if the prisoner confesses (“defect” the other prisoner), then their sentence will be reduced. In particular: i) if both confess (both “defect”), they are sentenced to 4 years in prison; ii) if one confesses (“defect”) and the other keeps quiet (“cooperate” with the other prisoner), then the one who has confessed is let free, and the other sentenced to 5 years; iii) if both keep quiet (“cooperate”), then they are both sentenced to two years of detention for some accessory crime. In matrix form, we have (rows for pl 1 strategy C/D; cols for pl 2 strategy): \\[ A = \\begin{pmatrix} -2 &amp; -5\\\\ 0 &amp; -4 \\end{pmatrix} \\quad B = \\begin{pmatrix} -2 &amp; -5\\\\ 0 &amp; -4 \\end{pmatrix} \\] What is the best strategy player 1 can play—without knowing whether player 2 will confess or not? If player 2 were to keep quiet, player 1 should confess and be let free; if player 2 confesses, on the other hand, player 1 should also confess and get a reduced sentence. As such, each player would rationally choose to confess, thereby getting sentenced to four years in prison; note that if they could trust the other player, they could cooperate to get a much reduced sentence. The defect/defect is called a Nash Equilibrium: no player can improve their payoff by changing only their own strategy. One of the most interesting problems in this area is the study of the evolution of cooperation. Here is a very minimal bibliography: Key paper: Axelrod and Hamilton (1981) The seminal paper in this area. Interestingly, it details the outcome of a computer-based tournament in which several programs iteratively play the prisoner’s dilemma against each other. Key paper: Clutton-Brock (2009) An opinionated review of cooperation between non-kin in animal societies. The opening “As Darwin appreciated, cooperative behaviour—actions adapted to assist others that involve costs to the fitness of participants—poses a fundamental problem to the traditional theory of natural selection” succinlty summarizes why the evolution of cooperation is such a central problem. Key paper: Nowak and May (1992) Nowak and May examine the case in which populations of “cooperators” and “defectors” play the prisoner’s dilemma in a spatial setting. Despite the simple setting and the deterministic nature of the simulation, they find long-term coexistence of the different populations, giving rise to amazing spatial patterns. Key paper: Nowak and Sigmund (2005) Cooperation can evolve via indirect reciprocity (I help you in the hope that someone will help me) when players have a “reputation” to defend. 7.3 Mixed strategies Above, the player could choose one out of two strategies. A generalization of this situation is one in which players play mixed strategies, i.e., play a given strategy at random according to a set of probabilities. Call \\(x_i\\) the probability that player 1 plays strategy \\(i\\); then \\(\\sum_i x_i = 1\\). Similarly, \\(y_i\\) is the probability that player 2 plays strategy \\(i\\). A natural choice for the payoff of player 1 is therefore: \\[ \\sum_{i=1}^m \\sum_{j = 1}^n x_i y_j \\pi_1 (s_1, s_2) = x^T A y \\] Similarly, we have \\(y^T B x\\) for player 2. A mixed strategy \\(x\\) is dominated by mixed strategy \\(\\tilde{x}\\) if \\(\\tilde{x}^T A y \\geq x^T A y\\) for every \\(y\\). The condition can be written as \\((\\tilde{x} - x)^T A y \\geq 0\\). 7.4 Nash Equilibria A pair of mixed strategies \\(\\tilde{x}\\) and \\(\\tilde{y}\\) is called a Nash Equilibrium for a two person matrix game if: \\[ \\begin{aligned} \\tilde{x}^T A \\tilde{y} \\geq x^T A \\tilde{y} &amp;\\quad \\text{for all } x\\\\ \\tilde{y}^T B \\tilde{x} \\geq y^T B \\tilde{x} &amp;\\quad \\text{for all } y \\end{aligned} \\] Nash proved that every two-person game has at least one Nash Equilibrium. 7.5 Evolutionary stable strategies In the context of evolution, one can consider \\(x\\) to be the proportion of individuals (e.g., of different species, or phenotypes) displaying different characteristics. When playing against each other, they win or lose, and their payoffs are invested in reproduction. Because the different “strategies” (populations, phenotypes) play against each other, the payoff matrix is the same for all players, and encoded in matrix \\(A\\). In this context, a strategy \\(x\\) is called an evolutionary stable strategy if two conditions are met: \\[ x^T A x \\geq y^T A x \\quad \\text{for all } y \\] meaning that \\(x\\) plays against itself not worse than any other strategy, and \\[ \\text{If } y \\neq x \\text{ then } y^T A x = x^T A x \\text{ implies } x^T A y &gt; y^T A y \\] meaning that if \\(y\\) plays as well as \\(x\\) against \\(x\\), then \\(x\\) plays against \\(y\\) better than \\(y\\) against itself. We next connect NE and ESS with dynamical systems. 7.6 Replicator dynamics The replicator equation for this type of games can be written as: \\[ \\dfrac{d x_i}{dt} = x_i \\left( \\sum_j A_{ij} x_j - \\sum_{jk} x_j A_{jk} x_k \\right) \\] If we define \\(f = A x\\) as a vector reporting the “fitness”\" of each population at time \\(t\\), and \\(\\bar{f} = \\sum_{jk} x_j A_{jk} x_k = x^T A x\\) as the average fitness at time \\(t\\) we can write the replicator equation more compactly as: \\[ \\dfrac{d x_i}{dt} = x_i (f_i - \\bar{f}) \\] The RE is essentially equivalent to a GLV model in which we track frequencies instead of abundances. Importantly, we can see \\(x\\) as a “mixed strategy” for the symmetric game encoded in \\(A\\). In this context, an equilibrium of the replicator equation is a Nash Equilibrium for the game; similarly, a stable equilibrium for the replicator equation is an Evolutionary Stable Strategy. 7.6.1 Invariants Adding a constant to each column of \\(A\\) does not alter the dynamics. We have \\(B = A + e b^T\\), where \\(e\\) is a vector of ones. Then: \\[ \\begin{aligned} x_i \\left( \\sum_j B_{ij} x_j - \\sum_{kj} x_k B_{kj} x_j \\right) &amp; = x_i \\left( \\sum_j (A_{ij} + b_j) x_j - \\sum_{kj} x_k (A_{kj} + b_j) x_j \\right)\\\\ &amp;= x_i \\left(\\sum_j A_{ij} x_j + \\sum_j b_j x_j - \\sum_{kj} x_k A_{kj} x_j - \\sum_{kj} x_k b_{j} x_j \\right)\\\\ &amp;= x_i \\left(\\sum_j A_{ij} x_j + \\sum_j b_j x_j - \\sum_{kj} x_k A_{kj} x_j - \\sum_{j} b_{j} x_j \\right)\\\\ &amp;= x_i \\left(\\sum_j A_{ij} x_j - \\sum_{kj} x_k A_{kj} x_j \\right)\\\\ \\end{aligned} \\] Similarly, multiplying each column of \\(A\\) by a (possibly different) positive constant does not alter dynamics (it just rescales time). As such, if \\(A_2 = A_1 D + eb^T\\) the replicator equations formed using \\(A_1\\) and \\(A_2\\) are equivalent. 7.6.2 Rock-paper-scissor Let’s try our hand with a simple zero-sum (i.e., \\(A = -A^T\\)) replicator equation. We have three populations (“rock”, “paper”, and “scissors”) with payoff matrix: \\[ A = \\begin{pmatrix} 0 &amp; -1 &amp; 1\\\\ 1 &amp; 0 &amp; -1\\\\ -1 &amp; 1 &amp; 0 \\end{pmatrix} \\] We start the population at a random initial condition, and track dynamics: # define the differential equation RE &lt;-function(t, x, parameters){ with(as.list(c(x, parameters)), { x[x &lt; 10^-8] &lt;- 0 # prevent numerical problems x &lt;- x / sum(x) # keep on simplex dxdt &lt;- x * (A %*% x - sum(x * A %*% x)) list(dxdt) }) } # general function to integrate RE integrate_RE &lt;- function(A, x0, maxtime = 40, steptime = 0.05){ times &lt;- seq(0, maxtime, by = steptime) parameters &lt;- list(A = A) # solve numerically out &lt;- ode(y = x0, times = times, func = RE, parms = parameters, method = &quot;ode45&quot;) # plot and make into tidy form out &lt;- plot_ODE_output(out) return(out) } # payoff matrix A &lt;- matrix(c(0, -1, 1, 1, 0, -1, -1, 1, 0), 3, 3, byrow = TRUE) # initial conditions x0 &lt;- runif(3) x0 &lt;- x0 / sum(x0) rps &lt;- integrate_RE(A, x0) What if we start all populations at the same density? x0 &lt;- rep(1 / 3, 3) rps &lt;- integrate_RE(A, x0) And if they are close to the 1/3? x0 &lt;- rep(1/3, 3) + 0.05 * runif(3) x0 &lt;- x0 / sum(x0) rps &lt;- integrate_RE(A, x0) 7.6.3 Equivalence with GLV For a given \\(n-\\)species GLV system, there is an equivalent \\((n+1)-\\)dimensional replicator equation with zeros in the last row of the matrix. To show this, let’s take our functions for integrating GLV: # Generalized Lotka-Volterra model GLV &lt;- function(t, x, parameters){ with(as.list(c(x, parameters)), { x[x &lt; 10^-8] &lt;- 0 # prevent numerical problems dxdt &lt;- x * (r + A %*% x) list(dxdt) }) } # general function to integrate GLV integrate_GLV &lt;- function(r, A, x0, maxtime = 100, steptime = 0.5){ times &lt;- seq(0, maxtime, by = steptime) parameters &lt;- list(r = r, A = A) # solve numerically out &lt;- ode(y = x0, times = times, func = GLV, parms = parameters, method = &quot;ode45&quot;) # plot and make into tidy form out &lt;- plot_ODE_output(out) return(out) } And integrate the simple system: r &lt;- c(1, 2, 3) A &lt;- matrix(c(-1, 0.5, 0.1, -0.7, -2, 0, -0.3, 0, -5), 3, 3, byrow = TRUE) x0 &lt;- c(0.1, 3, 1) glvex &lt;- integrate_GLV(r, A, x0) B &lt;- matrix(0, 4, 4) B[1:3, 1:3] &lt;- A B[1:3, 4] &lt;- r \\[ \\begin{bmatrix}-1&amp;0.5&amp;0.1&amp;1 \\\\-0.7&amp;-2&amp;0&amp;2 \\\\-0.3&amp;0&amp;-5&amp;3 \\\\0&amp;0&amp;0&amp;0 \\\\\\end{bmatrix} \\] y0 &lt;- c(x0, 1) y0 &lt;- y0 / sum(y0) reex &lt;- integrate_RE(B, y0) Now let’s look at the equilibrium of the GLV model: knitr::kable(glvex %&gt;% filter(time == 100)) time species density 100 sp_1 1.3209145 100 sp_2 0.5376799 100 sp_3 0.5207451 And recover it from the RE equation (just divide by the density of the extra “species”): knitr::kable(reex %&gt;% filter(time == 40)) time species density 40 sp_1 0.3908793 40 sp_2 0.1591076 40 sp_3 0.1540969 40 sp_4 0.2959162 knitr::kable(reex %&gt;% filter(time == 40) %&gt;% mutate(density = density / tail(density, 1)) ) time species density 40 sp_1 1.3209123 40 sp_2 0.5376779 40 sp_3 0.5207453 40 sp_4 1.0000000 Not only the equilibria are the same, but also the dynamics are the same once time has been properly rescaled. Similarly, for each RE system we can always recover a matrix with zero in the last row by applying the transformations detailed above, and therefore recover the corresponding GLV. For example, take the matrix for the RPS above, and make each coefficient in the last row zero by adding the appropriate constant to each column. Then one recovers some sort of a predator-prey system: r &lt;- c(-1, 1) A &lt;- matrix(c(-1, 2, -2, 1), 2, 2, byrow = TRUE) x0 &lt;- c(0.9, 1.1) glvex &lt;- integrate_GLV(r, A, x0, maxtime = 15, steptime = 0.01) in which the species oscillate around one. Key paper: Page and Nowak (2002) In this brief paper, Page and Nowak show that the replicator-mutator equation and the Price equation are two ways of tracking general evolutionary dynamics. They discuss the connections with GLV and adaptive dynamics. 7.6.4 Hypertournament games The rock-paper-scissor game above is a simple case of a “hypertournament” game. Take the zero-sum payoff matrix \\(A = -A^T\\). Then, we have \\[ \\sum_i \\sum_j A_{ij} x_i x_j = 0 \\] and the RE simplifies to \\[ \\dfrac{d x}{dt} = D(x) A x \\] At equilibrium, either some elements of \\(x\\) are zero, or \\[ A x^\\star = 0 \\] meaning that if a feasible equilibrium \\(x^\\star\\) exists, it is an eigenvector of \\(A\\) corresponding to a zero eigenvalue. 7.6.4.1 Number of coexisting species We now show how the equations above can arise when modeling ecological dynamics. Suppose that a forest is composed of a fixed number of trees. Each time a tree dies (with rate \\(d = 1\\) for all species), a gap in the canopy opens, and species will compete to colonize it. Let’s assume that two seeds (sampled with probability proportional to the density of the species) land in the empty patch, and that they compete to fill the gap. Call \\(H_{ij}\\) the probability that \\(i\\) wins when competing with \\(j\\); we have \\(H_{ij} + H_{ji} = 1\\). We can write the dynamics (Grilli et al. 2017) as: \\[ \\begin{aligned} \\dfrac{d x}{dt} &amp;= x_i \\left(\\sum_j 2 H_{ij} x_j - 1 \\right) \\\\ &amp;=x_i \\sum_j (2 H_{ij} x_j - x_j) \\\\ &amp;= x_i \\sum_j (H_{ij} x_j + (1 - H_{ji}) x_j - x_j) \\\\ &amp;= x_i \\sum_j (H_{ij} - H_{ji}) x_j \\\\ &amp;= x_i \\sum_j A_{ij} x_j \\end{aligned} \\] I.e., we recover the RE for a zero-sum game. What happens if we draw \\(H\\) (and therefore \\(A\\)) at random? Allesina and Levine (2011) and Grilli et al. (2017) applied the results of Fisher and Reeves (1995) and Brandl (2017) to show that, when \\(n\\) species compete, the probability of observing \\(k\\) coexisting is \\(p(k|n) = \\binom{n}{k} 2^{1-n}\\) when \\(k\\) is odd, and \\(p(k|n) = 0\\) when \\(k\\) is even. Importantly, to find the set of coexisting species we do not need to integrate dynamics. One can use linear programming to solve for the set of species that will coexist. library(lpSolve) # Build a random matrix H such that H_ij + H_ji = 1 random_H &lt;- function(n){ # build random hypertournament H H &lt;- matrix(runif(n * n), n, n) return(H / (H + t(H))) } # Find the optimal strategy for the two-person game encoded in H # using linear programming. # This is also the coexistence equilibrium of the dynamical system. find_optimal_strategy &lt;- function(H){ n &lt;- dim(H)[1] f.obj &lt;- rep(1, n) f.con &lt;- H f.rhs &lt;- rep(1, n) f.dir &lt;- rep(&quot;&lt;=&quot;, n) z &lt;- lp (&quot;max&quot;, f.obj, f.con, f.dir, f.rhs) return(z$solution / sum(z$solution)) } Now let’s try to count how many species suvive when starting with 10: n &lt;- 10 num_simulations &lt;- 5000 results &lt;- tibble(simulation = 1:num_simulations, coexisting = 0) for (i in 1:num_simulations){ H &lt;- random_H(n) coexisting &lt;- find_optimal_strategy(H) results[i,&quot;coexisting&quot;] &lt;- sum((coexisting &gt; 0)*1) } # and plot ggplot(data = results) + aes(x = coexisting) + geom_bar() + scale_x_continuous(breaks = 0:10) 7.6.5 Lyapunov function In the rock-paper-scissor example above, species cycled neutrally around the unique equilibrium point. To show that this is in fact the behavior of this type of RE, we write a Lyapunov function. By finding a constant of motion we can show that the species will follow closed orbits. Suppose \\(x_{i}^\\star &gt; 0\\) is the equilibrium for the system. We write: \\[ V(x) = -\\sum_i x_i^\\star \\log \\frac{x_i}{x_i^\\star} . \\] Because of Gibbs’ inequality, \\(V(x) \\geq 0\\) for any \\(x\\), and is equal to zero only if \\(x = x^\\star\\). Note also that at equilibrium \\(2 \\sum_j H_{ij} x_j^\\star = 1\\). We write: \\[ \\begin{aligned} \\dfrac{d V}{d t} &amp;= \\sum_i \\dfrac{\\partial V}{\\partial x_i} \\dfrac{d x_i}{d t}\\\\ &amp;= - \\sum_i \\frac{x_i^\\star}{x_i} \\dfrac{d x_i}{d t} \\\\ &amp;= -2 \\sum_{i,j} x_i^\\star H_{ij}x_j + \\sum_i x_i^\\star\\\\ &amp;= -2 \\sum_{i,j} x_i^\\star H_{ij}x_j + 1\\\\ &amp;= \\sum_j \\left(-2 \\sum_i H_{ij}x_i^\\star \\right) x_j + 1\\\\ &amp;= \\sum_j \\left(-2 \\sum_i (1 - H_{ji}) x_i^\\star \\right) x_j + 1\\\\ &amp;= \\sum_j \\left(-2 \\sum_i x_i^\\star + 2 \\sum_i H_{ji} x_i^\\star \\right) x_j + 1 \\\\ &amp;= \\sum_j \\left(-2 + 1 \\right) x_j + 1 \\\\ &amp;=- \\sum_j x_j + 1\\\\ &amp;= 0 \\end{aligned} \\] We have found a constant of motion, meaning that the system will follow closed orbits. Hence, unless we start the system precisely at \\(x^\\star\\), the abundances will cycle neutrally around the equilibrium. Let’s try with a larger system: n &lt;- 5 # search for random H yielding all species coexisting i &lt;- 0 while(TRUE){ i &lt;- i + 1 set.seed(i) H &lt;- random_H(n) x_star &lt;- find_optimal_strategy(H) if (all(x_star) &gt; 0) break } # payoff matrix A &lt;- H - t(H) # initial conditions close to equilibrium x0 &lt;- x_star + runif(n) * 0.2 x0 &lt;- x0 / sum(x0) fivespp &lt;- integrate_RE(A, x0, maxtime = 400, steptime = 0.1) Homework 7a Analyze the replicator equation when the matrix \\(A\\) is: \\[ A = \\begin{pmatrix} 0 &amp; -\\alpha &amp; 1\\\\ 1 &amp; 0 &amp; -\\alpha\\\\ -\\alpha &amp; 1 &amp; 0 \\end{pmatrix} \\] for the cases in which a) \\(\\alpha &gt; 1\\), b) \\(\\alpha &lt; 1\\). Write code to simulate the system, and prove stability/instability depending on the value of \\(\\alpha\\). Homework 7b As seen above, generally zero-sum matrix games will lead to an odd number of species coexisting. Can you build a matrix leading to four species/strategies coexisting? Now simulate the dynamics several times starting from different initial conditions—do species cycle around the same equilibrium? Why? 7.6.6 Higher-order interactions We can extend the game above to the case in which three (or more) seeds compete to fill each patch. Grilli et al. (2017) showed that in this case, one can write the replicator equation: \\[ \\dfrac{d x_i}{dt} = x_i \\sum_{j,k} A_{ijk} x_j x_k \\] where the tensor \\(A\\) (a three-dimensional matrix) encodes the effect of a pair of species (\\(j\\) and \\(k\\)) on the density of \\(i\\). Importantly, one can choose the tensor such that the equilibrium is the same as for the two-player replicator equation: take \\(A_{ijk} = 2 H_{ij} H_{ik} - H_{ji} H_{jk} - H_{ki} H_{kj}\\), which can be derived from first principles by writing the stochastic dynamics. What is surprising is that, while the equilibrium is unchanged, the dynamics are now globally stable: # Now payoff is a tensor RE_3 &lt;- function(t, x, parameters){ with(as.list(c(x, parameters)), { x[x &lt; 10^-8] &lt;- 0 # prevent numerical problems x &lt;- x / sum(x) # keep on simplex n &lt;- length(x) dxidt &lt;- rep(0, n) for (i in 1:n){ dxidt[i] &lt;- x[i] * x %*% P3[i,,] %*% x } list(dxidt) }) } # general function to integrate RE_3 integrate_RE_3 &lt;- function(H, x0, maxtime = 40, steptime = 0.05){ times &lt;- seq(0, maxtime, by = steptime) n &lt;- nrow(H) P3 &lt;- array(0, c(n, n, n)) for (i in 1:n){ for (j in 1:n){ for (k in 1:n){ P3[i,j,k] &lt;- 2 * H[i,j] * H[i,k] - H[j,i] * H[j,k] - H[k,i] * H[k,j] } } } parameters &lt;- list(P3 = P3) # solve numerically out &lt;- ode(y = x0, times = times, func = RE_3, parms = parameters, method = &quot;ode45&quot;) # plot and make into tidy form out &lt;- plot_ODE_output(out) return(out) } # integrate the system above fivespp &lt;- integrate_RE_3(H, x0, maxtime = 800, steptime = 0.1) And the rock-paper-scissors: H &lt;- matrix(c(1/2, 1, 0, 0, 1/2, 1, 1, 0, 1/2), 3, 3, byrow = TRUE) x0 &lt;- runif(3) x0 &lt;- x0 / sum(x0) rps &lt;- integrate_RE_3(H, x0, maxtime = 50, steptime = 0.1) References "],
["metapopulation-dynamics-on-networks.html", "Lecture 8 Metapopulation dynamics on networks 8.1 Metapopulations 8.2 Hanski Ovaskainen 2000 8.3 SIS on a contact network 8.4 Metapopulations on randomly distributed patches 8.5 [Optional] Ecosystem engineering and metapopulations", " Lecture 8 Metapopulation dynamics on networks Lesson plan: We analyze Levins’ metapopulation model, which we’ve encountered before. We introduce the idea of a network of dispersal, and see how metapopulation persistence depends on network structure. We draw a parallel with Susceptible-Infected-Susceptible models, in which individuals play the role of habitable patches and parasites disperse on a network of contacts. Finally, we discuss recent extensions of metapopulation models including several complications. 8.1 Metapopulations Definition of metapopulations, Levins’ model, extensions to multispecies, network structure. Equivalence with SIS model. History: Richard Levins (1930-2016) Born in Brooklyn, New York, he studied agriculture and mathematics at Cornell. Early on, influenced by geneticist and polymath Haldane, he became a Marxist activist. Upon graduation, having been blacklisted as a communist (and with the Korean War raging), he moved to Puerto Rico with his wife, and set up a farm. In his spare time, he conducted experiments on fruit flies, organized anti-colonialist rallies and anti-war protests, and taught at the University of Puerto Rico. In 1964, he was invited to Cuba to help organize the biology department of the University of Havana. He received his doctorate from Columbia University in 1965. In 1967 he moved to the University of Chicago, where he joined Richard Lewontin—whith whom he established a lifelong collaboration. They both moved to Harvard in 19XX. It is impossible to summarize his numerous contributions to ecology, mathematics, political science, and the philosophy of science. He has inspired countless ecologists, and his approach and style are still visible in many of the research programs being carried out today. Of particular interest for this class, his theory of evolution in a changing environment (Levins (1968)), the development of the idea of limiting similarity (MacArthur and Levins (1967)), his work on metapopulation dynamics (Levins (1969)), and the development of Loop Analysis (i.e., a qualitative theory for dynamical systems, Puccia and Levins (2013)). Key paper: Levins (1966) A must read for anyone interested in modeling (in biology and elsewhere). Just two quotes that resonate with the approach taken in these lectures: there are too many parameters to measure; some are still only vaguely defined; many would require a lifetime each for their measurement. The equations are insoluble analytically and exceed the capacity of even good computers, Even if soluble, the result expressed in the form of quotients of sums of products of parameters would have no meaning for us. \\(\\ldots\\) Therefore, we attempt to treat the same problem with several alternative models each with different simplifications but with a common biological assumption. Then, if these models, despite their different assumptions, lead to similar results we have what we can call a robust theorem which is relatively free of the details of the model. Hence our truth is the intersection of independent lies. 8.2 Hanski Ovaskainen 2000 Hanski and Ovaskainen: extension to geographic location of patches, kernel of dispersal. Assumptions of the model Leading eigenvalue and Perron eigenvector History: Ilkka A. Hanski (1953-2016) Photo by Otso Ovaskainen. Born in Lempäälä, Finland, he studied at the University of Helsinki, and received his doctorate from the University of Oxford in 1979. From 1981 to his premature death in 2016, he worked at various Finnish institutions, lastly at the Academy of Finland. His work on metapopulation theory is extremely well-known, thanks also to the amazing work on the Glanville fritillary butterfly Melitaea cinxia. This butterfly inhabits the dry meadows in Åland Islands archipelago—with about 4000 meadows, sampled yearly by an army of students since 1991, the fragmented landscape is an ideal testing ground for metapopulation theory. Hanski won numerous awards, and served as a strong advocate for ecological conservation. 8.3 SIS on a contact network NIMFA model, equivalence with Hanski-Ovaskainen 8.4 Metapopulations on randomly distributed patches Grilli et al. 8.5 [Optional] Ecosystem engineering and metapopulations New work with Zach Homework: Gillespie-based simulation using event-driven simulations. Contrast approximation (NIMFA/Hanski-Ovaskainen) References "],
["quasi-polynomial-systems.html", "Lecture 9 Quasi-polynomial systems 9.1 From QP to GLV", " Lecture 9 Quasi-polynomial systems Lesson plan: We discuss a fairly general class of dynamical systems, called “Quasi-Polynomial” (QP-)systems. We show how any QP-system can be written as a larger-dimensional Generalized Lotka-Volterra model. This means that the machinery we built for analyzing GLV models can be used to tackle a variety of models that at face value do not seem to fall in this class. This also shows that the GLV model is in a way a “universal” model. For a simple application, we examine models of metapopulation dynamics with ecosystem engineering. 9.1 From QP to GLV We call a Quasi-Polynomial system a system of \\(n\\) ODEs that can be written as: \\[ \\frac{d x_i(t)}{d t} = x_i(t) \\left(s_i + \\sum_{j = i}^m A_{ij} \\prod_{k=1}^n x_k(t)^{B_{jk}}\\right) \\] where \\(s\\) is a vector of “growth rates” (not necessarily positive), \\(A\\) is a matrix of interactions, and \\(B\\) a matrix of exponents. Note that if we take \\(B = I_n\\) (the identity matrix), we recover the GLV model. If \\(B\\) contains only integers, then we recover a polynomial system. Extending this model to real (but not necessarily integer) numbers \\(B_{jk}\\), we have a “quasi-polynomial” system (Hernández-Bermejo, Fairén, and Brenig (1998)). In general, we assume that \\(A\\) is of size \\(n \\times m\\), \\(B\\) is \\(m \\times n\\), and that the \\(x_i(t)\\) are real and positive (if that’s not the case, one needs to perform a change of variables that ensures positivity). The system has \\(n\\) variables (the \\(x_i(t)\\)), and we can identify \\(m\\) “quasi-monomials”: \\[ \\prod_{k=1}^n x_k^{B_{jk}} \\] For example, take the system: \\[ \\begin{cases} \\frac{d x_1}{dt} = x_1 -x_1^{3/2} + \\frac{1}{4}x_1 x_2^2\\\\ \\frac{d x_2}{dt} = x_2 - \\frac{1}{2}x_2^2\\\\ \\end{cases} \\] with dynamics: qp1 &lt;- function(t, x, pars){ x1 &lt;- x[1] x2 &lt;- x[2] dx1dt &lt;- x1 * (1 - sqrt(x1) + (1 / 4) * x2^2) dx2dt &lt;- x2 * (1 - (1 / 2) * x2) return(list(c(dx1dt, dx2dt))) } set.seed(0) x0 &lt;- runif(2) outqp1 &lt;- ode(y = x0, times = seq(0, 45, by = 0.25), func = qp1, parms = NULL, method = &quot;ode45&quot;) ts &lt;- plot_ODE_output(outqp1) Showing that in this case dynamics reach the equilibrium \\((x_1^\\star, x_2^\\star) = (4,2)\\). This can be rewritten as: \\[ \\begin{cases} \\frac{d x_1}{dt} = x_1\\left(1 -x_1^{1/2} + \\frac{1}{4} x_2^2\\right)\\\\ \\frac{d x_2}{dt} = x_2 \\left(1 - \\frac{1}{2}x_2 \\right) \\end{cases} \\] which is in QP-form, with: \\[s = (1, 1)^T\\] \\[A = \\begin{pmatrix} -1 &amp; 1/4 &amp; 0\\\\ 0 &amp; 0 &amp; -1/2 \\end{pmatrix}\\] \\[B = \\begin{pmatrix} 1/2 &amp; 0 \\\\ 0 &amp; 2 \\\\ 0 &amp; 1 \\end{pmatrix}\\] Now we perform a change of variables, writing an equation for each quasi-monomial: \\[ z = () \\] References "],
["references.html", "References", " References "],
["random-bits-and-pieces.html", "Lecture 10 Random bits and pieces 10.1 Stability of larger matrices 10.2 Exercise", " Lecture 10 Random bits and pieces 10.1 Stability of larger matrices There are a number of techniques that can be used to prove the stability of larger systems. 10.1.1 Descartes’ rule of signs For a single-variable polynomial with real coefficients are ordered by descending variable exponent, then the number of positive roots of the polynomial is either equal to the number of sign differences between consecutive nonzero coefficients, or is less than it by an even number. Multiple roots of the same value are counted separately. As such, if a polynomial has all coefficients of the same sign, it has no positive roots. By considering \\(p(-\\lambda)\\) we can find the maximum number of negative roots. For example, for the Lotka-Volterra predator-prey model, we have \\[ M = \\begin{pmatrix} 0 &amp; -\\dfrac{ad}{b}\\\\ \\dfrac{bg}{d} &amp; 0 \\end{pmatrix} \\] The characteristic polynomial is \\[ p(\\lambda) = \\lambda^2 + \\dfrac{g}{d} \\] Meaning that the number of positve roots is zero. Taking \\(p(-\\lambda) = (-\\lambda)^2 + \\dfrac{g}{d}\\) which again has only positive coefficients, meaning that the number of negative roots is also zero. As such, the eigenvalues are purely imaginary (center), \\(\\lambda = \\pm i \\sqrt{g / d}\\). 10.1.2 Routh-Hurwitz criterion You can use the coefficients of the polynomial to determine stability. The polynomial \\[ p(\\lambda) = \\lambda^2 + a_1 \\lambda + a_0 \\] has all roots in the left half-plane (stable equilibrium) if \\(a_0 &gt; 0\\) and \\(a_1 &gt; 0\\). Note that, in this case \\(a_0 = \\det(A)\\) and \\(a_1 = -\\text{tr}(A)\\). Similarly, the polynomial \\[ p(\\lambda) = \\lambda^3 + a_2 \\lambda^2 + a_1 \\lambda + a_0 \\] has roots in the left half-plane if \\(a_2 &gt; 0\\), \\(a_0 &gt; 0\\), and \\(a_2 a_1 &gt; a_0\\). These conditions can be extended to larger matrices, but they become increasingly involved. 10.1.3 Bounding eigenvalues using the symmetric part Call \\(\\lambda_1 (A)\\) the eigenvalue of \\(A\\) with the largest real part (i.e., the “rightmost” eigenvalue). Then \\[ \\Re (\\lambda_1 (A)) \\leq \\lambda_1 ((A + A^T ) / 2) \\] if \\(\\lambda_1 ((A + A^T ) / 2) &lt; 0\\), then \\(A\\) is stable, and any matrix \\(DA\\) with \\(D\\) diagonal and positive is stable (\\(D-\\)stability). 10.2 Exercise To make sure you can work with stability, consider the following model that Carlos and I are studying. We consider a simple variation on the LV predator-prey system, in which predators are divided into two classes, linked by reproduction (e.g., males and females), and each class has a different mortality rate: \\[ \\begin{cases} \\dfrac{d x(t)}{d t} = x(t) \\left(r - a \\left(y^{(1)}(t) + y^{(2)}(t) \\right) )\\right)\\\\ \\dfrac{d y^{(1)}(t)}{d t} = -d^{(1)}y^{(1)}(t) + \\dfrac{e a x(t)}{2}\\left(y^{(1)}(t) + y^{(2)}(t) \\right) \\\\ \\dfrac{d y^{(2)}(t)}{d t} = -d^{(2)}y^{(2)}(t) + \\dfrac{e a x(t)}{2}\\left(y^{(1)}(t) + y^{(2)}(t) \\right) \\end{cases}\\quad. \\] where we take \\(d^{(1)} = d (1 + \\epsilon)\\) and \\(d^{(2)} = d (1 - \\epsilon)\\), with \\(|\\epsilon| &lt; 1\\) to ensure that predators cannot grow by themselves. Each class of predators has its own mortality, but the reproduction term is pooled and divided equally. The analysis of the model is simplified by considering the variables \\(y(t) = y^{(1)}(t) + y^{(2)}(t)\\) (i.e., the total density for the predator), and \\(z(t) = y^{(2)}(t) - y^{(1)}(t)\\) (i.e., the difference between the densities of the predator classes), yielding: \\[ \\begin{cases} \\dfrac{d x(t)}{d t} = x(t) \\left(r - a y(t))\\right)\\\\ \\dfrac{d y(t)}{d t} = y(t) \\left( -d + e a x(t) \\right) + d \\epsilon z(t)\\\\ \\dfrac{d z(t)}{d t} = -d z(t) + d \\epsilon y(t) \\end{cases}\\quad. \\] Find the two equilibria of the system, and perform the stability analysis. We describe our methods in this chapter. "]
]
